# Rule-GNN å®Œæ•´è®­ç»ƒæ­¥éª¤æŒ‡å—

## ğŸ“š ç›®å½•

1. [ç¯å¢ƒå‡†å¤‡](#1-ç¯å¢ƒå‡†å¤‡)
2. [æ•°æ®å‡†å¤‡](#2-æ•°æ®å‡†å¤‡)
3. [é…ç½®æ–‡ä»¶è¯´æ˜](#3-é…ç½®æ–‡ä»¶è¯´æ˜)
4. [è®­ç»ƒæµç¨‹è¯¦è§£](#4-è®­ç»ƒæµç¨‹è¯¦è§£)
5. [Rule-GNN æ ¸å¿ƒç®—æ³•æ­¥éª¤](#5-rule-gnn-æ ¸å¿ƒç®—æ³•æ­¥éª¤)
6. [è¾“å‡ºæ–‡ä»¶è¯´æ˜](#6-è¾“å‡ºæ–‡ä»¶è¯´æ˜)
7. [å¸¸è§é—®é¢˜æ’æŸ¥](#7-å¸¸è§é—®é¢˜æ’æŸ¥)
8. [è¿›é˜¶ä½¿ç”¨](#8-è¿›é˜¶ä½¿ç”¨)

---

## 1. ç¯å¢ƒå‡†å¤‡

### 1.1 åˆ›å»º Python ç¯å¢ƒ

```bash
# åˆ›å»º conda ç¯å¢ƒ
conda create -n RulE python=3.8.0
conda activate RulE
```

### 1.2 å®‰è£…ä¾èµ–

```bash
cd /path/to/RulE-master
pip install -r requirements.txt
```

**æ ¸å¿ƒä¾èµ–**:
- `torch>=1.10.0` - PyTorch æ·±åº¦å­¦ä¹ æ¡†æ¶
- `torch-geometric==2.0.4` - å›¾ç¥ç»ç½‘ç»œæ¡†æ¶
- `torch-scatter` - scatter æ“ä½œï¼ˆPyG ä¾èµ–ï¼‰
- `numpy` - æ•°å€¼è®¡ç®—
- `tqdm` - è¿›åº¦æ¡æ˜¾ç¤º

### 1.3 éªŒè¯å®‰è£…

```bash
python -c "import torch; import torch_geometric; print('PyTorch:', torch.__version__); print('PyG:', torch_geometric.__version__)"
```

**é¢„æœŸè¾“å‡º**:
```
PyTorch: 1.10.0+cu113
PyG: 2.0.4
```

---

## 2. æ•°æ®å‡†å¤‡

### 2.1 æ•°æ®é›†ç»“æ„

Rule-GNN éœ€è¦ä»¥ä¸‹æ•°æ®æ–‡ä»¶ï¼ˆä»¥ UMLS ä¸ºä¾‹ï¼‰:

```
data/umls/
â”œâ”€â”€ entities.dict          # å®ä½“å­—å…¸
â”œâ”€â”€ relations.dict         # å…³ç³»å­—å…¸
â”œâ”€â”€ train.txt             # è®­ç»ƒä¸‰å…ƒç»„
â”œâ”€â”€ valid.txt             # éªŒè¯ä¸‰å…ƒç»„
â”œâ”€â”€ test.txt              # æµ‹è¯•ä¸‰å…ƒç»„
â””â”€â”€ mined_rules.txt       # æŒ–æ˜çš„é€»è¾‘è§„åˆ™
```

### 2.2 æ•°æ®æ ¼å¼è¯´æ˜

#### `entities.dict`
æ ¼å¼: `<entity_id>\t<entity_name>`

```
0	umls:C0000005
1	umls:C0000039
2	umls:C0000052
...
```

#### `relations.dict`
æ ¼å¼: `<relation_id>\t<relation_name>`

```
0	umls:treats
1	umls:diagnoses
2	umls:causes
...
```

#### `train.txt / valid.txt / test.txt`
æ ¼å¼: `<head_name>\t<relation_name>\t<tail_name>`

```
umls:C0000005	umls:treats	umls:C0000039
umls:C0000052	umls:diagnoses	umls:C0000084
...
```

**æ³¨æ„**: ä½¿ç”¨å®ä½“/å…³ç³»åç§°ï¼Œä¸æ˜¯ IDï¼

#### `mined_rules.txt`
æ ¼å¼: `<rule_head_id> <rule_body_id_1> <rule_body_id_2> ...`

```
3 1 2
5 2 4
7 3 1 2
...
```

**ç¤ºä¾‹**: `3 1 2` è¡¨ç¤ºè§„åˆ™ "r1 âˆ§ r2 â†’ r3"

### 2.3 æ•°æ®é›†ä¸‹è½½

**UMLS** (åŒ»å­¦çŸ¥è¯†å›¾è°±):
- å®ä½“æ•°: 135
- å…³ç³»æ•°: 46
- è®­ç»ƒä¸‰å…ƒç»„: 5,216
- è§„åˆ™æ•°: ~600

**FB15k-237** (å¸¸è¯†çŸ¥è¯†å›¾è°±):
- å®ä½“æ•°: 14,541
- å…³ç³»æ•°: 237
- è®­ç»ƒä¸‰å…ƒç»„: 272,115
- è§„åˆ™æ•°: ~2,000

**WN18RR** (è¯æ±‡çŸ¥è¯†å›¾è°±):
- å®ä½“æ•°: 40,943
- å…³ç³»æ•°: 11
- è®­ç»ƒä¸‰å…ƒç»„: 86,835
- è§„åˆ™æ•°: ~500

---

## 3. é…ç½®æ–‡ä»¶è¯´æ˜

### 3.1 é…ç½®æ–‡ä»¶ä½ç½®

```bash
config/umls_rule_gnn_config.json
```

### 3.2 æ ¸å¿ƒå‚æ•°è§£æ

#### ğŸ“ åŸºç¡€é…ç½®

```json
{
    "dataset": "umls",
    "data_path": "../data/umls",
    "rule_file": "../data/umls/mined_rules.txt",
    "save_path": "umls"
}
```

- `dataset`: æ•°æ®é›†åç§°ï¼ˆç”¨äºæ—¥å¿—ï¼‰
- `data_path`: æ•°æ®é›†ç›®å½•è·¯å¾„
- `rule_file`: è§„åˆ™æ–‡ä»¶è·¯å¾„
- `save_path`: è¾“å‡ºä¿å­˜è·¯å¾„ï¼ˆç›¸å¯¹äº `src/` ç›®å½•ï¼‰

#### âš™ï¸ è®¾å¤‡é…ç½®

```json
{
    "cuda": true,
    "cpu_num": 10,
    "seed": 800
}
```

- `cuda`: æ˜¯å¦ä½¿ç”¨ GPUï¼ˆtrue/falseï¼‰
- `cpu_num`: CPU çº¿ç¨‹æ•°ï¼ˆç”¨äºæ•°æ®åŠ è½½ï¼‰
- `seed`: éšæœºç§å­ï¼ˆä¿è¯å¯å¤ç°ï¼‰

#### ğŸ§  æ¨¡å‹é…ç½®

```json
{
    "hidden_dim": 2000,
    "p_norm": 2
}
```

- `hidden_dim`: åµŒå…¥ç»´åº¦ï¼ˆè¶Šå¤§è¡¨è¾¾èƒ½åŠ›è¶Šå¼ºï¼Œä½†å ç”¨æ›´å¤šå†…å­˜ï¼‰
- `p_norm`: è·ç¦»åº¦é‡çš„èŒƒæ•°ï¼ˆRulE ä½¿ç”¨ï¼Œé€šå¸¸ä¸º 2ï¼‰

#### ğŸ”„ RulE é¢„è®­ç»ƒå‚æ•°

```json
{
    "batch_size": 256,
    "negative_sample_size": 512,
    "rule_batch_size": 256,
    "rule_negative_size": 128,
    "gamma_fact": 6,
    "gamma_rule": 8,
    "learning_rate": 0.0001,
    "max_steps": 30000
}
```

**æ‰¹æ¬¡è®¾ç½®**:
- `batch_size`: ä¸‰å…ƒç»„æ‰¹å¤§å°
- `negative_sample_size`: æ¯ä¸ªæ­£ä¸‰å…ƒç»„å¯¹åº”çš„è´Ÿæ ·æœ¬æ•°
- `rule_batch_size`: è§„åˆ™æ‰¹å¤§å°
- `rule_negative_size`: æ¯ä¸ªæ­£è§„åˆ™å¯¹åº”çš„è´Ÿæ ·æœ¬æ•°

**æŸå¤±å‡½æ•°**:
- `gamma_fact`: ä¸‰å…ƒç»„æŸå¤±çš„ marginï¼ˆè¶Šå¤§è¶Šä¸¥æ ¼ï¼‰
- `gamma_rule`: è§„åˆ™æŸå¤±çš„ margin
- `weight_rule`: è§„åˆ™æŸå¤±æƒé‡ï¼ˆé»˜è®¤ 1.0ï¼‰

**ä¼˜åŒ–å™¨**:
- `learning_rate`: å­¦ä¹ ç‡
- `max_steps`: æœ€å¤§è®­ç»ƒæ­¥æ•°
- `warm_up_steps`: å­¦ä¹ ç‡ warm-up æ­¥æ•°ï¼ˆé»˜è®¤ max_steps/2ï¼‰

**è´Ÿé‡‡æ ·ç­–ç•¥**:
- `negative_adversarial_sampling`: æ˜¯å¦ä½¿ç”¨å¯¹æŠ—æ€§è´Ÿé‡‡æ ·
- `adversarial_temperature`: å¯¹æŠ—æ€§é‡‡æ ·æ¸©åº¦ï¼ˆè¶Šå°è¶Šéš¾ï¼‰

#### ğŸŒ Rule-GNN å‚æ•°

```json
{
    "smoothing": 0.2,
    "batch_per_epoch": 1000000,
    "print_every": 10,
    "g_batch_size": 16,
    "g_lr": 0.0001,
    "dropout": 0.1,
    "rule_gnn_num_iters": 50,
    "rule_gnn_valid_every": 5
}
```

**è®­ç»ƒæ§åˆ¶**:
- `smoothing`: æ ‡ç­¾å¹³æ»‘ç³»æ•°ï¼ˆé˜²æ­¢è¿‡æ‹Ÿåˆï¼‰
- `batch_per_epoch`: æ¯ä¸ª epoch æœ€å¤§æ‰¹æ¬¡æ•°
  - **é‡è¦**: `TrainDataset` å·²å°†æ•°æ®æŒ‰å…³ç³»åˆ†ç»„ä¸º batch
  - UMLS å®é™…æœ‰çº¦ 282 ä¸ª batchï¼ˆæŒ‰å…³ç³»å’Œ `g_batch_size` åˆ†ç»„ï¼‰
  - è®¾ä¸º 1000000 ç›¸å½“äºä¸é™åˆ¶ï¼Œå¤„ç†æ‰€æœ‰ batch
  - è‹¥è®¾ä¸º 50ï¼Œåˆ™æ¯ä¸ª epoch åªå¤„ç†å‰ 50 ä¸ª batchï¼ˆå¿«é€Ÿæµ‹è¯•ï¼‰
- `print_every`: æ¯ N ä¸ªæ‰¹æ¬¡æ‰“å°æ—¥å¿—

**ä¼˜åŒ–å™¨**:
- `g_batch_size`: TrainDataset å†…éƒ¨åˆ†ç»„å¤§å°
  - **ä¸æ˜¯** DataLoader çš„ batch_size
  - ä¼ ç»™ TrainDataset ç”¨äºæŒ‰å…³ç³»åˆ†ç»„
  - DataLoader çš„ batch_size å›ºå®šä¸º 1ï¼ˆå› ä¸º TrainDataset å·²è¿”å› batchï¼‰
- `g_lr`: Rule-GNN å­¦ä¹ ç‡
- `dropout`: Dropout ç‡

**è®­ç»ƒå¾ªç¯**:
- `rule_gnn_num_iters`: Rule-GNN è®­ç»ƒ epoch æ•°
- `rule_gnn_valid_every`: æ¯ N ä¸ª epoch éªŒè¯ä¸€æ¬¡

**æ‰¹æ¬¡å¤§å°å±‚çº§å…³ç³»**:
```
TrainDataset(g_batch_size=16)  # å†…éƒ¨æŒ‰å…³ç³»åˆ†ç»„ï¼Œæ¯ç»„ 16 ä¸ªä¸‰å…ƒç»„
     â†“
è¿”å›å·²ç» batch å¥½çš„æ•°æ®: (h[16], r[16], t[16], target[16, 135], ...)
     â†“
DataLoader(batch_size=1)  # æ¯æ¬¡å– 1 ä¸ª "å·²åˆ†å¥½çš„ batch"
     â†“
trainer æ”¶åˆ°: (h[1, 16], r[1, 16], t[1, 16], ...)
     â†“
squeeze(0) å: (h[16], r[16], t[16], ...)  # è¿˜åŸä¸ºå®é™… batch
```

### 3.3 å‚æ•°è°ƒä¼˜å»ºè®®

#### ğŸ’» GPU å†…å­˜å—é™ (< 8GB)

```json
{
    "hidden_dim": 1000,
    "batch_size": 128,
    "negative_sample_size": 256,
    "g_batch_size": 8
}
```

#### âš¡ å¿«é€Ÿæµ‹è¯•ï¼ˆå‡å°‘è®­ç»ƒæ—¶é—´ï¼‰

```json
{
    "max_steps": 1000,
    "rule_gnn_num_iters": 5,
    "valid_steps": 100
}
```

#### ğŸ† è¿½æ±‚æœ€ä½³æ€§èƒ½

```json
{
    "hidden_dim": 2000,
    "max_steps": 50000,
    "rule_gnn_num_iters": 100,
    "dropout": 0.15
}
```

---

## 4. è®­ç»ƒæµç¨‹è¯¦è§£

### 4.1 å®Œæ•´è®­ç»ƒï¼ˆä»é›¶å¼€å§‹ï¼‰

#### æ­¥éª¤ 1: è¿›å…¥æºç ç›®å½•

```bash
cd /path/to/RulE-master/src
```

#### æ­¥éª¤ 2: å¯åŠ¨è®­ç»ƒ

```bash
python main_rule_gnn.py --init ../config/umls_rule_gnn_config.json
```

#### æ­¥éª¤ 3: è®­ç»ƒè¿‡ç¨‹ç›‘æ§

**é˜¶æ®µ 1: åŠ è½½æ•°æ®**

```
================================================================================
Phase 1: Loading Data
================================================================================
Entities: 135
Relations: 46
Train triples: 5216
Valid triples: 652
Test triples: 661
Number of rules: 587
Max rule length: 3
```

**é˜¶æ®µ 2: RulE é¢„è®­ç»ƒ**

```
================================================================================
Phase 2: RulE Pre-training (RotatE + Rule Embeddings)
================================================================================
Starting RulE pre-training...

Step 100/30000 | Loss: 2.345 | Fact Loss: 1.234 | Rule Loss: 1.111
Step 200/30000 | Loss: 2.123 | Fact Loss: 1.112 | Rule Loss: 1.011
...
Step 1000/30000 | Valid MRR: 0.523 | Hits@10: 0.721
...
Step 30000/30000 | Valid MRR: 0.867 | Hits@10: 0.943

RulE pre-training completed!
Evaluating RulE pre-training results...
Valid MRR: 0.867 | Hits@1: 0.792 | Hits@3: 0.904 | Hits@10: 0.943
Test MRR: 0.859 | Hits@1: 0.783 | Hits@3: 0.897 | Hits@10: 0.938
```

**é˜¶æ®µ 3: å¯¼å‡ºåµŒå…¥**

```
================================================================================
Phase 3: Exporting Embeddings for Rule-GNN
================================================================================
Exported entity embeddings: torch.Size([135, 4000])
Exported relation embeddings: torch.Size([46, 2000])
Exported rule embeddings: torch.Size([587, 2000])
```

**æ³¨æ„**: `entity_embedding` ç»´åº¦æ˜¯ `hidden_dim * 2`ï¼ˆå¤æ•°åµŒå…¥ï¼‰

**é˜¶æ®µ 4: Rule-GNN è®­ç»ƒ**

```
================================================================================
Phase 4: Rule-GNN Training (replaces Grounding)
================================================================================
GNN layers (= max rule length): 3
Rule-GNN parameters: 24,567,890

Loading pretrained embeddings into Rule-GNN...
Starting Rule-GNN training...

Epoch 1/50
Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 326/326 [00:45<00:00,  7.2it/s, loss=1.234]
Train Loss: 1.2345

Epoch 5/50
Valid MRR: 0.912 | Hits@1: 0.856 | Hits@3: 0.943 | Hits@10: 0.978
Saved best model to umls/rule_gnn_best.pt

...

Epoch 50/50
Valid MRR: 0.941 | Hits@1: 0.897 | Hits@3: 0.967 | Hits@10: 0.989
```

**é˜¶æ®µ 5: æœ€ç»ˆæµ‹è¯•**

```
================================================================================
Final Test Evaluation
================================================================================
Test MRR: 0.938 | Hits@1: 0.893 | Hits@3: 0.964 | Hits@10: 0.987
Test MR: 1.82
```

### 4.2 è·³è¿‡é¢„è®­ç»ƒï¼ˆä½¿ç”¨å·²æœ‰ checkpointï¼‰

#### å‰ææ¡ä»¶

ç¡®ä¿å­˜åœ¨ RulE é¢„è®­ç»ƒ checkpoint:

```bash
ls -lh umls/rule_checkpoint
# åº”è¯¥çœ‹åˆ°æ–‡ä»¶å­˜åœ¨
```

#### å¯åŠ¨è®­ç»ƒ

```bash
python main_rule_gnn.py --init ../config/umls_rule_gnn_config.json --skip_pretrain
```

**è®­ç»ƒæµç¨‹**:
```
é˜¶æ®µ 1: åŠ è½½æ•°æ®
é˜¶æ®µ 2: è·³è¿‡ RulE é¢„è®­ç»ƒï¼ˆä» checkpoint åŠ è½½ï¼‰
é˜¶æ®µ 3: å¯¼å‡ºåµŒå…¥
é˜¶æ®µ 4: Rule-GNN è®­ç»ƒ
é˜¶æ®µ 5: ä¿å­˜ç»“æœ
```

### 4.3 è®­ç»ƒæ—¶é—´ä¼°ç®—

#### UMLS æ•°æ®é›†ï¼ˆ135 å®ä½“ï¼Œ5K ä¸‰å…ƒç»„ï¼‰

| é˜¶æ®µ | GPU (V100) | CPU (10æ ¸) |
|-----|-----------|-----------|
| RulE é¢„è®­ç»ƒ (30K steps) | ~30 åˆ†é’Ÿ | ~3 å°æ—¶ |
| Rule-GNN è®­ç»ƒ (50 epochs) | ~15 åˆ†é’Ÿ | ~1.5 å°æ—¶ |
| **æ€»è®¡** | ~45 åˆ†é’Ÿ | ~4.5 å°æ—¶ |

#### FB15k-237 æ•°æ®é›†ï¼ˆ14K å®ä½“ï¼Œ272K ä¸‰å…ƒç»„ï¼‰

| é˜¶æ®µ | GPU (V100) | CPU (10æ ¸) |
|-----|-----------|-----------|
| RulE é¢„è®­ç»ƒ (50K steps) | ~4 å°æ—¶ | ~2 å¤© |
| Rule-GNN è®­ç»ƒ (50 epochs) | ~2 å°æ—¶ | ~8 å°æ—¶ |
| **æ€»è®¡** | ~6 å°æ—¶ | ~2.5 å¤© |

---

## 5. Rule-GNN æ ¸å¿ƒç®—æ³•æ­¥éª¤

### 5.1 è®¾è®¡æ¨¡å¼è¯´æ˜

Rule-GNN é‡‡ç”¨ **å…¨å®ä½“æ‰“åˆ†æ¨¡å¼ï¼ˆFull Rankingï¼‰**ï¼Œä¸ RulE åŸå§‹ Grounding é˜¶æ®µä¸€è‡´ï¼š

| ç‰¹æ€§ | Rule-GNNï¼ˆGrounding æ¨¡å¼ï¼‰ | KGE è´Ÿé‡‡æ ·æ¨¡å¼ |
|------|--------------------------|--------------|
| æ‰“åˆ†å®ä½“æ•° | æ‰€æœ‰å®ä½“ï¼ˆå¦‚ 135ï¼‰ | 1 + neg_sizeï¼ˆå¦‚ 129ï¼‰ |
| æ ‡ç­¾ç±»å‹ | å¤šçƒ­æ ‡ç­¾ï¼ˆå¤šä¸ªæ­£ç¡®ç­”æ¡ˆï¼‰ | å•çƒ­ï¼ˆç¬¬ 0 ä¸ªæ˜¯æ­£æ ·æœ¬ï¼‰ |
| æŸå¤±å‡½æ•° | BCEWithLogitsLoss | CrossEntropyLoss |
| é€‚ç”¨åœºæ™¯ | å°å›¾ã€å¤šç­”æ¡ˆæŸ¥è¯¢ | å¤§å›¾ã€å•ç­”æ¡ˆæŸ¥è¯¢ |

### 5.2 è®­ç»ƒé˜¶æ®µå®Œæ•´æ­¥éª¤

#### è¾“å…¥æ•°æ®

```
- queries: æŸ¥è¯¢ (h, r) [batch_size, 2]
- target: å¤šçƒ­æ ‡ç­¾ [batch_size, num_entities]
  - target[i][j] = 1 è¡¨ç¤ºå®ä½“ j æ˜¯æŸ¥è¯¢ i çš„æ­£ç¡®ç­”æ¡ˆ
- edge_index: å›¾çš„è¾¹ç´¢å¼• [2, num_edges]
- edge_type: è¾¹çš„ç±»å‹ [num_edges]
```

#### æ­¥éª¤ 1: åˆå§‹åŒ–èŠ‚ç‚¹ç‰¹å¾

```python
# ä»é¢„è®­ç»ƒçš„ RulE åŠ è½½å®ä½“åµŒå…¥
h = entity_embedding.weight  # [num_entities, hidden_dim]
```

**è¯´æ˜**ï¼š
- å®ä½“åµŒå…¥æ¥è‡ª RulE é¢„è®­ç»ƒé˜¶æ®µ
- è¿™æ˜¯æ‰€æœ‰å®ä½“çš„åˆå§‹è¡¨ç¤º

#### æ­¥éª¤ 2: è·å–æ¿€æ´»è§„åˆ™

```python
# æ ¹æ®æŸ¥è¯¢å…³ç³»ï¼Œæ‰¾åˆ°ç›¸å…³çš„è§„åˆ™
active_rules = set()
for r in query_relations:
    if r in relation2rules:
        for rule in relation2rules[r]:
            active_rules.add(rule_id)

rule_ids = list(active_rules)  # [num_active_rules]
```

**ç¤ºä¾‹**ï¼š
- æŸ¥è¯¢å…³ç³» `treats`ï¼ˆæ²»ç–—ï¼‰
- ç›¸å…³è§„åˆ™ï¼š
  - è§„åˆ™ 1: `diagnoses âˆ§ treats â†’ treats`
  - è§„åˆ™ 2: `causes âˆ§ treats â†’ treats`
- `rule_ids = [1, 2]`

#### æ­¥éª¤ 3: GNN æ¶ˆæ¯ä¼ é€’ï¼ˆå¤šå±‚ï¼Œç¨€ç–åŒ–å®ç°ï¼‰

```python
for layer_idx in range(num_layers):
    h = gnn_layer(h, edge_index, edge_type, rule_ids)
```

**æ¯å±‚ GNN åšçš„äº‹æƒ…**ï¼š

##### 3.0 åˆå§‹åŒ–ï¼šé¢„æ„å»ºç¨€ç–ç´¢å¼•ï¼ˆè®­ç»ƒå¼€å§‹å‰æ‰§è¡Œä¸€æ¬¡ï¼‰

```python
# é¢„æ„å»ºå…³ç³»åˆ°è¾¹çš„ç´¢å¼•æ˜ å°„ï¼Œé¿å…é‡å¤è®¡ç®— mask
relation2edges = {}   # å…³ç³»rçš„è¾¹ç´¢å¼•
relation2src = {}     # å…³ç³»rçš„æºèŠ‚ç‚¹
relation2dst = {}     # å…³ç³»rçš„ç›®æ ‡èŠ‚ç‚¹

for r in range(num_relations):
    mask = (edge_type == r)
    if mask.sum() > 0:
        relation2edges[r] = nonzero(mask)
        relation2src[r] = edge_index[0][mask]
        relation2dst[r] = edge_index[1][mask]
```

**å…³é”®ä¼˜åŒ–**ï¼š
- é¢„æ„å»ºç´¢å¼•åªéœ€ ~249KB å†…å­˜ï¼ˆvs åŸç¨ å¯†å®ç° 79MBï¼‰
- é¿å… forward ä¸­é‡å¤è®¡ç®— mask æ“ä½œ

##### 3.1 Query è®¡ç®—å¤–æï¼ˆåªè®¡ç®—ä¸€æ¬¡ï¼‰

```python
# ã€ä¼˜åŒ–ã€‘Query ç§»åˆ°è§„åˆ™å¾ªç¯å¤–ï¼Œåªè®¡ç®— 1 æ¬¡
# åŸå®ç°ï¼šåœ¨æ¯ä¸ªè§„åˆ™å¾ªç¯å†…è®¡ç®—ï¼Œ50æ¬¡ Ã— 79MB = 3.95GB
# ä¼˜åŒ–åï¼šåªè®¡ç®— 1 æ¬¡ï¼Œ79MB
query_all = W_q(h[dst])  # [num_edges, hidden_dim]
```

##### 3.2 æŒ‰å…³ç³»åˆ†å—è®¡ç®—æ³¨æ„åŠ›ï¼ˆç¨€ç–åŒ–æ ¸å¿ƒï¼‰

```python
# åˆå§‹åŒ–ç´¯åŠ å™¨
combined_messages = zeros(num_edges, hidden_dim)

for rule_idx, rule_id in enumerate(rule_ids):
    h_rule = rule_embedding[rule_id]  # [hidden_dim]

    # ã€ç¨€ç–åŒ–ã€‘æŒ‰å…³ç³»åˆ†å—å¤„ç†ï¼Œæ¯æ¬¡åªå¤„ç† ~113 æ¡è¾¹
    for r in relation2edges.keys():
        # è·å–å½“å‰å…³ç³»çš„ç¨€ç–ç´¢å¼•ï¼ˆé¢„æ„å»ºï¼ŒO(1) è®¿é—®ï¼‰
        edge_indices_r = relation2edges[r]  # [num_edges_r] ~113
        src_r = relation2src[r]
        dst_r = relation2dst[r]

        # Query: ä»é¢„è®¡ç®—ç»“æœä¸­ç´¢å¼•ï¼ˆä¸åˆ†é…æ–°å†…å­˜ï¼‰
        query_r = query_all[edge_indices_r]  # [num_edges_r, hidden_dim]

        # Key: æ„å»ºå°çŸ©é˜µï¼ˆæ ¸å¿ƒå†…å­˜èŠ‚çœç‚¹ï¼‰
        # åŸå®ç°ï¼š[10432, 6000] = 237MB
        # ç¨€ç–å®ç°ï¼š[~113, 6000] = 2.6MB
        h_src_r = h[src_r]  # [num_edges_r, hidden_dim]
        h_rel_r = W_r[r].mean(dim=-1)  # [hidden_dim]
        key_input_r = concat([h_src_r, h_rel_r, h_rule])  # [num_edges_r, hidden_dim*3]
        key_r = W_k(key_input_r)  # [num_edges_r, hidden_dim]

        # æ³¨æ„åŠ›åˆ†æ•°
        attn_scores_r = (query_r * key_r).sum(dim=-1) / sqrt(hidden_dim)
        attn_weights_r = scatter_softmax(attn_scores_r, dst_r)  # [num_edges_r]

        # æ¶ˆæ¯è®¡ç®—
        msg_r = matmul(h_src_r, W_r[r])  # [num_edges_r, hidden_dim]
        msg_r = msg_r * attn_weights_r.unsqueeze(-1)  # åŠ æƒ

        # ç¨€ç–ç´¯åŠ åˆ°å¯¹åº”è¾¹ä½ç½®
        combined_messages[edge_indices_r] += msg_r
```

**å†…å­˜å¯¹æ¯”**ï¼ˆUMLS æ•°æ®é›†ï¼‰ï¼š
| çŸ©é˜µ | ç¨ å¯†å®ç° | ç¨€ç–å®ç° | èŠ‚çœ |
|------|---------|---------|------|
| `query` | 79MB Ã— 50 = 3.95GB | 79MB Ã— 1 | 98% |
| `key_input` | 237MB Ã— 50 = 11.85GB | 2.6MB Ã— 1 | 99.98% |
| **æ€»è®¡** | **~24 GB (OOM)** | **~160 MB** | **99.3%** |

##### 3.3 èšåˆæ¶ˆæ¯åˆ°ç›®æ ‡èŠ‚ç‚¹

```python
# å–æ‰€æœ‰è§„åˆ™çš„å¹³å‡
combined_messages /= num_rules

# ä½¿ç”¨ scatter_add èšåˆåˆ°ç›®æ ‡èŠ‚ç‚¹
h_new = scatter_add(combined_messages, dst, dim=0)  # [num_entities, hidden_dim]

# æ·»åŠ åç½® + LayerNorm + ReLU + Dropout
h_new = h_new + bias
h_new = layer_norm(h_new)
h_new = relu(h_new)
h_new = dropout(h_new)
```

**å›¾è§£**ï¼š

```
     Layer 1                 Layer 2                 Layer 3
        â†“                       â†“                       â†“
    [Entity Emb]    â†’    [Updated Emb]    â†’    [Final Emb]
        â†“                       â†“                       â†“
   è§„åˆ™1 + è§„åˆ™2            è§„åˆ™1 + è§„åˆ™2           è§„åˆ™1 + è§„åˆ™2
   (æŒ‰å…³ç³»åˆ†å—)            (æŒ‰å…³ç³»åˆ†å—)            (æŒ‰å…³ç³»åˆ†å—)
   æ¶ˆæ¯ä¼ é€’                 æ¶ˆæ¯ä¼ é€’                æ¶ˆæ¯ä¼ é€’
```

#### æ­¥éª¤ 4: å¯¹æ‰€æœ‰å®ä½“æ‰“åˆ†

```python
# æå–æŸ¥è¯¢å¤´å®ä½“çš„è¡¨ç¤º
h_heads = h[queries[:, 0]]  # [batch_size, hidden_dim]

# æ‰€æœ‰å®ä½“çš„è¡¨ç¤º
h_tails = h  # [num_entities, hidden_dim]

# æ‹¼æ¥å¹¶é€šè¿‡ MLP æ‰“åˆ†
# h_heads: [batch_size, 1, hidden_dim] æ‰©å±•
# h_tails: [1, num_entities, hidden_dim] æ‰©å±•
combined = concat([h_heads, h_tails], dim=-1)  # [batch_size, num_entities, hidden_dim*2]

scores = MLP(combined).squeeze(-1)  # [batch_size, num_entities]
```

**è¯´æ˜**ï¼š
- å¯¹æ¯ä¸ªæŸ¥è¯¢ï¼Œè®¡ç®—æ‰€æœ‰å®ä½“ä½œä¸ºå°¾å®ä½“çš„å¾—åˆ†
- è¾“å‡ºç»´åº¦ï¼š`[batch_size, num_entities]`

#### æ­¥éª¤ 5: è®¡ç®—æŸå¤±

```python
# target: å¤šçƒ­æ ‡ç­¾ [batch_size, num_entities]
# æ ‡ç­¾å¹³æ»‘
if smoothing > 0:
    smooth_target = target * (1.0 - smoothing) + smoothing / num_entities
    loss = BCEWithLogitsLoss(scores, smooth_target)
else:
    loss = BCEWithLogitsLoss(scores, target)
```

**å¤šçƒ­æ ‡ç­¾ç¤ºä¾‹**ï¼š
```
æŸ¥è¯¢: (å®ä½“5, å…³ç³»3, ?)
æ­£ç¡®ç­”æ¡ˆ: å®ä½“ 10, 12, 15

target = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, ...]
                                      â†‘     â†‘        â†‘
                                     10    12       15
```

#### æ­¥éª¤ 6: åå‘ä¼ æ’­

```python
optimizer.zero_grad()
loss.backward()
optimizer.step()
```

### 5.3 è¯„ä¼°é˜¶æ®µæ­¥éª¤

#### æ­¥éª¤ 1-4: ä¸è®­ç»ƒç›¸åŒ

è·å–æ‰€æœ‰å®ä½“çš„å¾—åˆ† `scores: [batch_size, num_entities]`

#### æ­¥éª¤ 5: è¿‡æ»¤å·²çŸ¥ä¸‰å…ƒç»„

```python
# filter_mask: æ ‡è®°æ‰€æœ‰å·²çŸ¥ä¸‰å…ƒç»„ï¼ˆè®­ç»ƒ+éªŒè¯+æµ‹è¯•ï¼‰
# å°†å·²çŸ¥ç­”æ¡ˆçš„å¾—åˆ†è®¾ä¸ºè´Ÿæ— ç©·ï¼Œé¿å…å®ƒä»¬å½±å“æ’å
scores = scores.masked_fill(filter_mask, -1e9)
```

#### æ­¥éª¤ 6: è®¡ç®—æ’å

```python
for i in range(batch_size):
    true_tail = true_tails[i]
    true_score = scores[i, true_tail]

    # æ’å = æ¯”çœŸå®ç­”æ¡ˆå¾—åˆ†é«˜çš„å®ä½“æ•° + 1
    rank = (scores[i] > true_score).sum() + 1

    ranks.append(rank)
    reciprocal_ranks.append(1.0 / rank)
```

#### æ­¥éª¤ 7: è®¡ç®—æŒ‡æ ‡

```python
metrics = {
    'MRR': mean(reciprocal_ranks),      # å¹³å‡å€’æ•°æ’å
    'MR': mean(ranks),                   # å¹³å‡æ’å
    'HITS@1': mean(ranks <= 1),          # Top-1 å‡†ç¡®ç‡
    'HITS@3': mean(ranks <= 3),          # Top-3 å‡†ç¡®ç‡
    'HITS@10': mean(ranks <= 10)         # Top-10 å‡†ç¡®ç‡
}
```

### 5.4 ä¸åŸå§‹ RulE Grounding çš„å¯¹æ¯”

| æ­¥éª¤ | RulE Grounding | Rule-GNN |
|------|---------------|----------|
| **è§„åˆ™å¤„ç†** | æ˜¾å¼æšä¸¾æ¯æ¡è§„åˆ™çš„ grounding è·¯å¾„ | éšå¼é€šè¿‡ GNN æ¶ˆæ¯ä¼ é€’ |
| **è·¯å¾„éå†** | r1 â†’ r2 â†’ r3 æŒ‰é¡ºåºéå† | å¤šå±‚ GNNï¼Œæ¯å±‚èšåˆæ‰€æœ‰å…³ç³» |
| **è®¡ç®—æ–¹å¼** | ç¨€ç–çŸ©é˜µä¹˜æ³•ï¼ˆé€å…³ç³»ï¼‰ | æ³¨æ„åŠ›åŠ æƒæ¶ˆæ¯ä¼ é€’ |
| **è§„åˆ™æƒé‡** | MLP å­¦ä¹ æ¯æ¡è§„åˆ™çš„æƒé‡ | æ³¨æ„åŠ›æœºåˆ¶è‡ªåŠ¨è°ƒæ§ |
| **å¯å¹¶è¡Œæ€§** | è§„åˆ™ä¹‹é—´é¡ºåºå¤„ç† | æ‰€æœ‰è§„åˆ™å¹¶è¡Œè®¡ç®— |

### 5.5 ä¸ºä»€ä¹ˆç”¨ Grounding æ¨¡å¼è€Œä¸æ˜¯è´Ÿé‡‡æ ·ï¼Ÿ

1. **æ•°æ®å…¼å®¹**ï¼š`TrainDataset` è¿”å›å¤šçƒ­æ ‡ç­¾ `target`ï¼Œå¤©ç„¶æ”¯æŒ Grounding æ¨¡å¼

2. **å¤šç­”æ¡ˆé—®é¢˜**ï¼š
   - çŸ¥è¯†å›¾è°±ä¸­ `(h, r, ?)` å¯èƒ½æœ‰å¤šä¸ªæ­£ç¡®ç­”æ¡ˆ
   - ä¾‹å¦‚ï¼š"åŒ—äº¬çš„å¤§å­¦" â†’ æ¸…åã€åŒ—å¤§ã€äººå¤§...
   - è´Ÿé‡‡æ ·åªèƒ½å¤„ç†å•ç­”æ¡ˆï¼Œå…¨å®ä½“æ‰“åˆ†èƒ½å¤„ç†å¤šç­”æ¡ˆ

3. **ä¸ RulE ä¸€è‡´**ï¼šä¿æŒè®­ç»ƒæ–¹å¼ä¸€è‡´ï¼Œä¾¿äºå¯¹æ¯”

4. **è®¡ç®—å¯è¡Œ**ï¼šUMLS åªæœ‰ 135 ä¸ªå®ä½“ï¼Œå…¨æ‰“åˆ†è®¡ç®—é‡å¯æ¥å—

### 5.6 å®Œæ•´ä»£ç æµç¨‹å›¾

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Rule-GNN è®­ç»ƒæµç¨‹                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 1. æ•°æ®åŠ è½½                                                  â”‚
â”‚    - TrainDataset è¿”å›: (all_h, all_r, all_t, target, edges) â”‚
â”‚    - target: å¤šçƒ­æ ‡ç­¾ [batch_size, num_entities]             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 2. è·å–æ¿€æ´»è§„åˆ™                                              â”‚
â”‚    - æ ¹æ®æŸ¥è¯¢å…³ç³»æ‰¾ç›¸å…³è§„åˆ™                                   â”‚
â”‚    - rule_ids = [rule1, rule2, ...]                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 3. GNN æ¶ˆæ¯ä¼ é€’ï¼ˆé‡å¤ num_layers æ¬¡ï¼‰                         â”‚
â”‚    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚    â”‚ For each rule:                                      â”‚  â”‚
â”‚    â”‚   - è®¡ç®—è§„åˆ™æ„ŸçŸ¥çš„æ³¨æ„åŠ›æƒé‡                          â”‚  â”‚
â”‚    â”‚   - æ¶ˆæ¯ = W_r * h[src] * attention                 â”‚  â”‚
â”‚    â”‚   - èšåˆåˆ°ç›®æ ‡èŠ‚ç‚¹: h[dst] = sum(messages)          â”‚  â”‚
â”‚    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚    - å¤šè§„åˆ™å–å¹³å‡                                           â”‚
â”‚    - LayerNorm + ReLU + Dropout                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 4. å…¨å®ä½“æ‰“åˆ†                                                â”‚
â”‚    - h_heads = h[queries[:, 0]]                             â”‚
â”‚    - scores = MLP(concat(h_heads, h_all))                   â”‚
â”‚    - è¾“å‡º: [batch_size, num_entities]                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 5. è®¡ç®—æŸå¤±                                                  â”‚
â”‚    - æ ‡ç­¾å¹³æ»‘: smooth_target = target * 0.8 + 0.2/N         â”‚
â”‚    - loss = BCEWithLogitsLoss(scores, smooth_target)        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 6. åå‘ä¼ æ’­                                                  â”‚
â”‚    - optimizer.zero_grad()                                  â”‚
â”‚    - loss.backward()                                        â”‚
â”‚    - optimizer.step()                                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## 6. è¾“å‡ºæ–‡ä»¶è¯´æ˜

### 6.1 è¾“å‡ºç›®å½•ç»“æ„

è®­ç»ƒå®Œæˆåï¼Œè¾“å‡ºç›®å½•ç»“æ„å¦‚ä¸‹:

```
{save_path}/  (ä¾‹å¦‚ src/umls/)
â”œâ”€â”€ config.json                # è®­ç»ƒé…ç½®å¤‡ä»½
â”œâ”€â”€ run.log                    # å®Œæ•´è®­ç»ƒæ—¥å¿—
â”œâ”€â”€ rule_checkpoint            # RulE é¢„è®­ç»ƒæ¨¡å‹
â”œâ”€â”€ rule_gnn_best.pt           # Rule-GNN æœ€ä½³æ¨¡å‹
â””â”€â”€ rule_gnn_results.json      # æµ‹è¯•ç»“æœ
```

### 5.2 æ–‡ä»¶è¯¦è§£

#### `config.json`

ä¿å­˜çš„è®­ç»ƒé…ç½®ï¼ˆJSON æ ¼å¼ï¼‰ï¼Œç”¨äºå¤ç°å®éªŒ:

```json
{
    "dataset": "umls",
    "data_path": "../data/umls",
    "hidden_dim": 2000,
    "max_steps": 30000,
    "rule_gnn_num_iters": 50,
    ...
}
```

#### `run.log`

å®Œæ•´çš„è®­ç»ƒæ—¥å¿—ï¼ˆæ–‡æœ¬æ ¼å¼ï¼‰:

```
2024-11-19 10:00:00,123 - INFO - ================================================================================
2024-11-19 10:00:00,124 - INFO - Rule-GNN Training
2024-11-19 10:00:00,125 - INFO - ================================================================================
2024-11-19 10:00:01,456 - INFO - Phase 1: Loading Data
...
```

#### `rule_checkpoint`

RulE é¢„è®­ç»ƒæ¨¡å‹ï¼ˆPyTorch checkpointï¼‰:

```python
checkpoint = torch.load('rule_checkpoint')
# åŒ…å«:
# - 'model': æ¨¡å‹ state_dict
# - 'entity_embedding.weight': å®ä½“åµŒå…¥
# - 'relation_embedding.weight': å…³ç³»åµŒå…¥
# - 'rule_emb.weight': è§„åˆ™åµŒå…¥
```

#### `rule_gnn_best.pt`

Rule-GNN æœ€ä½³æ¨¡å‹ï¼ˆPyTorch checkpointï¼‰:

```python
checkpoint = torch.load('rule_gnn_best.pt')
# åŒ…å«:
# - 'model_state_dict': Rule-GNN æ¨¡å‹ state_dict
```

#### `rule_gnn_results.json`

æµ‹è¯•é›†ç»“æœï¼ˆJSON æ ¼å¼ï¼‰:

```json
{
    "dataset": "umls",
    "hidden_dim": 2000,
    "num_layers": 3,
    "test_metrics": {
        "MRR": 0.938,
        "MR": 1.82,
        "HITS@1": 0.893,
        "HITS@3": 0.964,
        "HITS@10": 0.987
    },
    "timestamp": "2024-11-19 12:30:45"
}
```

### 5.3 ä½¿ç”¨è®­ç»ƒå¥½çš„æ¨¡å‹

#### åŠ è½½ Rule-GNN æ¨¡å‹

```python
import torch
from rule_gnn_model import RuleGNN

# åˆ›å»ºæ¨¡å‹
model = RuleGNN(
    num_entities=135,
    num_relations=46*2,
    num_rules=587,
    hidden_dim=2000,
    num_layers=3,
    dropout=0.1
)

# åŠ è½½ checkpoint
checkpoint = torch.load('umls/rule_gnn_best.pt')
model.load_state_dict(checkpoint['model_state_dict'])
model.eval()
```

#### è¿›è¡Œæ¨ç†

```python
# å‡†å¤‡æŸ¥è¯¢: (head, relation)
queries = torch.tensor([[10, 5]])  # head=10, relation=5

# å‡†å¤‡å›¾æ•°æ®
edge_index = ...  # [2, num_edges]
edge_type = ...   # [num_edges]

# æ¿€æ´»çš„è§„åˆ™
rule_ids = torch.tensor([0, 1, 2, 10, 15])

# å‰å‘ä¼ æ’­
with torch.no_grad():
    scores = model(queries, edge_index, edge_type, rule_ids)
    # scores: [1, num_entities]

    # è·å– top-10 é¢„æµ‹
    top10_scores, top10_entities = torch.topk(scores[0], k=10)

    print("Top-10 é¢„æµ‹:")
    for i, (entity, score) in enumerate(zip(top10_entities, top10_scores)):
        print(f"{i+1}. Entity {entity.item()}: {score.item():.4f}")
```

---

