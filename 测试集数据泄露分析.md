# 测试集数据使用与泄露分析报告

## 🔍 您的问题

> 预训练和规则grounding的时候会不会去使用测试集去测试当前的参数和模型，如果会，这些使用测试测试集的数据会不会去优化模型？

## ✅ 简短回答

**不会造成数据泄露！** 虽然测试集数据在评估时会被使用，但它们**不会被用来优化模型参数**。代码实现是严格遵循机器学习规范的。

---

## 📊 详细分析

### 1️⃣ 三个关键数据映射

在 `src/data.py:251-253` 中定义了三个映射：

```python
self.hr2o = dict()          # 只包含训练集 (training set only)
self.hr2oo = dict()         # 包含训练集 + 验证集 (train + valid)
self.hr2ooo = dict()        # 包含训练集 + 验证集 + 测试集 (train + valid + test)
```

这三个映射的作用：
- `hr2o`: 用于训练时生成目标标签
- `hr2oo`: 用于验证时过滤已知三元组
- `hr2ooo`: 用于测试时过滤已知三元组

---

### 2️⃣ 预训练阶段 (PreTrainer)

#### 训练数据来源

**src/trainer.py:47-71** - 训练数据加载：
```python
triplets_dataloader_head = DataLoader(
    KGETrainDataset(
        triples=self.graph.train_facts,  # ← 只使用训练集！
        ...
    ),
    ...
)
```

**关键点**：
- ✅ 训练只使用 `self.graph.train_facts` (训练集三元组)
- ✅ 不涉及验证集或测试集的三元组

#### 验证流程

**src/trainer.py:117-122** - 验证检查点：
```python
if step % args.valid_steps == 0:
    logging.info('Evaluating on Valid Dataset...')
    mrr = self.evaluate("valid", self.expectation)  # ← 只在验证集上评估
    if mrr > best_mrr:
        save_model(self.model, optimizer, args)     # ← 保存最优模型
        best_mrr = mrr
```

**关键点**：
- ✅ 每1000步在验证集上评估一次
- ✅ 使用 `@torch.no_grad()` 装饰器 (src/trainer.py:226)，**不计算梯度**
- ✅ 只保存验证集上MRR最高的模型
- ❌ **从不在预训练阶段评估测试集**

#### evaluate() 方法分析

**src/trainer.py:226-327** - 评估实现：
```python
@torch.no_grad()  # ← 禁用梯度计算！
def evaluate(self, split, expectation=True):
    test_set = getattr(self, "%s_set" % split)  # split = "valid" 或 "test"
    dataloader = DataLoader(test_set, batch_size=1, ...)
    model = self.model
    model.eval()  # ← 设置为评估模式！

    # ... 计算logits和排名 ...

    return mrr  # ← 只返回指标，不更新参数！
```

**关键保护机制**：
1. `@torch.no_grad()`: PyTorch不会为任何操作构建计算图，**无法进行反向传播**
2. `model.eval()`: 关闭Dropout和BatchNorm的训练模式
3. 没有 `optimizer.step()` 调用
4. 没有 `loss.backward()` 调用

**结论**: ✅ 评估过程**物理上无法**更新模型参数

---

### 3️⃣ Grounding阶段 (GroundTrainer)

#### 训练数据来源

**src/data.py:449-493** - TrainDataset实现：
```python
class TrainDataset(Dataset):
    def __init__(self, graph, batch_size):
        self.r2instances = [[] for r in range(self.graph.relation_size * 2)]
        for h, r, t in self.graph.ground_train_facts:  # ← 只使用训练集！
            self.r2instances[r].append((h, r, t))

    def __getitem__(self, idx):
        # ...
        hr_index = self.graph.encode_hr(h, r)
        t_index = torch.LongTensor(self.graph.hr2o[hr_index])  # ← 使用hr2o (仅训练集)!
        target[k][t_index] = 1  # ← 目标标签只来自训练集！
```

**关键点**：
- ✅ 训练样本来自 `ground_train_facts` (训练集)
- ✅ 目标标签使用 `hr2o` 映射 (只包含训练集三元组)
- ✅ **不使用** `hr2oo` 或 `hr2ooo`

#### 每轮训练后的验证

**src/trainer.py:322-331** - Grounding训练循环：
```python
for k in range(args.num_iters):  # 20轮
    self.train_step(optimizer, train_dataloader, ...)  # ← 训练
    valid_mrr_iter = self.evaluate('valid', args.alpha, expectation=True)  # ← 验证集评估

    if valid_mrr_iter > best_valid_mrr:
        best_valid_mrr = valid_mrr_iter
        self.save(args, os.path.join(args.save_path, 'grounding.pt'))  # ← 保存最优
```

**关键点**：
- ✅ 每轮训练后在**验证集**上评估
- ✅ 根据验证集MRR保存最优模型
- ❌ **训练过程中不使用测试集**

#### 最终测试

**src/trainer.py:338-343** - 训练结束后才测试：
```python
# 训练完成后
checkpoint = torch.load(os.path.join(self.args.save_path, 'grounding.pt'))
self.model.load_state_dict(checkpoint['model'])  # ← 加载最优模型

test_mrr_iter = self.evaluate('valid', args.alpha, expectation=True)  # 再次验证
test_mrr_iter = self.evaluate('test', args.alpha, expectation=True)   # ← 第一次测试！
test_mrr_iter = self.evaluate_t('test_kge', args.alpha, expectation=True)  # 组合模式测试
```

**关键点**：
- ✅ **测试集只在整个训练结束后使用一次**
- ✅ 加载的是验证集上最优的模型
- ✅ 测试结果不影响任何模型参数

---

### 4️⃣ 测试集数据在何处被使用？

#### 4.1 构建过滤掩码 (Filtered Setting)

**src/data.py:532-567** - TestDataset实现：
```python
class TestDataset(Dataset):
    def __getitem__(self, idx):
        all_h, all_r, all_t = ...

        mask = torch.ones(len(data), self.graph.entity_size).bool()
        for k, (h, r, t) in enumerate(data):
            hr_index = self.graph.encode_hr(h, r)
            t_index = torch.LongTensor(self.graph.hr2ooo[hr_index])  # ← 使用hr2ooo!
            mask[k][t_index] = 0  # ← 过滤掉所有已知三元组（train/valid/test）

        return all_h, all_r, all_t, mask
```

**作用**：
- 在排名时排除所有已知的真实三元组（包括训练集、验证集、测试集）
- 这是知识图谱评估的**标准做法** (Filtered Setting)
- 避免惩罚模型预测出其他正确答案

#### 4.2 评估函数中的使用

**src/trainer.py:459-471** - 计算排名：
```python
for k in range(concat_all_t.size(0)):
    h, r, t = concat_all_h[k], concat_all_r[k], concat_all_t[k]
    val = concat_logits[k, t]  # ← 真实答案的分数

    # 只在未被过滤的候选中计算排名
    L = (concat_logits[k][concat_flag[k]] > val).sum().item() + 1
    H = (concat_logits[k][concat_flag[k]] >= val).sum().item() + 2
```

**concat_flag** 来自 `TestDataset` 返回的 `mask`，它使用 `hr2ooo` 过滤所有已知三元组。

---

## 🛡️ 数据泄露防护机制总结

### ✅ 训练阶段的严格隔离

| 阶段 | 训练数据 | 目标标签来源 | 验证数据 | 测试数据 |
|------|---------|-------------|---------|---------|
| **预训练** | train_facts | hr2o (仅训练) | 每1000步验证 | ❌ 不使用 |
| **Grounding** | ground_train_facts | hr2o (仅训练) | 每轮验证 | ❌ 不使用 |
| **最终评估** | ❌ 不训练 | - | 最优模型验证 | ✅ 仅评估一次 |

### ✅ 梯度计算的物理隔离

```python
@torch.no_grad()  # ← 关键保护！PyTorch不会构建计算图
def evaluate(self, split, expectation=True):
    model.eval()  # ← 关闭训练模式
    # ... 只做前向传播，计算指标 ...
    return mrr  # ← 只返回指标，无反向传播
```

### ✅ 模型选择机制

```python
# 预训练阶段
if mrr > best_mrr:  # ← 基于验证集MRR
    save_model(...)  # ← 保存最优模型

# Grounding阶段
if valid_mrr_iter > best_valid_mrr:  # ← 基于验证集MRR
    self.save(...)  # ← 保存最优模型
```

所有模型选择**只依赖验证集性能**，测试集从未参与模型选择！

---

## 🎯 测试集的唯一用途

测试集数据**只有两个合法用途**：

### 1. 提供评估样本
**src/data.py:537-541** - 测试三元组：
```python
class TestDataset(Dataset):
    def __init__(self, graph, batch_size):
        facts = self.graph.test_facts  # ← 测试集三元组
        # 用于生成查询 (h, r, ?) 来评估模型
```

### 2. 构建过滤掩码 (Filtered Evaluation)
**src/data.py:562-565** - 过滤已知答案：
```python
hr_index = self.graph.encode_hr(h, r)
t_index = torch.LongTensor(self.graph.hr2ooo[hr_index])  # ← 包含test
mask[k][t_index] = 0  # ← 避免惩罚预测出其他正确答案
```

**为什么要过滤测试集？**
- 知识图谱通常是**不完整的**
- 测试集中的 (h, r, t1) 不意味着 (h, r, t2) 一定是错的
- 如果模型预测出 t2，而 t2 恰好在测试集中（但不是当前评估的三元组），不应该惩罚模型
- 这是评估知识图谱模型的**国际标准做法**

---

## 📝 代码证据链

### 证据1: 训练数据严格来自训练集
```python
# src/trainer.py:48-49
KGETrainDataset(
    triples=self.graph.train_facts,  # ✓ 训练集
```

### 证据2: 目标标签只使用hr2o
```python
# src/data.py:485
t_index = torch.LongTensor(self.graph.hr2o[hr_index])  # ✓ 仅训练集
target[k][t_index] = 1
```

### 证据3: 评估时禁用梯度
```python
# src/trainer.py:226
@torch.no_grad()  # ✓ 物理上无法反向传播
def evaluate(self, split, expectation=True):
```

### 证据4: 测试在训练结束后
```python
# src/trainer.py:341-343
checkpoint = torch.load(...)  # ✓ 加载已训练完的模型
self.model.load_state_dict(checkpoint['model'])
test_mrr = self.evaluate('test', ...)  # ✓ 只评估，不训练
```

---

## 🏆 结论

### ✅ 没有数据泄露

1. **训练阶段**：
   - 预训练和Grounding都**只使用训练集**三元组
   - 目标标签来自 `hr2o`，**只包含训练集**
   - 验证集用于模型选择，但通过 `@torch.no_grad()` 保护

2. **测试阶段**：
   - 测试集**只在训练完全结束后使用一次**
   - 使用 `@torch.no_grad()` 和 `model.eval()`，**物理上无法更新参数**
   - 测试结果不影响任何模型参数或训练过程

3. **数据使用符合标准**：
   - 训练集 → 训练模型
   - 验证集 → 选择最优超参数和检查点
   - 测试集 → 最终评估（一次性，不更新模型）

### ✅ Filtered Setting是合理的

在知识图谱评估中使用 `hr2ooo` 过滤所有已知三元组是**国际标准做法**，不构成数据泄露，因为：
- 只是改变评估方式（排名时排除已知答案）
- 不影响模型训练
- 不提供额外的监督信号

### ✅ 代码实现规范

RulE的实现严格遵循机器学习规范：
- 数据集划分清晰
- 梯度隔离完善
- 模型选择基于验证集
- 测试集只用于最终评估

**您可以放心使用这个模型，不存在测试集数据泄露问题！** 🎉
