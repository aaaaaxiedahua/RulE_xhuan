# Rule-NBF: è§„åˆ™å¢å¼ºçš„ç¥ç»Bellman-Fordç½‘ç»œ

**å®Œæ•´æ–¹æ¡ˆè®¾è®¡ä¸å®ä¾‹è¯¦è§£**

---

## ğŸ“‹ ç›®å½•

1. [æ–¹æ¡ˆæ¦‚è¿°](#æ–¹æ¡ˆæ¦‚è¿°)
2. [æ ¸å¿ƒåˆ›æ–°ç‚¹](#æ ¸å¿ƒåˆ›æ–°ç‚¹)
3. [å®Œæ•´æ¶æ„è®¾è®¡](#å®Œæ•´æ¶æ„è®¾è®¡)
4. [è¯¦ç»†å®ä¾‹æ¼”ç¤º](#è¯¦ç»†å®ä¾‹æ¼”ç¤º)
5. [å®Œæ•´ä»£ç å®ç°](#å®Œæ•´ä»£ç å®ç°)
6. [å®éªŒè®¾è®¡](#å®éªŒè®¾è®¡)
7. [ä¸ç°æœ‰æ–¹æ³•å¯¹æ¯”](#ä¸ç°æœ‰æ–¹æ³•å¯¹æ¯”)

---

## ğŸ¯ ä¸€ã€æ–¹æ¡ˆæ¦‚è¿°

### 1.1 æ ¸å¿ƒæ€æƒ³

**Rule-NBF = NBFNetçš„å¼ºå¤§æ¡†æ¶ + RulEçš„è§„åˆ™å…ˆéªŒ + AdaPropçš„é«˜æ•ˆé‡‡æ ·**

```
é—®é¢˜ï¼šå¦‚ä½•ç»“åˆä¸‰ä¸ªSOTAæ–¹æ³•çš„ä¼˜åŠ¿ï¼Ÿ

ç­”æ¡ˆï¼šä¸æ˜¯ç®€å•æ‹¼æ¥ï¼Œè€Œæ˜¯æ·±åº¦èåˆ
  - ç”¨è§„åˆ™ç»“æ„æŒ‡å¯¼NBFNetçš„ä¼ æ’­è¿‡ç¨‹
  - ç”¨è§„åˆ™è¯­ä¹‰å¢å¼ºAdaPropçš„é‡‡æ ·ç­–ç•¥
  - ä¿æŒç«¯åˆ°ç«¯å¯è®­ç»ƒ
```

### 1.2 è®¾è®¡ç†å¿µ

**ä¸‰ä¸ª"ä¸æ˜¯"ï¼Œä¸‰ä¸ª"è€Œæ˜¯"**ï¼š

```
âŒ ä¸æ˜¯ï¼šåœ¨GNNçš„attentionä¸­æ‹¼æ¥è§„åˆ™åµŒå…¥
âœ… è€Œæ˜¯ï¼šç”¨è§„åˆ™ç»“æ„æŒ‡å¯¼æ¯ä¸€å±‚çš„ä¼ æ’­æ–¹å‘

âŒ ä¸æ˜¯ï¼šå…¨å›¾ä¼ æ’­ï¼Œæ•ˆç‡ä½ä¸‹
âœ… è€Œæ˜¯ï¼šè§„åˆ™æ„ŸçŸ¥çš„è‡ªé€‚åº”é‡‡æ ·ï¼Œåªä¼ æ’­åˆ°ç›¸å…³å®ä½“

âŒ ä¸æ˜¯ï¼šéšå¼å­¦ä¹ è§„åˆ™æ¨¡å¼
âœ… è€Œæ˜¯ï¼šæ˜¾å¼åˆ©ç”¨é¢„å…ˆæŒ–æ˜çš„è§„åˆ™çŸ¥è¯†
```

### 1.3 æ•´ä½“æµç¨‹å›¾

```
è¾“å…¥: Query (å¼ ä¸‰, grandfather, ?)
  â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ æ­¥éª¤1: åŠ¨æ€è§„åˆ™é€‰æ‹©                      â”‚
â”‚ ä»æ‰€æœ‰grandfatherç›¸å…³è§„åˆ™ä¸­              â”‚
â”‚ é€‰æ‹©Top-Kæœ€ç›¸å…³çš„è§„åˆ™                    â”‚
â”‚                                          â”‚
â”‚ è¾“å‡º: è§„åˆ™åˆ—è¡¨                           â”‚
â”‚ - father âˆ§ father â†’ grandfather (0.95)  â”‚
â”‚ - mother âˆ§ father â†’ grandfather (0.88)  â”‚
â”‚ - son âˆ§ father â†’ grandfather (0.82)     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
  â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ æ­¥éª¤2: è§„åˆ™å¼•å¯¼çš„åˆå§‹åŒ– (INDICATOR)       â”‚
â”‚ æ ¹æ®æŸ¥è¯¢å…³ç³»å’Œé€‰ä¸­çš„è§„åˆ™                 â”‚
â”‚ åˆå§‹åŒ–èµ·ç‚¹è¡¨ç¤º                           â”‚
â”‚                                          â”‚
â”‚ h[å¼ ä¸‰] = INDICATOR(grandfather, rules)â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
  â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ æ­¥éª¤3: ç¬¬1å±‚ä¼ æ’­                         â”‚
â”‚                                          â”‚
â”‚ 3.1 è§„åˆ™æ„ŸçŸ¥é‡‡æ ·                         â”‚
â”‚     ä»å¼ ä¸‰çš„é‚»å±…ä¸­é‡‡æ ·100ä¸ª              â”‚
â”‚     ä¼˜å…ˆé‡‡æ ·: father/motherè¾¹çš„é‚»å±…      â”‚
â”‚     ï¼ˆè§„åˆ™ä½“ç¬¬1ä¸ªå…³ç³»ï¼‰                  â”‚
â”‚                                          â”‚
â”‚ 3.2 è§„åˆ™å¼•å¯¼MESSAGE                      â”‚
â”‚     åªæ²¿father/motherè¾¹ä¼ æ’­              â”‚
â”‚     æ¶ˆæ¯æƒé‡ç”±è§„åˆ™ç½®ä¿¡åº¦å†³å®š             â”‚
â”‚                                          â”‚
â”‚ 3.3 è§„åˆ™åŠ æƒAGGREGATE                    â”‚
â”‚     ç”¨è§„åˆ™ç½®ä¿¡åº¦åŠ æƒèšåˆ                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
  â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ æ­¥éª¤4: ç¬¬2å±‚ä¼ æ’­                         â”‚
â”‚                                          â”‚
â”‚ 4.1 è§„åˆ™æ„ŸçŸ¥é‡‡æ ·                         â”‚
â”‚     ä»ç¬¬1å±‚å®ä½“çš„é‚»å±…ä¸­é‡‡æ ·              â”‚
â”‚     ä¼˜å…ˆé‡‡æ ·: fatherè¾¹çš„é‚»å±…             â”‚
â”‚     ï¼ˆè§„åˆ™ä½“ç¬¬2ä¸ªå…³ç³»ï¼‰                  â”‚
â”‚                                          â”‚
â”‚ 4.2 è§„åˆ™å¼•å¯¼MESSAGE                      â”‚
â”‚     åªæ²¿fatherè¾¹ä¼ æ’­                     â”‚
â”‚                                          â”‚
â”‚ 4.3 è§„åˆ™åŠ æƒAGGREGATE                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
  â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ æ­¥éª¤5: è§„åˆ™ä¸€è‡´æ€§çº¦æŸ                    â”‚
â”‚ ç¡®ä¿æœ€ç»ˆè¡¨ç¤ºç¬¦åˆè§„åˆ™é€»è¾‘                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
  â†“
è¾“å‡º: å¯¹æ‰€æœ‰å®ä½“çš„å¾—åˆ†
```

---

## ğŸ’¡ äºŒã€æ ¸å¿ƒåˆ›æ–°ç‚¹

### åˆ›æ–°ç‚¹1: è§„åˆ™å¼•å¯¼çš„åˆå§‹åŒ– (Rule-Guided INDICATOR)

**ä¼ ç»Ÿæ–¹æ³•çš„é—®é¢˜**ï¼š

```python
# ä¼ ç»ŸGNN
h[query_head] = entity_embedding[query_head]
# å›ºå®šçš„å®ä½“åµŒå…¥ï¼Œä¸æŸ¥è¯¢æ— å…³

# NBFNet
h[query_head] = W(relation_embedding[query_relation])
# åªè€ƒè™‘æŸ¥è¯¢å…³ç³»ï¼Œæ²¡æœ‰è§„åˆ™ä¿¡æ¯
```

**Rule-NBFçš„åˆ›æ–°**ï¼š

```python
# Rule-NBF
h[query_head] = INDICATOR(
    query_relation,
    selected_rules,  # æ–°å¢ï¼šè§„åˆ™å…ˆéªŒ
    rule_embeddings
)
# åŒæ—¶è€ƒè™‘ï¼šæŸ¥è¯¢å…³ç³» + ç›¸å…³è§„åˆ™
```

**ç›´è§‚ç†è§£**ï¼š

```
æŸ¥è¯¢: (å¼ ä¸‰, grandfather, ?)

ä¼ ç»Ÿ: h[å¼ ä¸‰] = entity_embedding[å¼ ä¸‰]
      â†’ é€šç”¨è¡¨ç¤ºï¼Œä¸çŸ¥é“è¦æ‰¾ä»€ä¹ˆ

NBFNet: h[å¼ ä¸‰] = W(grandfather_embedding)
       â†’ çŸ¥é“è¦æ‰¾grandfatherï¼Œä½†ä¸çŸ¥é“è·¯å¾„

Rule-NBF: h[å¼ ä¸‰] = INDICATOR(grandfather, [
              fatherâˆ§fatherâ†’grandfather,
              motherâˆ§fatherâ†’grandfather
          ])
         â†’ ä¸ä»…çŸ¥é“è¦æ‰¾grandfather
         â†’ è¿˜çŸ¥é“åº”è¯¥æ²¿father/motherè¾¹èµ°
```

### åˆ›æ–°ç‚¹2: è§„åˆ™æ„ŸçŸ¥çš„è‡ªé€‚åº”é‡‡æ ·

**ä¼ ç»Ÿæ–¹æ³•çš„é—®é¢˜**ï¼š

```python
# ä¼ ç»ŸGNNï¼šå…¨å›¾ä¼ æ’­
for layer in range(num_layers):
    for node in all_nodes:
        h_new[node] = aggregate(neighbors(node))

# å®ä½“æ•°é‡çˆ†ç‚¸:
#   ç¬¬1å±‚: 1ä¸ª
#   ç¬¬2å±‚: 20ä¸ª
#   ç¬¬3å±‚: 400ä¸ª
#   ç¬¬4å±‚: 8000ä¸ª (çˆ†ç‚¸ï¼)

# NBFNetï¼šæŸ¥è¯¢æ„ŸçŸ¥ï¼Œä½†ä»å…¨å›¾ä¼ æ’­
# AdaPropï¼šè¯­ä¹‰é‡‡æ ·ï¼Œä½†æ²¡ç”¨è§„åˆ™ä¿¡æ¯
```

**Rule-NBFçš„åˆ›æ–°**ï¼š

```python
# Rule-NBFï¼šè§„åˆ™æ„ŸçŸ¥é‡‡æ ·
for layer in range(num_layers):
    # 1. ç¡®å®šæœ¬å±‚åº”è¯¥ä¼ æ’­çš„å…³ç³»ï¼ˆä»è§„åˆ™ä½“ï¼‰
    layer_relations = get_layer_relations(rules, layer)
    # ä¾‹å¦‚: layer=0 â†’ [father, mother]

    # 2. åªè€ƒè™‘è¿™äº›å…³ç³»çš„é‚»å±…
    candidates = get_neighbors_by_relations(
        current_entities,
        layer_relations
    )

    # 3. è¯­ä¹‰é‡‡æ ·Top-K
    sampled_entities = adaptive_sample(
        candidates,
        budget=100,  # å›ºå®šæ•°é‡
        scoring_fn=semantic_scorer
    )

    # 4. åªåœ¨é‡‡æ ·çš„å®ä½“ä¸Šä¼ æ’­
    h = propagate(sampled_entities, layer_relations)
```

**æ•ˆæœå¯¹æ¯”**ï¼š

```
åœºæ™¯: 3å±‚GNNï¼Œå¹³å‡åº¦æ•°20

ä¼ ç»ŸGNN:
  ç¬¬1å±‚: 1ä¸ªå®ä½“
  ç¬¬2å±‚: 20ä¸ªå®ä½“
  ç¬¬3å±‚: 400ä¸ªå®ä½“
  æ€»è®¡: 421ä¸ªå®ä½“éœ€è¦è®¡ç®—

AdaProp:
  æ¯å±‚: 100ä¸ªå®ä½“ï¼ˆå›ºå®šé‡‡æ ·ï¼‰
  æ€»è®¡: 300ä¸ªå®ä½“éœ€è¦è®¡ç®—

Rule-NBF:
  ç¬¬1å±‚: 1ä¸ªå®ä½“
  ç¬¬2å±‚: 50ä¸ªå€™é€‰ï¼ˆåªæœ‰father/motheré‚»å±…ï¼‰â†’ é‡‡æ ·50ä¸ª
  ç¬¬3å±‚: 30ä¸ªå€™é€‰ï¼ˆåªæœ‰fatheré‚»å±…ï¼‰â†’ é‡‡æ ·30ä¸ª
  æ€»è®¡: 81ä¸ªå®ä½“éœ€è¦è®¡ç®—

åŠ é€Ÿæ¯”: 421 / 81 = 5.2å€
```

### åˆ›æ–°ç‚¹3: è§„åˆ™å¼•å¯¼çš„æ¶ˆæ¯ä¼ é€’

**ä¼ ç»Ÿæ–¹æ³•çš„é—®é¢˜**ï¼š

```python
# R-GCN: å…³ç³»ç‰¹å®šï¼Œä½†ä¸æŸ¥è¯¢æ— å…³
message = W_relation[r] @ h[neighbor]

# NBFNet: æŸ¥è¯¢è°ƒåˆ¶ï¼Œä½†æ²¡ç”¨è§„åˆ™
message = W_r @ h[neighbor] * sigmoid(W_query(query_rel))

# ç®€å•Rule-GNN: åªæ˜¯æ‹¼æ¥è§„åˆ™åµŒå…¥
attention = softmax([h_i, h_j, h_r, h_R])  # æµ…å±‚
```

**Rule-NBFçš„åˆ›æ–°**ï¼š

```python
# Rule-NBF: è§„åˆ™æ·±åº¦å¼•å¯¼
def compute_message(h_neighbor, edge_relation, query_relation, active_rules):
    # 1. æ£€æŸ¥è¾¹å…³ç³»æ˜¯å¦åœ¨è§„åˆ™ä½“ä¸­
    rule_match_scores = []
    for rule in active_rules:
        if edge_relation in rule.body[current_layer]:
            # åŒ¹é…ï¼Œé«˜åˆ†
            rule_match_scores.append(rule.confidence)
        else:
            # ä¸åŒ¹é…ï¼Œä½åˆ†
            rule_match_scores.append(0.0)

    # 2. åŸºç¡€æ¶ˆæ¯
    message_base = W_relation[edge_relation] @ h_neighbor

    # 3. æŸ¥è¯¢è°ƒåˆ¶ï¼ˆä»NBFNetï¼‰
    query_modulation = sigmoid(W_query(query_relation))

    # 4. è§„åˆ™è°ƒåˆ¶ï¼ˆåˆ›æ–°ï¼‰
    rule_modulation = sum(
        rule_match_scores[i] * W_rule(rule_embeddings[i])
        for i in range(len(active_rules))
    )

    # 5. ç»¼åˆ
    message = message_base * query_modulation * (1 + rule_modulation)

    return message
```

**ç›´è§‚ç†è§£**ï¼š

```
æŸ¥è¯¢: (å¼ ä¸‰, grandfather, ?)
è§„åˆ™: father âˆ§ father â†’ grandfather (ç½®ä¿¡åº¦0.9)
å½“å‰å±‚: ç¬¬1å±‚

è¾¹1: (å¼ ä¸‰, father, æå››)
  edge_relation = father
  è§„åˆ™ä½“ç¬¬1ä¸ªå…³ç³» = father
  â†’ åŒ¹é…ï¼rule_match_score = 0.9
  â†’ messageæƒé‡é«˜

è¾¹2: (å¼ ä¸‰, spouse, ç‹èŠ³)
  edge_relation = spouse
  è§„åˆ™ä½“ç¬¬1ä¸ªå…³ç³» = father
  â†’ ä¸åŒ¹é…ï¼rule_match_score = 0.0
  â†’ messageæƒé‡ä½ï¼ˆå‡ ä¹ä¸ä¼ æ’­ï¼‰

æ•ˆæœ: è‡ªåŠ¨æ²¿è§„åˆ™è·¯å¾„ä¼ æ’­ï¼Œè¿‡æ»¤æ— å…³è¾¹
```

### åˆ›æ–°ç‚¹4: è§„åˆ™ç½®ä¿¡åº¦åŠ æƒèšåˆ

**ä¼ ç»Ÿæ–¹æ³•çš„é—®é¢˜**ï¼š

```python
# ä¼ ç»ŸGNN: ç®€å•æ±‚å’Œ
h_new = sum(messages)

# NBFNet: å¯å­¦ä¹ èšåˆ
h_new = AGGREGATE(messages)  # ä½†ä¸è€ƒè™‘è§„åˆ™è´¨é‡
```

**Rule-NBFçš„åˆ›æ–°**ï¼š

```python
# Rule-NBF: è§„åˆ™ç½®ä¿¡åº¦åŠ æƒ
def aggregate(messages, active_rules):
    # 1. è®¡ç®—æ¯æ¡è§„åˆ™çš„æ•´ä½“ç½®ä¿¡åº¦
    overall_confidence = sum(rule.confidence for rule in active_rules) / len(active_rules)

    # 2. åŠ æƒèšåˆ
    h_aggregated = sum(messages) * overall_confidence

    # 3. å¦‚æœè§„åˆ™è´¨é‡é«˜ï¼Œç»™ç»“æœé«˜æƒé‡
    # å¦‚æœè§„åˆ™è´¨é‡ä½ï¼Œé™ä½æƒé‡

    return h_aggregated
```

**æ•ˆæœ**ï¼š

```
åœºæ™¯1: é«˜è´¨é‡è§„åˆ™
  è§„åˆ™: father âˆ§ father â†’ grandfather (ç½®ä¿¡åº¦0.95)
  èšåˆç»“æœ = messages Ã— 0.95
  â†’ æ¨¡å‹ç›¸ä¿¡è¿™ä¸ªç»“æœ

åœºæ™¯2: ä½è´¨é‡è§„åˆ™
  è§„åˆ™: colleague âˆ§ works_in â†’ grandfather (ç½®ä¿¡åº¦0.15)
  èšåˆç»“æœ = messages Ã— 0.15
  â†’ æ¨¡å‹ä¸å¤ªç›¸ä¿¡è¿™ä¸ªç»“æœ

ä¼˜åŠ¿: è‡ªåŠ¨åŒºåˆ†è§„åˆ™è´¨é‡ï¼Œé¿å…ä½è´¨é‡è§„åˆ™å¹²æ‰°
```

### åˆ›æ–°ç‚¹5: è§„åˆ™ä¸€è‡´æ€§çº¦æŸ

**ä¼ ç»Ÿæ–¹æ³•çš„é—®é¢˜**ï¼š

```python
# ä¼ ç»ŸGNN: åªæœ‰é“¾æ¥é¢„æµ‹æŸå¤±
loss = cross_entropy(predicted_scores, true_labels)

# æ²¡æœ‰è€ƒè™‘è§„åˆ™çš„é€»è¾‘çº¦æŸ
```

**Rule-NBFçš„åˆ›æ–°**ï¼š

```python
# Rule-NBF: å¢åŠ è§„åˆ™ä¸€è‡´æ€§æŸå¤±
def compute_consistency_loss(h, rules, knowledge_graph):
    loss = 0

    for rule in rules:
        # è§„åˆ™: r1 âˆ§ r2 â†’ r3
        r1, r2 = rule.body
        r3 = rule.head

        # æ‰¾åˆ°æ‰€æœ‰æ»¡è¶³r1 âˆ§ r2çš„è·¯å¾„
        for (x, r1, y) in KG:
            for (y, r2, z) in KG:
                # æ ¹æ®è§„åˆ™ï¼Œåº”è¯¥æœ‰(x, r3, z)

                # æ£€æŸ¥å›¾ä¸­æ˜¯å¦çœŸçš„æœ‰
                has_edge_r3 = (x, r3, z) in KG

                if not has_edge_r3:
                    # æ ¹æ®è§„åˆ™åº”è¯¥æœ‰ï¼Œä½†å›¾ä¸­æ²¡æœ‰
                    # æ¨¡å‹åº”è¯¥é¢„æµ‹å‡ºæ¥

                    # è®¡ç®—æ¨¡å‹çš„é¢„æµ‹æ¦‚ç‡
                    predicted_prob = sigmoid((h[x] @ W[r3] @ h[z]))

                    # æœŸæœ›æ¦‚ç‡ = è§„åˆ™ç½®ä¿¡åº¦
                    target_prob = rule.confidence

                    # ä¸€è‡´æ€§æŸå¤±
                    loss += (predicted_prob - target_prob) ** 2

    return loss
```

**æ•ˆæœ**ï¼š

```
ç¤ºä¾‹:
  KGä¸­æœ‰: (å¼ ä¸‰, father, æå››) å’Œ (æå››, father, èµµå…­)
  è§„åˆ™: father âˆ§ father â†’ grandfather (ç½®ä¿¡åº¦0.9)

  ä½†KGä¸­æ²¡æœ‰: (å¼ ä¸‰, grandfather, èµµå…­)

ä¸€è‡´æ€§çº¦æŸ:
  å¼ºåˆ¶æ¨¡å‹é¢„æµ‹: P(å¼ ä¸‰, grandfather, èµµå…­) â‰ˆ 0.9

ä¼˜åŠ¿:
  âœ… æ¨¡å‹å­¦ä¹ ç¬¦åˆè§„åˆ™çš„è¡¨ç¤º
  âœ… æå‡æ³›åŒ–èƒ½åŠ›ï¼ˆé¢„æµ‹ç¼ºå¤±è¾¹ï¼‰
  âœ… å¢å¼ºå¯è§£é‡Šæ€§
```

---

## ğŸ—ï¸ ä¸‰ã€å®Œæ•´æ¶æ„è®¾è®¡

### 3.1 ç³»ç»Ÿæ¶æ„å›¾

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        Rule-NBF Model                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                               â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚            ç»„ä»¶1: åŠ¨æ€è§„åˆ™é€‰æ‹©å™¨                     â”‚    â”‚
â”‚  â”‚  è¾“å…¥: Query (h, r)                                 â”‚    â”‚
â”‚  â”‚  è¾“å‡º: Top-Kç›¸å…³è§„åˆ™                                â”‚    â”‚
â”‚  â”‚                                                       â”‚    â”‚
â”‚  â”‚  [æŸ¥è¯¢ç¼–ç å™¨] â†’ [è§„åˆ™åŒ¹é…ç½‘ç»œ] â†’ [Top-Ké€‰æ‹©]        â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â”‚                           â†“                                   â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚         ç»„ä»¶2: è§„åˆ™å¼•å¯¼çš„INDICATOR                   â”‚    â”‚
â”‚  â”‚  æ ¹æ®æŸ¥è¯¢å…³ç³»å’Œè§„åˆ™åˆå§‹åŒ–                           â”‚    â”‚
â”‚  â”‚                                                       â”‚    â”‚
â”‚  â”‚  h[query_head] = INDICATOR(query_rel, rules)        â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â”‚                           â†“                                   â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚        ç»„ä»¶3: è§„åˆ™æ„ŸçŸ¥çš„è‡ªé€‚åº”é‡‡æ ·                   â”‚    â”‚
â”‚  â”‚  æ¯å±‚ä¼ æ’­å‰é‡‡æ ·å®ä½“                                 â”‚    â”‚
â”‚  â”‚                                                       â”‚    â”‚
â”‚  â”‚  for each layer:                                     â”‚    â”‚
â”‚  â”‚    - ç¡®å®šè§„åˆ™ä½“å…³ç³»                                 â”‚    â”‚
â”‚  â”‚    - åªé‡‡æ ·ç›¸å…³é‚»å±…                                 â”‚    â”‚
â”‚  â”‚    - è¯­ä¹‰æ„ŸçŸ¥æ‰“åˆ†                                   â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â”‚                           â†“                                   â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚          ç»„ä»¶4: è§„åˆ™å¼•å¯¼çš„MESSAGE                    â”‚    â”‚
â”‚  â”‚  è®¡ç®—æ¶ˆæ¯æ—¶è€ƒè™‘è§„åˆ™åŒ¹é…                             â”‚    â”‚
â”‚  â”‚                                                       â”‚    â”‚
â”‚  â”‚  message = base Ã— query_mod Ã— rule_mod              â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â”‚                           â†“                                   â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚        ç»„ä»¶5: è§„åˆ™åŠ æƒçš„AGGREGATE                    â”‚    â”‚
â”‚  â”‚  ç”¨è§„åˆ™ç½®ä¿¡åº¦åŠ æƒèšåˆç»“æœ                           â”‚    â”‚
â”‚  â”‚                                                       â”‚    â”‚
â”‚  â”‚  h_new = aggregate(messages) Ã— rule_confidence      â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â”‚                           â†“                                   â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚         ç»„ä»¶6: è§„åˆ™ä¸€è‡´æ€§çº¦æŸ                        â”‚    â”‚
â”‚  â”‚  ç¡®ä¿ç»“æœç¬¦åˆè§„åˆ™é€»è¾‘                               â”‚    â”‚
â”‚  â”‚                                                       â”‚    â”‚
â”‚  â”‚  loss = pred_loss + Î» Ã— consistency_loss            â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â”‚                                                               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 3.2 æ•°æ®æµç¤ºæ„

```
è¾“å…¥æ•°æ®:
  - Query: (å¼ ä¸‰, grandfather, ?)
  - Knowledge Graph: å…¨å›¾çš„è¾¹
  - Rules: é¢„å…ˆæŒ–æ˜çš„è§„åˆ™

â†“ æµç»å„ç»„ä»¶

ç»„ä»¶1 - è§„åˆ™é€‰æ‹©:
  è¾“å…¥: (å¼ ä¸‰, grandfather, ?)
  è¾“å‡º: [
    rule1: fatherâˆ§fatherâ†’grandfather (score: 0.95),
    rule2: motherâˆ§fatherâ†’grandfather (score: 0.88),
    rule3: sonâˆ§fatherâ†’grandfather (score: 0.82)
  ]

â†“

ç»„ä»¶2 - åˆå§‹åŒ–:
  è¾“å…¥: grandfather_emb, [rule1, rule2, rule3]
  è¾“å‡º: h[å¼ ä¸‰] = [0.2, 0.5, ..., 0.8] (200ç»´å‘é‡)

â†“

ç»„ä»¶3 - é‡‡æ · (ç¬¬1å±‚):
  è¾“å…¥: å½“å‰å®ä½“={å¼ ä¸‰}, è§„åˆ™ä½“ç¬¬1ä¸ªå…³ç³»={father, mother}
  å€™é€‰é‚»å±…: {æå››(father), ç‹äº”(father), æèŠ³(mother), èµµåˆš(colleague), ...}
  é‡‡æ ·ç­–ç•¥:
    - æå››: åŒ¹é…father â†’ é‡‡æ ·æ¦‚ç‡0.4
    - ç‹äº”: åŒ¹é…father â†’ é‡‡æ ·æ¦‚ç‡0.35
    - æèŠ³: åŒ¹é…mother â†’ é‡‡æ ·æ¦‚ç‡0.2
    - èµµåˆš: ä¸åŒ¹é… â†’ é‡‡æ ·æ¦‚ç‡0.02
  è¾“å‡º: {æå››, ç‹äº”, æèŠ³} (é‡‡æ ·3ä¸ª)

â†“

ç»„ä»¶4 - MESSAGE:
  å¯¹è¾¹(å¼ ä¸‰, father, æå››):
    base_message = W_father @ h[æå››]
    query_mod = sigmoid(W_query(grandfather_emb))
    rule_mod = 0.95 (rule1åŒ¹é…) + 0.88 (rule2åŒ¹é…)
    final_message = base Ã— query_mod Ã— (1 + rule_mod)

  å¯¹è¾¹(å¼ ä¸‰, spouse, ç‹èŠ³):
    rule_mod = 0 (ä¸åŒ¹é…ä»»ä½•è§„åˆ™)
    final_message â‰ˆ 0 (è¢«è¿‡æ»¤)

â†“

ç»„ä»¶5 - AGGREGATE:
  messages = [msg_æå››, msg_ç‹äº”, msg_æèŠ³]
  overall_confidence = (0.95 + 0.88 + 0.82) / 3 = 0.88
  h[å¼ ä¸‰]_new = sum(messages) Ã— 0.88

â†“

... ç»§ç»­ç¬¬2å±‚ã€ç¬¬3å±‚ ...

â†“

ç»„ä»¶6 - ä¸€è‡´æ€§çº¦æŸ:
  æ£€æŸ¥: å¦‚æœå­˜åœ¨ å¼ ä¸‰â†’fatherâ†’æå››â†’fatherâ†’èµµå…­
  æœŸæœ›: P(å¼ ä¸‰, grandfather, èµµå…­) â‰ˆ 0.95
  æŸå¤±: |predicted_prob - 0.95|^2

â†“

è¾“å‡º:
  - Scores: [å¼ ä¸‰â†’èµµå…­: 0.92, å¼ ä¸‰â†’å­™ä¸ƒ: 0.85, ...]
  - Loss: pred_loss + Î» Ã— consistency_loss
```

---

## ğŸ“ å››ã€è¯¦ç»†å®ä¾‹æ¼”ç¤º

### 4.1 å®Œæ•´ç¤ºä¾‹åœºæ™¯

**çŸ¥è¯†å›¾è°±**ï¼š

```
å®ä½“:
  å¼ ä¸‰ (id=0)
  æå›› (id=1, å¼ ä¸‰çš„å„¿å­)
  ç‹äº” (id=2, å¼ ä¸‰çš„å„¿å­)
  æèŠ³ (id=3, å¼ ä¸‰çš„å¦»å­)
  èµµå…­ (id=4, æå››çš„å„¿å­)
  å­™ä¸ƒ (id=5, ç‹äº”çš„å„¿å­)
  èµµåˆš (id=6, å¼ ä¸‰çš„åŒäº‹)

è¾¹:
  (å¼ ä¸‰, father, æå››)
  (å¼ ä¸‰, father, ç‹äº”)
  (å¼ ä¸‰, spouse, æèŠ³)
  (å¼ ä¸‰, colleague, èµµåˆš)
  (æå››, father, èµµå…­)
  (ç‹äº”, father, å­™ä¸ƒ)
  (æèŠ³, mother, æå››)
  (æèŠ³, mother, ç‹äº”)
```

**è§„åˆ™åº“**ï¼ˆé¢„å…ˆæŒ–æ˜ï¼‰ï¼š

```
Rule 1: father âˆ§ father â†’ grandfather
  - ç½®ä¿¡åº¦: 0.95
  - æ”¯æŒåº¦: 1000

Rule 2: mother âˆ§ father â†’ grandfather
  - ç½®ä¿¡åº¦: 0.88
  - æ”¯æŒåº¦: 800

Rule 3: son âˆ§ father â†’ grandfather
  - ç½®ä¿¡åº¦: 0.82
  - æ”¯æŒåº¦: 600

... (è¿˜æœ‰100å¤šæ¡å…¶ä»–è§„åˆ™)
```

**æŸ¥è¯¢**ï¼š

```
Query: (å¼ ä¸‰, grandfather, ?)
æœŸæœ›ç­”æ¡ˆ: èµµå…­, å­™ä¸ƒ
```

### 4.2 é€æ­¥æ‰§è¡Œè¿‡ç¨‹

#### æ­¥éª¤1: åŠ¨æ€è§„åˆ™é€‰æ‹©

```python
# è¾“å…¥
query_head = å¼ ä¸‰ (id=0)
query_relation = grandfather (id=15)

# è§„åˆ™é€‰æ‹©å™¨å·¥ä½œæµç¨‹
all_rules_for_grandfather = [
    Rule(id=1, body=[father, father], head=grandfather, conf=0.95),
    Rule(id=2, body=[mother, father], head=grandfather, conf=0.88),
    Rule(id=3, body=[son, father], head=grandfather, conf=0.82),
    Rule(id=25, body=[spouse, parent], head=grandfather, conf=0.45),
    Rule(id=67, body=[colleague, friend], head=grandfather, conf=0.05),
    ... (å…±120æ¡)
]

# æŸ¥è¯¢ç¼–ç 
h_query = query_encoder([
    entity_embedding[å¼ ä¸‰],  # [200]
    relation_embedding[grandfather]  # [200]
])  # â†’ [200]

# å¯¹æ¯æ¡è§„åˆ™è®¡ç®—åŒ¹é…å¾—åˆ†
for rule in all_rules_for_grandfather:
    # è§„åˆ™ç¼–ç ï¼ˆç¼–ç è§„åˆ™ä½“åºåˆ—ï¼‰
    h_rule = rule_encoder([
        relation_embedding[r] for r in rule.body
    ])  # â†’ [200]

    # åŒ¹é…å¾—åˆ†
    score = MLP([h_query, h_rule])  # â†’ scalar
    rule.selection_score = score

# Top-Ké€‰æ‹©
selected_rules = top_k(all_rules_for_grandfather, k=5)

# è¾“å‡º
selected_rules = [
    Rule(id=1, score=0.98),  # father âˆ§ father
    Rule(id=2, score=0.95),  # mother âˆ§ father
    Rule(id=3, score=0.92),  # son âˆ§ father
    Rule(id=8, score=0.78),  # parent âˆ§ father
    Rule(id=12, score=0.65)  # sibling âˆ§ parent
]
```

**ä¸ºä»€ä¹ˆè¿™5æ¡è¢«é€‰ä¸­**ï¼š

```
Rule 1 (father âˆ§ father):
  - è§„åˆ™ä½“ç®€å•ï¼Œä¸grandfatherè¯­ä¹‰æœ€æ¥è¿‘
  - é«˜ç½®ä¿¡åº¦0.95
  â†’ é€‰æ‹©å¾—åˆ†: 0.98

Rule 2 (mother âˆ§ father):
  - ä¹Ÿæ˜¯2è·³è§„åˆ™ï¼Œè¯­ä¹‰ç›¸å…³
  - ç½®ä¿¡åº¦0.88
  â†’ é€‰æ‹©å¾—åˆ†: 0.95

Rule 67 (colleague âˆ§ friend):
  - è§„åˆ™ä½“ä¸grandfatherå®Œå…¨æ— å…³
  - ä½ç½®ä¿¡åº¦0.05
  â†’ é€‰æ‹©å¾—åˆ†: 0.02 (è¢«è¿‡æ»¤)
```

#### æ­¥éª¤2: è§„åˆ™å¼•å¯¼çš„åˆå§‹åŒ–

```python
# è¾“å…¥
query_relation_emb = relation_embedding[grandfather]  # [200]
selected_rules = [Rule1, Rule2, Rule3, Rule8, Rule12]

# INDICATORå‡½æ•°
def indicator(query_rel_emb, rules):
    # 1. ç¼–ç æŸ¥è¯¢å…³ç³»
    h_query = W_query(query_rel_emb)  # [200]

    # 2. ç¼–ç è§„åˆ™é›†åˆ
    rule_embs = [rule_embedding[r.id] for r in rules]  # [5, 200]

    # 3. æ³¨æ„åŠ›èšåˆ
    # Query: æŸ¥è¯¢å…³ç³»
    # Key/Value: è§„åˆ™åµŒå…¥
    h_rules_agg = attention(
        query=h_query,  # [1, 200]
        key=rule_embs,  # [5, 200]
        value=rule_embs
    )  # â†’ [200]

    # æ³¨æ„åŠ›æƒé‡:
    #   Rule1: 0.45 (æœ€ç›¸å…³)
    #   Rule2: 0.30
    #   Rule3: 0.15
    #   Rule8: 0.07
    #   Rule12: 0.03

    # 4. èåˆ
    h_init = MLP([h_query, h_rules_agg])  # [200]

    return h_init

# åˆå§‹åŒ–
h = zeros(num_entities=7, dim=200)
h[å¼ ä¸‰] = indicator(query_relation_emb, selected_rules)
# h[å¼ ä¸‰] = [0.15, 0.28, -0.13, ..., 0.42] (200ç»´)

# å…¶ä»–å®ä½“åˆå§‹ä¸º0
h[æå››] = [0, 0, ..., 0]
h[ç‹äº”] = [0, 0, ..., 0]
...
```

**åˆå§‹åŒ–çš„æ„ä¹‰**ï¼š

```
ä¼ ç»ŸGNN:
  h[å¼ ä¸‰] = entity_embedding[å¼ ä¸‰]
  â†’ åªæ˜¯ä¸€ä¸ªå›ºå®šçš„å‘é‡
  â†’ ä¸çŸ¥é“è¦æ‰¾ä»€ä¹ˆ

NBFNet:
  h[å¼ ä¸‰] = W(grandfather_emb)
  â†’ çŸ¥é“è¦æ‰¾grandfather
  â†’ ä½†ä¸çŸ¥é“å…·ä½“è·¯å¾„

Rule-NBF:
  h[å¼ ä¸‰] = INDICATOR(grandfather, [Rule1, Rule2, ...])
  â†’ çŸ¥é“è¦æ‰¾grandfather
  â†’ çŸ¥é“åº”è¯¥æ²¿father/motherè¾¹
  â†’ çŸ¥é“è§„åˆ™çš„é‡è¦æ€§æ’åº
  â†’ ä¸ºåç»­ä¼ æ’­æä¾›äº†å¼ºå…ˆéªŒ
```

#### æ­¥éª¤3: ç¬¬1å±‚ä¼ æ’­

##### 3.1 è§„åˆ™æ„ŸçŸ¥é‡‡æ ·

```python
# å½“å‰çŠ¶æ€
current_entities = {å¼ ä¸‰}
current_layer = 0

# ç¡®å®šæœ¬å±‚åº”è¯¥ä¼ æ’­çš„å…³ç³»ï¼ˆä»è§„åˆ™ä½“ï¼‰
layer_relations = set()
for rule in selected_rules:
    if len(rule.body) > 0:
        layer_relations.add(rule.body[0])  # ç¬¬1ä¸ªå…³ç³»

# layer_relations = {father, mother, son, parent}

# è·å–å€™é€‰é‚»å±…ï¼ˆåªè€ƒè™‘è¿™äº›å…³ç³»ï¼‰
candidates = []
for entity in current_entities:
    for neighbor in KG.neighbors(entity):
        edge_relation = KG.get_edge_relation(entity, neighbor)
        if edge_relation in layer_relations:
            candidates.append((neighbor, edge_relation))

# candidates = [
#   (æå››, father),
#   (ç‹äº”, father),
#   (æèŠ³, spouse),  # spouseä¸åœ¨layer_relationsï¼Œè¢«è¿‡æ»¤
#   (èµµåˆš, colleague)  # colleagueä¸åœ¨layer_relationsï¼Œè¢«è¿‡æ»¤
# ]

# å®é™…candidates = [(æå››, father), (ç‹äº”, father)]
# æ³¨æ„: æèŠ³å’Œèµµåˆšå› ä¸ºè¾¹å…³ç³»ä¸åŒ¹é…ï¼Œç›´æ¥è¢«è¿‡æ»¤

# å¦‚æœè¿˜æœ‰motherè¾¹ï¼Œä¹Ÿä¼šè¢«åŒ…å«
# å‡è®¾è¿˜æœ‰: (æèŠ³_mother, mother) é€šè¿‡å…¶ä»–è·¯å¾„

# å¯¹æ¯ä¸ªå€™é€‰è®¡ç®—é‡‡æ ·æ¦‚ç‡
sampling_probs = []
for (neighbor, edge_relation) in candidates:
    # 1. è¯­ä¹‰å¾—åˆ†
    semantic_score = semantic_scorer(
        h[å¼ ä¸‰],
        entity_embedding[neighbor],
        relation_embedding[edge_relation],
        relation_embedding[grandfather]
    )
    # æå››: 0.6, ç‹äº”: 0.55

    # 2. è§„åˆ™åŒ¹é…å¾—åˆ†
    rule_match_score = 0
    for rule in selected_rules:
        if rule.body[0] == edge_relation:  # ç¬¬1ä¸ªå…³ç³»åŒ¹é…
            rule_match_score += rule.confidence

    # å¯¹äºæå››(father):
    #   Rule1 (fatherâˆ§father): +0.95
    #   Rule2 (motherâˆ§father): mother != father, +0
    #   â†’ rule_match_score = 0.95

    # 3. ç»¼åˆå¾—åˆ†
    total_score = semantic_score + Î» * rule_match_score
    # æå››: 0.6 + 0.3 * 0.95 = 0.885
    # ç‹äº”: 0.55 + 0.3 * 0.95 = 0.835

    sampling_probs.append(total_score)

# Softmaxå½’ä¸€åŒ–
sampling_probs = softmax([0.885, 0.835])
# â†’ [0.52, 0.48]

# é‡‡æ ·ï¼ˆå‡è®¾budget=2ï¼Œå…¨é€‰ï¼‰
sampled_entities = {æå››, ç‹äº”}
```

**é‡‡æ ·çš„æ•ˆæœ**ï¼š

```
å…¨å›¾é‚»å±…: {æå››, ç‹äº”, æèŠ³, èµµåˆš}

è§„åˆ™è¿‡æ»¤å: {æå››, ç‹äº”}
  - æèŠ³(spouse): ä¸åœ¨è§„åˆ™ä½“ç¬¬1ä¸ªå…³ç³» â†’ è¿‡æ»¤
  - èµµåˆš(colleague): ä¸åœ¨è§„åˆ™ä½“ç¬¬1ä¸ªå…³ç³» â†’ è¿‡æ»¤

é‡‡æ ·ç»“æœ: {æå››, ç‹äº”}
  - éƒ½åŒ¹é…è§„åˆ™
  - éƒ½æœ‰é«˜é‡‡æ ·æ¦‚ç‡

æ•ˆç‡æå‡:
  åŸæœ¬éœ€è¦å¤„ç†4ä¸ªé‚»å±…
  ç°åœ¨åªéœ€è¦å¤„ç†2ä¸ªé‚»å±…
  â†’ 50%è®¡ç®—èŠ‚çœ
```

##### 3.2 è§„åˆ™å¼•å¯¼MESSAGE

```python
# å¯¹æ¯æ¡è¾¹è®¡ç®—æ¶ˆæ¯

# è¾¹1: (å¼ ä¸‰, father, æå››)
edge_relation = father
u, v = å¼ ä¸‰, æå››

# åŸºç¡€æ¶ˆæ¯
message_base = W_relation[father] @ h[æå››]
# [200, 200] @ [200] â†’ [200]

# æŸ¥è¯¢è°ƒåˆ¶ï¼ˆä»NBFNetï¼‰
query_modulation = sigmoid(W_query(relation_embedding[grandfather]))
# â†’ [200]ï¼Œå…ƒç´ å–å€¼åœ¨[0,1]

# è§„åˆ™è°ƒåˆ¶ï¼ˆåˆ›æ–°ï¼‰
rule_modulation = 0
for rule in selected_rules:
    if len(rule.body) > current_layer:
        expected_relation = rule.body[current_layer]
        if edge_relation == expected_relation:
            # åŒ¹é…
            h_rule = rule_embedding[rule.id]
            rule_mod = sigmoid(W_rule(h_rule))  # [200]
            rule_modulation += rule.confidence * rule_mod

# å¯¹äºfatherè¾¹:
#   Rule1 (fatherâˆ§father): expected=father, åŒ¹é…, +0.95*[...]
#   Rule2 (motherâˆ§father): expected=mother, ä¸åŒ¹é…, +0
#   Rule8 (parentâˆ§father): expected=parent, ä¸åŒ¹é…, +0
# â†’ rule_modulation â‰ˆ 0.95 * sigmoid(W_rule(rule1_emb))

# æœ€ç»ˆæ¶ˆæ¯
message = message_base * query_modulation * (1 + rule_modulation)
# â†’ [200]

# è¾¹2: (å¼ ä¸‰, father, ç‹äº”)
# åŒæ ·çš„è®¡ç®—ï¼Œç±»ä¼¼çš„ç»“æœ

# å¦‚æœæœ‰è¾¹3: (å¼ ä¸‰, spouse, æèŠ³)ï¼ˆè¢«è¿‡æ»¤ï¼Œä¸è®¡ç®—ï¼‰
# edge_relation = spouse
# rule_modulation = 0 (ä¸åŒ¹é…ä»»ä½•è§„åˆ™)
# message â‰ˆ message_base * query_mod * 1 (å¾ˆå°)
```

**æ¶ˆæ¯çš„å¯¹æ¯”**ï¼š

```
ä¼ ç»ŸR-GCN:
  message_father = W_father @ h[æå››]
  message_spouse = W_spouse @ h[æèŠ³]
  â†’ æ‰€æœ‰è¾¹åŒç­‰å¯¹å¾…

NBFNet:
  message_father = W_father @ h[æå››] * sigmoid(W_q(grandfather))
  message_spouse = W_spouse @ h[æèŠ³] * sigmoid(W_q(grandfather))
  â†’ æŸ¥è¯¢è°ƒåˆ¶ï¼Œä½†fatherå’Œspouseçš„è°ƒåˆ¶å¯èƒ½å·®ä¸å¤š

Rule-NBF:
  message_father = base * query_mod * (1 + 0.95 * rule_mod)
                 â‰ˆ base * query_mod * 1.95  (å‡ ä¹ç¿»å€)

  message_spouse = base * query_mod * (1 + 0 * rule_mod)
                 â‰ˆ base * query_mod * 1.0

  â†’ fatherè¾¹çš„æ¶ˆæ¯å‡ ä¹æ˜¯spouseè¾¹çš„2å€
  â†’ è§„åˆ™æ˜¾å¼å¢å¼ºäº†ç›¸å…³è¾¹çš„æ¶ˆæ¯
```

##### 3.3 è§„åˆ™åŠ æƒAGGREGATE

```python
# æ”¶é›†æ‰€æœ‰æ¶ˆæ¯
messages = {
    æå››: message_from_æå››,  # [200]
    ç‹äº”: message_from_ç‹äº”   # [200]
}

# èšåˆ
h_å¼ ä¸‰_aggregated = messages[æå››] + messages[ç‹äº”]  # [200]

# è§„åˆ™ç½®ä¿¡åº¦åŠ æƒ
overall_confidence = mean([rule.confidence for rule in selected_rules])
# = (0.95 + 0.88 + 0.82 + ...) / 5 = 0.82

h_å¼ ä¸‰_new = h_å¼ ä¸‰_aggregated * overall_confidence
# = h_å¼ ä¸‰_aggregated * 0.82

# Layer Normalization
h_å¼ ä¸‰_new = layer_norm(h_å¼ ä¸‰_new)

# æ›´æ–°
h[å¼ ä¸‰] = h_å¼ ä¸‰_new
```

**åŠ æƒçš„æ„ä¹‰**ï¼š

```
åœºæ™¯1: é«˜è´¨é‡è§„åˆ™
  selected_rules éƒ½æ˜¯é«˜ç½®ä¿¡åº¦è§„åˆ™ (0.9+)
  overall_confidence = 0.9
  h_new = h_aggregated * 0.9
  â†’ æ¨¡å‹ç›¸ä¿¡è¿™ä¸ªèšåˆç»“æœ

åœºæ™¯2: ä½è´¨é‡è§„åˆ™
  selected_rules éƒ½æ˜¯ä½ç½®ä¿¡åº¦è§„åˆ™ (0.3-)
  overall_confidence = 0.3
  h_new = h_aggregated * 0.3
  â†’ æ¨¡å‹é™ä½è¿™ä¸ªèšåˆç»“æœçš„æƒé‡

æ•ˆæœ: è‡ªåŠ¨è°ƒèŠ‚ä¸åŒè§„åˆ™çš„å½±å“åŠ›
```

#### æ­¥éª¤4: ç¬¬2å±‚ä¼ æ’­

##### 4.1 è§„åˆ™æ„ŸçŸ¥é‡‡æ ·

```python
# å½“å‰çŠ¶æ€
current_entities = {æå››, ç‹äº”}
current_layer = 1

# ç¡®å®šæœ¬å±‚åº”è¯¥ä¼ æ’­çš„å…³ç³»ï¼ˆè§„åˆ™ä½“ç¬¬2ä¸ªå…³ç³»ï¼‰
layer_relations = set()
for rule in selected_rules:
    if len(rule.body) > 1:
        layer_relations.add(rule.body[1])  # ç¬¬2ä¸ªå…³ç³»

# å¯¹äºRule1 (fatherâˆ§father): body[1] = father
# å¯¹äºRule2 (motherâˆ§father): body[1] = father
# layer_relations = {father}

# è·å–å€™é€‰é‚»å±…
candidates = []
for entity in current_entities:  # æå››, ç‹äº”
    for neighbor in KG.neighbors(entity):
        edge_relation = KG.get_edge_relation(entity, neighbor)
        if edge_relation in layer_relations:
            candidates.append((entity, neighbor, edge_relation))

# å¯¹äºæå››:
#   é‚»å±…: èµµå…­(father), ...
#   èµµå…­çš„è¾¹å…³ç³»æ˜¯father â†’ åŒ¹é… â†’ åŠ å…¥candidates

# å¯¹äºç‹äº”:
#   é‚»å±…: å­™ä¸ƒ(father), ...
#   å­™ä¸ƒçš„è¾¹å…³ç³»æ˜¯father â†’ åŒ¹é… â†’ åŠ å…¥candidates

# candidates = [(æå››, èµµå…­, father), (ç‹äº”, å­™ä¸ƒ, father)]

# é‡‡æ ·ï¼ˆéƒ½ä¿ç•™ï¼‰
sampled_entities = {èµµå…­, å­™ä¸ƒ}
```

##### 4.2 è§„åˆ™å¼•å¯¼MESSAGE

```python
# è¾¹: (æå››, father, èµµå…­)
message_base = W_father @ h[èµµå…­]

query_modulation = sigmoid(W_query(grandfather_emb))

# è§„åˆ™è°ƒåˆ¶ï¼ˆç¬¬2å±‚ï¼‰
rule_modulation = 0
for rule in selected_rules:
    if len(rule.body) > 1 and rule.body[1] == father:
        # Rule1 (fatherâˆ§father): åŒ¹é…
        rule_modulation += 0.95 * sigmoid(W_rule(rule1_emb))

message = message_base * query_modulation * (1 + rule_modulation)

# ç±»ä¼¼åœ°è®¡ç®— (ç‹äº”, father, å­™ä¸ƒ) çš„æ¶ˆæ¯
```

##### 4.3 èšåˆ

```python
# æå››çš„æ–°è¡¨ç¤º
h[æå››] = aggregate(message_from_èµµå…­) * overall_confidence

# ç‹äº”çš„æ–°è¡¨ç¤º
h[ç‹äº”] = aggregate(message_from_å­™ä¸ƒ) * overall_confidence
```

**ç¬¬2å±‚å®Œæˆåçš„çŠ¶æ€**ï¼š

```
h[å¼ ä¸‰]: åŒ…å«äº†1è·³ä¿¡æ¯ï¼ˆä»æå››ã€ç‹äº”ï¼‰
h[æå››]: åŒ…å«äº†2è·³ä¿¡æ¯ï¼ˆä»å¼ ä¸‰åˆ°èµµå…­ï¼‰
h[ç‹äº”]: åŒ…å«äº†2è·³ä¿¡æ¯ï¼ˆä»å¼ ä¸‰åˆ°å­™ä¸ƒï¼‰
h[èµµå…­]: åŒ…å«äº†2è·³è·¯å¾„ å¼ ä¸‰â†’æå››â†’èµµå…­ çš„ä¿¡æ¯
h[å­™ä¸ƒ]: åŒ…å«äº†2è·³è·¯å¾„ å¼ ä¸‰â†’ç‹äº”â†’å­™ä¸ƒ çš„ä¿¡æ¯
```

#### æ­¥éª¤5: è§„åˆ™ä¸€è‡´æ€§çº¦æŸ

```python
def compute_consistency_loss(h, selected_rules, KG):
    loss = 0

    for rule in selected_rules:
        # Rule1: father âˆ§ father â†’ grandfather
        r1, r2 = father, father
        r3 = grandfather

        # æ‰¾åˆ°æ‰€æœ‰æ»¡è¶³ father âˆ§ father çš„è·¯å¾„
        for (x, r1, y) in KG.edges:
            if r1 == father:
                for (y, r2, z) in KG.edges:
                    if r2 == father:
                        # æ‰¾åˆ°è·¯å¾„: x â†’ y â†’ z
                        # ä¾‹å¦‚: å¼ ä¸‰ â†’ æå›› â†’ èµµå…­

                        # æ£€æŸ¥æ˜¯å¦æœ‰è¾¹ (x, grandfather, z)
                        has_edge = (x, grandfather, z) in KG

                        if not has_edge:
                            # åº”è¯¥æœ‰ï¼Œä½†æ²¡æœ‰
                            # è®¡ç®—æ¨¡å‹é¢„æµ‹æ¦‚ç‡
                            predicted_prob = sigmoid(
                                h[x] @ W_grandfather @ h[z]
                            )

                            # ç›®æ ‡æ¦‚ç‡ = è§„åˆ™ç½®ä¿¡åº¦
                            target_prob = 0.95

                            # æŸå¤±
                            loss += (predicted_prob - target_prob) ** 2

    return loss
```

**å…·ä½“è®¡ç®—**ï¼š

```
è·¯å¾„: å¼ ä¸‰ â†’ æå›› â†’ èµµå…­
è§„åˆ™: father âˆ§ father â†’ grandfather (0.95)

æ£€æŸ¥: KGä¸­æ²¡æœ‰ (å¼ ä¸‰, grandfather, èµµå…­)

è®¡ç®—:
  predicted_prob = sigmoid(h[å¼ ä¸‰] @ W_grandfather @ h[èµµå…­])
  å‡è®¾ = 0.87

  target_prob = 0.95

  loss = (0.87 - 0.95)^2 = 0.0064

è·¯å¾„: å¼ ä¸‰ â†’ ç‹äº” â†’ å­™ä¸ƒ
è§„åˆ™: father âˆ§ father â†’ grandfather (0.95)

æ£€æŸ¥: KGä¸­æ²¡æœ‰ (å¼ ä¸‰, grandfather, å­™ä¸ƒ)

è®¡ç®—:
  predicted_prob = sigmoid(h[å¼ ä¸‰] @ W_grandfather @ h[å­™ä¸ƒ])
  å‡è®¾ = 0.91

  target_prob = 0.95

  loss = (0.91 - 0.95)^2 = 0.0016

æ€»ä¸€è‡´æ€§æŸå¤± = 0.0064 + 0.0016 = 0.008
```

**ä¸€è‡´æ€§çº¦æŸçš„æ•ˆæœ**ï¼š

```
æ²¡æœ‰ä¸€è‡´æ€§çº¦æŸ:
  æ¨¡å‹å¯èƒ½é¢„æµ‹: P(å¼ ä¸‰, grandfather, èµµå…­) = 0.65
  â†’ ä¸ç¬¦åˆè§„åˆ™çš„é«˜ç½®ä¿¡åº¦

æœ‰ä¸€è‡´æ€§çº¦æŸ:
  æ¨¡å‹è¢«å¼ºåˆ¶é¢„æµ‹: P(å¼ ä¸‰, grandfather, èµµå…­) â‰ˆ 0.95
  â†’ ç¬¦åˆè§„åˆ™é€»è¾‘
  â†’ æå‡æ³›åŒ–èƒ½åŠ›
```

#### æ­¥éª¤6: æœ€ç»ˆé¢„æµ‹

```python
# å¯¹æ‰€æœ‰å®ä½“æ‰“åˆ†
scores = []
for entity in all_entities:
    # æ–¹æ³•1: å†…ç§¯
    score = (h[å¼ ä¸‰] * h[entity]).sum()

    # æ–¹æ³•2: MLP
    score = MLP([h[å¼ ä¸‰], h[entity]])

    scores.append(score)

# scores = [
#   å¼ ä¸‰: -inf (è‡ªå·±)
#   æå››: 0.32 (å„¿å­ï¼Œä¸æ˜¯å­™å­)
#   ç‹äº”: 0.29 (å„¿å­ï¼Œä¸æ˜¯å­™å­)
#   æèŠ³: 0.15 (å¦»å­ï¼Œä¸æ˜¯å­™å­)
#   èµµå…­: 0.92 âœ… (å­™å­ï¼Œé«˜åˆ†)
#   å­™ä¸ƒ: 0.88 âœ… (å­™å­ï¼Œé«˜åˆ†)
#   èµµåˆš: 0.05 (åŒäº‹ï¼Œä¸æ˜¯å­™å­)
# ]

# æ’åº
sorted_entities = argsort(scores, descending=True)
# â†’ [èµµå…­, å­™ä¸ƒ, æå››, ç‹äº”, æèŠ³, èµµåˆš, å¼ ä¸‰]

# Top-2é¢„æµ‹
predictions = [èµµå…­, å­™ä¸ƒ]  # æ­£ç¡®ï¼
```

**ä¸ºä»€ä¹ˆèµµå…­å’Œå­™ä¸ƒå¾—åˆ†é«˜ï¼Ÿ**

```
èµµå…­çš„è¡¨ç¤º h[èµµå…­]:
  - ç¬¬2å±‚ä¼ æ’­æ—¶æ›´æ–°
  - åŒ…å«äº†è·¯å¾„ å¼ ä¸‰â†’æå››â†’èµµå…­ çš„ä¿¡æ¯
  - è¿™ä¸ªè·¯å¾„å®Œå…¨åŒ¹é…è§„åˆ™ fatherâˆ§fatherâ†’grandfather
  - è§„åˆ™ç½®ä¿¡åº¦0.95 â†’ é«˜æƒé‡
  â†’ ä¸h[å¼ ä¸‰]çš„å†…ç§¯å¾ˆé«˜

å­™ä¸ƒçš„è¡¨ç¤º h[å­™ä¸ƒ]:
  - åŒæ ·åŒ…å«äº†è·¯å¾„ å¼ ä¸‰â†’ç‹äº”â†’å­™ä¸ƒ
  - åŒæ ·åŒ¹é…è§„åˆ™
  â†’ é«˜åˆ†

æå››çš„è¡¨ç¤º h[æå››]:
  - åªåŒ…å«äº†1è·³è·¯å¾„ å¼ ä¸‰â†’æå››
  - ä¸å®Œæ•´åŒ¹é…2è·³è§„åˆ™
  â†’ ä¸­ç­‰åˆ†æ•°

èµµåˆšçš„è¡¨ç¤º h[èµµåˆš]:
  - æ²¡æœ‰è¢«ä¼ æ’­åˆ°ï¼ˆcolleagueè¾¹è¢«è¿‡æ»¤ï¼‰
  - ä¿æŒåˆå§‹å€¼ï¼ˆå‡ ä¹ä¸º0ï¼‰
  â†’ å¾ˆä½åˆ†æ•°
```

### 4.3 å®Œæ•´æµç¨‹æ€»ç»“

```
Query: (å¼ ä¸‰, grandfather, ?)

ç¬¬0æ­¥: è§„åˆ™é€‰æ‹©
  â†’ é€‰ä¸­5æ¡é«˜åˆ†è§„åˆ™

ç¬¬1æ­¥: åˆå§‹åŒ–
  â†’ h[å¼ ä¸‰] = INDICATOR(grandfather, rules)
  â†’ èåˆæŸ¥è¯¢å’Œè§„åˆ™ä¿¡æ¯

ç¬¬2æ­¥: ç¬¬1å±‚ä¼ æ’­
  â†’ åªä¼ æ’­åˆ°æå››ã€ç‹äº”ï¼ˆfatherè¾¹ï¼‰
  â†’ æèŠ³ã€èµµåˆšè¢«è¿‡æ»¤ï¼ˆspouseã€colleagueè¾¹ä¸åŒ¹é…è§„åˆ™ï¼‰
  â†’ æ¶ˆæ¯è¢«è§„åˆ™å¢å¼ºï¼ˆfatherè¾¹æƒé‡Ã—1.95ï¼‰

ç¬¬3æ­¥: ç¬¬2å±‚ä¼ æ’­
  â†’ åªä¼ æ’­åˆ°èµµå…­ã€å­™ä¸ƒï¼ˆfatherè¾¹ï¼‰
  â†’ å®Œæˆ2è·³è·¯å¾„ fatherâˆ§father

ç¬¬4æ­¥: ä¸€è‡´æ€§çº¦æŸ
  â†’ å¼ºåˆ¶ P(å¼ ä¸‰, grandfather, èµµå…­) â‰ˆ 0.95
  â†’ æå‡æ³›åŒ–èƒ½åŠ›

ç¬¬5æ­¥: é¢„æµ‹
  â†’ èµµå…­ã€å­™ä¸ƒå¾—åˆ†æœ€é«˜
  â†’ æ­£ç¡®é¢„æµ‹ï¼

æ•ˆç‡:
  å…¨å›¾ä¼ æ’­: éœ€è¦è®¿é—® 1 + 4 + 16 = 21ä¸ªå®ä½“
  Rule-NBF: åªè®¿é—® 1 + 2 + 2 = 5ä¸ªå®ä½“
  â†’ åŠ é€Ÿæ¯”: 21 / 5 = 4.2å€

å‡†ç¡®æ€§:
  æ²¡æœ‰è§„åˆ™: å¯èƒ½ä¼ æ’­åˆ°èµµåˆšã€æèŠ³ç­‰æ— å…³å®ä½“ï¼Œå¼•å…¥å™ªå£°
  Rule-NBF: åªä¼ æ’­åˆ°ç›¸å…³å®ä½“ï¼Œç²¾å‡†å®šä½ç­”æ¡ˆ
```

---

## ğŸ’» äº”ã€å®Œæ•´ä»£ç å®ç°

### 5.1 æ ¸å¿ƒæ¨¡å‹ä»£ç 

```python
import torch
import torch.nn as nn
import torch.nn.functional as F
from torch_scatter import scatter_add

class RuleNBF(nn.Module):
    """
    Rule-enhanced Neural Bellman-Ford Network

    å®Œæ•´èåˆ:
    - NBFNetçš„Bellman-Fordæ¡†æ¶
    - RulEçš„è§„åˆ™å…ˆéªŒçŸ¥è¯†
    - AdaPropçš„è‡ªé€‚åº”é‡‡æ ·
    """

    def __init__(self, num_entities, num_relations, rules,
                 hidden_dim=200, num_layers=3, sample_budget=100):
        super().__init__()

        self.num_entities = num_entities
        self.num_relations = num_relations
        self.hidden_dim = hidden_dim
        self.num_layers = num_layers
        self.sample_budget = sample_budget

        # åµŒå…¥å±‚
        self.entity_embedding = nn.Embedding(num_entities, hidden_dim)
        self.relation_embedding = nn.Embedding(num_relations, hidden_dim)
        self.rule_embedding = nn.Embedding(len(rules), hidden_dim)

        # è§„åˆ™ä¿¡æ¯
        self.rules = rules
        self.rule_index = self._build_rule_index(rules)

        # ç»„ä»¶1: åŠ¨æ€è§„åˆ™é€‰æ‹©å™¨
        self.rule_selector = DynamicRuleSelector(hidden_dim, len(rules))

        # ç»„ä»¶2: è§„åˆ™å¼•å¯¼çš„INDICATOR
        self.indicator = RuleGuidedIndicator(hidden_dim)

        # ç»„ä»¶3-5: æ¯å±‚çš„ä¼ æ’­ç»„ä»¶
        self.message_layers = nn.ModuleList([
            RuleGuidedMessage(hidden_dim, num_relations)
            for _ in range(num_layers)
        ])

        self.aggregate_layers = nn.ModuleList([
            RuleWeightedAggregate(hidden_dim)
            for _ in range(num_layers)
        ])

        # ç»„ä»¶6: è§„åˆ™ä¸€è‡´æ€§å±‚
        self.consistency_layer = RuleConsistencyLayer(hidden_dim)

        # é¢„æµ‹å±‚
        self.scorer = nn.Sequential(
            nn.Linear(hidden_dim * 2, hidden_dim),
            nn.ReLU(),
            nn.Dropout(0.1),
            nn.Linear(hidden_dim, 1)
        )

        self._init_weights()

    def _init_weights(self):
        """åˆå§‹åŒ–æƒé‡"""
        nn.init.xavier_uniform_(self.entity_embedding.weight)
        nn.init.xavier_uniform_(self.relation_embedding.weight)
        nn.init.xavier_uniform_(self.rule_embedding.weight)

    def _build_rule_index(self, rules):
        """æ„å»ºè§„åˆ™ç´¢å¼•ï¼šrelation â†’ rules"""
        rule_index = {}
        for rule in rules:
            if rule.head not in rule_index:
                rule_index[rule.head] = []
            rule_index[rule.head].append(rule)
        return rule_index

    def forward(self, query_head, query_relation, edge_index, edge_type,
                return_details=False):
        """
        å‰å‘ä¼ æ’­

        Args:
            query_head: æŸ¥è¯¢å¤´å®ä½“ (int)
            query_relation: æŸ¥è¯¢å…³ç³» (int)
            edge_index: å…¨å›¾è¾¹ç´¢å¼• [2, num_edges]
            edge_type: è¾¹ç±»å‹ [num_edges]
            return_details: æ˜¯å¦è¿”å›è¯¦ç»†ä¿¡æ¯

        Returns:
            scores: æ‰€æœ‰å®ä½“çš„å¾—åˆ† [num_entities]
            consistency_loss: è§„åˆ™ä¸€è‡´æ€§æŸå¤±
            details: (å¯é€‰) è¯¦ç»†ä¿¡æ¯
        """
        device = edge_index.device

        # === æ­¥éª¤1: åŠ¨æ€è§„åˆ™é€‰æ‹© ===
        relevant_rules, rule_scores = self.rule_selector(
            query_head,
            query_relation,
            self.rules,
            self.entity_embedding,
            self.relation_embedding,
            self.rule_embedding,
            top_k=10
        )

        # === æ­¥éª¤2: è§„åˆ™å¼•å¯¼çš„åˆå§‹åŒ– ===
        h = torch.zeros(self.num_entities, self.hidden_dim, device=device)
        h[query_head] = self.indicator(
            self.relation_embedding(torch.tensor(query_relation, device=device)),
            relevant_rules,
            self.rule_embedding
        )

        # === æ­¥éª¤3-4: å¤šå±‚è§„åˆ™æ„ŸçŸ¥ä¼ æ’­ ===
        active_entities = {query_head}
        sampled_paths = [] if return_details else None

        for layer_idx in range(self.num_layers):
            # 3.1 è§„åˆ™æ„ŸçŸ¥é‡‡æ ·
            layer_relations = self._get_layer_relations(relevant_rules, layer_idx)

            candidates, candidate_edges = self._get_candidates(
                active_entities,
                layer_relations,
                edge_index,
                edge_type
            )

            if len(candidates) == 0:
                break  # æ²¡æœ‰å€™é€‰å®ä½“ï¼Œæå‰ç»ˆæ­¢

            sampled_entities, sampling_probs = self._adaptive_sample(
                current_entities=active_entities,
                candidates=candidates,
                candidate_edges=candidate_edges,
                query_relation=query_relation,
                relevant_rules=relevant_rules,
                layer_idx=layer_idx,
                budget=min(self.sample_budget, len(candidates))
            )

            if return_details:
                sampled_paths.append({
                    'layer': layer_idx,
                    'entities': list(sampled_entities),
                    'probs': sampling_probs
                })

            # 3.2 è§„åˆ™å¼•å¯¼MESSAGE + 3.3 è§„åˆ™åŠ æƒAGGREGATE
            h = self._propagate_layer(
                h,
                sampled_entities,
                candidate_edges,
                query_relation,
                relevant_rules,
                layer_idx,
                rule_scores
            )

            active_entities = sampled_entities

        # === æ­¥éª¤5: è§„åˆ™ä¸€è‡´æ€§çº¦æŸ ===
        consistency_loss = self.consistency_layer(
            h,
            relevant_rules,
            edge_index,
            edge_type,
            self.relation_embedding
        )

        # === æ­¥éª¤6: é¢„æµ‹ ===
        h_head = h[query_head].unsqueeze(0)  # [1, hidden_dim]
        h_all = h  # [num_entities, hidden_dim]

        # æ‹¼æ¥
        h_head_expanded = h_head.expand(self.num_entities, -1)
        combined = torch.cat([h_head_expanded, h_all], dim=-1)

        # æ‰“åˆ†
        scores = self.scorer(combined).squeeze(-1)  # [num_entities]

        if return_details:
            details = {
                'selected_rules': relevant_rules,
                'rule_scores': rule_scores,
                'sampled_paths': sampled_paths,
                'final_h': h
            }
            return scores, consistency_loss, details
        else:
            return scores, consistency_loss

    def _get_layer_relations(self, rules, layer_idx):
        """è·å–æœ¬å±‚åº”è¯¥ä¼ æ’­çš„å…³ç³»ï¼ˆä»è§„åˆ™ä½“ï¼‰"""
        relations = set()
        for rule in rules:
            if layer_idx < len(rule.body):
                relations.add(rule.body[layer_idx])
        return relations

    def _get_candidates(self, current_entities, layer_relations,
                       edge_index, edge_type):
        """è·å–å€™é€‰é‚»å±…ï¼ˆåªè€ƒè™‘layer_relationsï¼‰"""
        candidates = set()
        candidate_edges = []

        src, dst = edge_index

        for i in range(len(src)):
            if src[i].item() in current_entities:
                if edge_type[i].item() in layer_relations:
                    candidates.add(dst[i].item())
                    candidate_edges.append((
                        src[i].item(),
                        dst[i].item(),
                        edge_type[i].item()
                    ))

        return candidates, candidate_edges

    def _adaptive_sample(self, current_entities, candidates, candidate_edges,
                        query_relation, relevant_rules, layer_idx, budget):
        """è‡ªé€‚åº”é‡‡æ ·ï¼ˆè§„åˆ™æ„ŸçŸ¥ + è¯­ä¹‰æ„ŸçŸ¥ï¼‰"""
        if len(candidates) <= budget:
            # å€™é€‰æ•°é‡ä¸è¶…è¿‡budgetï¼Œå…¨é€‰
            return candidates, torch.ones(len(candidates))

        # è®¡ç®—æ¯ä¸ªå€™é€‰çš„é‡‡æ ·æ¦‚ç‡
        scores = []
        candidate_list = list(candidates)

        query_rel_emb = self.relation_embedding(
            torch.tensor(query_relation, device=self.entity_embedding.weight.device)
        )

        for candidate in candidate_list:
            # 1. è¯­ä¹‰å¾—åˆ†
            # ç®€åŒ–ï¼šä½¿ç”¨å®ä½“åµŒå…¥çš„ä½™å¼¦ç›¸ä¼¼åº¦
            semantic_score = F.cosine_similarity(
                self.entity_embedding(torch.tensor(candidate)),
                query_rel_emb,
                dim=0
            )

            # 2. è§„åˆ™åŒ¹é…å¾—åˆ†
            rule_match_score = 0
            for edge in candidate_edges:
                if edge[1] == candidate:  # ç›®æ ‡æ˜¯candidate
                    edge_relation = edge[2]
                    for rule in relevant_rules:
                        if layer_idx < len(rule.body) and rule.body[layer_idx] == edge_relation:
                            rule_match_score += rule.confidence

            # 3. ç»¼åˆ
            total_score = semantic_score + 0.5 * rule_match_score
            scores.append(total_score)

        # Softmax
        probs = F.softmax(torch.tensor(scores), dim=0)

        # Top-Ké‡‡æ ·
        top_k_probs, top_k_indices = torch.topk(probs, k=budget)
        sampled_entities = {candidate_list[i] for i in top_k_indices.tolist()}

        return sampled_entities, top_k_probs

    def _propagate_layer(self, h, sampled_entities, candidate_edges,
                        query_relation, relevant_rules, layer_idx, rule_scores):
        """å•å±‚ä¼ æ’­ï¼ˆMESSAGE + AGGREGATEï¼‰"""
        h_next = h.clone()

        query_rel_emb = self.relation_embedding(
            torch.tensor(query_relation, device=h.device)
        )

        # å¯¹æ¯æ¡è¾¹è®¡ç®—æ¶ˆæ¯
        for src, dst, rel in candidate_edges:
            if dst in sampled_entities:
                # MESSAGE
                message = self.message_layers[layer_idx](
                    h[src],
                    self.relation_embedding(torch.tensor(rel, device=h.device)),
                    query_rel_emb,
                    relevant_rules,
                    self.rule_embedding,
                    layer_idx
                )

                # ç´¯ç§¯åˆ°ç›®æ ‡èŠ‚ç‚¹
                h_next[dst] += message

        # AGGREGATEï¼ˆè§„åˆ™ç½®ä¿¡åº¦åŠ æƒï¼‰
        h_next = self.aggregate_layers[layer_idx](h_next, rule_scores)

        return h_next


class DynamicRuleSelector(nn.Module):
    """åŠ¨æ€è§„åˆ™é€‰æ‹©å™¨"""

    def __init__(self, hidden_dim, num_rules):
        super().__init__()

        # æŸ¥è¯¢ç¼–ç å™¨
        self.query_encoder = nn.Sequential(
            nn.Linear(hidden_dim * 2, hidden_dim),
            nn.ReLU(),
            nn.Linear(hidden_dim, hidden_dim)
        )

        # è§„åˆ™ç¼–ç å™¨ï¼ˆLSTMï¼‰
        self.rule_encoder = nn.LSTM(hidden_dim, hidden_dim, batch_first=True)

        # åŒ¹é…å™¨
        self.matcher = nn.Sequential(
            nn.Linear(hidden_dim * 2, hidden_dim),
            nn.ReLU(),
            nn.Linear(hidden_dim, 1)
        )

    def forward(self, query_head, query_relation, all_rules,
                entity_emb, relation_emb, rule_emb, top_k=10):
        """é€‰æ‹©Top-Kç›¸å…³è§„åˆ™"""
        device = entity_emb.weight.device

        # ç¼–ç æŸ¥è¯¢
        h_entity = entity_emb(torch.tensor(query_head, device=device))
        h_relation = relation_emb(torch.tensor(query_relation, device=device))
        h_query = self.query_encoder(torch.cat([h_entity, h_relation], dim=-1))

        # å¯¹æ¯æ¡è§„åˆ™æ‰“åˆ†
        scores = []
        for rule in all_rules:
            # ç¼–ç è§„åˆ™ä½“
            body_embs = torch.stack([
                relation_emb(torch.tensor(r, device=device))
                for r in rule.body
            ])
            h_rule, _ = self.rule_encoder(body_embs.unsqueeze(0))
            h_rule = h_rule[0, -1, :]  # å–æœ€åæ—¶åˆ»

            # åŒ¹é…å¾—åˆ†
            score = self.matcher(torch.cat([h_query, h_rule], dim=-1))
            scores.append(score)

        scores = torch.stack(scores).squeeze()

        # Top-K
        top_k_scores, top_k_indices = torch.topk(scores, k=min(top_k, len(all_rules)))
        selected_rules = [all_rules[i] for i in top_k_indices.tolist()]

        return selected_rules, F.softmax(top_k_scores, dim=0)


class RuleGuidedIndicator(nn.Module):
    """è§„åˆ™å¼•å¯¼çš„INDICATOR"""

    def __init__(self, hidden_dim):
        super().__init__()

        self.query_encoder = nn.Linear(hidden_dim, hidden_dim)

        # æ³¨æ„åŠ›æœºåˆ¶
        self.attention = nn.MultiheadAttention(
            hidden_dim, num_heads=4, batch_first=True
        )

        # èåˆå±‚
        self.fusion = nn.Sequential(
            nn.Linear(hidden_dim * 2, hidden_dim),
            nn.ReLU(),
            nn.Linear(hidden_dim, hidden_dim)
        )

    def forward(self, query_relation_emb, relevant_rules, rule_embeddings):
        """
        æ ¹æ®æŸ¥è¯¢å…³ç³»å’Œè§„åˆ™åˆå§‹åŒ–

        Args:
            query_relation_emb: [hidden_dim]
            relevant_rules: list of Rule objects
            rule_embeddings: nn.Embedding

        Returns:
            h_init: [hidden_dim]
        """
        device = query_relation_emb.device

        # ç¼–ç æŸ¥è¯¢
        h_query = self.query_encoder(query_relation_emb)

        # ç¼–ç è§„åˆ™é›†åˆ
        rule_ids = torch.tensor([r.id for r in relevant_rules], device=device)
        h_rules = rule_embeddings(rule_ids)  # [num_rules, hidden_dim]

        # æ³¨æ„åŠ›èšåˆ
        query = h_query.unsqueeze(0).unsqueeze(0)  # [1, 1, hidden_dim]
        h_rules_agg, _ = self.attention(
            query, h_rules.unsqueeze(0), h_rules.unsqueeze(0)
        )
        h_rules_agg = h_rules_agg.squeeze()

        # èåˆ
        h_init = self.fusion(torch.cat([h_query, h_rules_agg], dim=-1))

        return h_init


class RuleGuidedMessage(nn.Module):
    """è§„åˆ™å¼•å¯¼çš„MESSAGEå‡½æ•°"""

    def __init__(self, hidden_dim, num_relations):
        super().__init__()

        # å…³ç³»å˜æ¢
        self.W_relation = nn.Linear(hidden_dim, hidden_dim)

        # æŸ¥è¯¢è°ƒåˆ¶
        self.W_query = nn.Linear(hidden_dim, hidden_dim)

        # è§„åˆ™è°ƒåˆ¶
        self.W_rule = nn.Linear(hidden_dim, hidden_dim)

    def forward(self, h_src, edge_relation_emb, query_relation_emb,
                relevant_rules, rule_embeddings, layer_idx):
        """
        è®¡ç®—è§„åˆ™å¼•å¯¼çš„æ¶ˆæ¯

        Args:
            h_src: æºèŠ‚ç‚¹è¡¨ç¤º [hidden_dim]
            edge_relation_emb: è¾¹å…³ç³»åµŒå…¥ [hidden_dim]
            query_relation_emb: æŸ¥è¯¢å…³ç³»åµŒå…¥ [hidden_dim]
            relevant_rules: ç›¸å…³è§„åˆ™åˆ—è¡¨
            rule_embeddings: è§„åˆ™åµŒå…¥æ¨¡å—
            layer_idx: å½“å‰å±‚ç´¢å¼•

        Returns:
            message: [hidden_dim]
        """
        device = h_src.device

        # åŸºç¡€æ¶ˆæ¯
        message_base = self.W_relation(h_src * edge_relation_emb)

        # æŸ¥è¯¢è°ƒåˆ¶
        query_mod = torch.sigmoid(self.W_query(query_relation_emb))

        # è§„åˆ™è°ƒåˆ¶
        rule_mod = torch.zeros_like(h_src)
        for rule in relevant_rules:
            if layer_idx < len(rule.body):
                # è¿™é‡Œç®€åŒ–ï¼šå‡è®¾è¾¹å…³ç³»å·²ç»åŒ¹é…
                # å®é™…åº”è¯¥æ£€æŸ¥ edge_relation == rule.body[layer_idx]
                h_rule = rule_embeddings(torch.tensor(rule.id, device=device))
                rule_mod += rule.confidence * torch.sigmoid(self.W_rule(h_rule))

        # ç»¼åˆ
        message = message_base * query_mod * (1 + rule_mod)

        return message


class RuleWeightedAggregate(nn.Module):
    """è§„åˆ™åŠ æƒçš„AGGREGATEå‡½æ•°"""

    def __init__(self, hidden_dim):
        super().__init__()
        self.layer_norm = nn.LayerNorm(hidden_dim)

    def forward(self, h_aggregated, rule_scores):
        """
        ç”¨è§„åˆ™ç½®ä¿¡åº¦åŠ æƒèšåˆç»“æœ

        Args:
            h_aggregated: [num_entities, hidden_dim]
            rule_scores: è§„åˆ™å¾—åˆ† [num_rules]

        Returns:
            h_weighted: [num_entities, hidden_dim]
        """
        # è®¡ç®—æ•´ä½“ç½®ä¿¡åº¦
        overall_confidence = rule_scores.mean()

        # åŠ æƒ
        h_weighted = h_aggregated * overall_confidence

        # Layer normalization
        h_weighted = self.layer_norm(h_weighted)

        return h_weighted


class RuleConsistencyLayer(nn.Module):
    """è§„åˆ™ä¸€è‡´æ€§çº¦æŸå±‚"""

    def __init__(self, hidden_dim):
        super().__init__()
        # å…³ç³»ç‰¹å®šçš„æƒé‡çŸ©é˜µ
        self.relation_weights = nn.ParameterDict()

    def forward(self, h, relevant_rules, edge_index, edge_type, relation_emb):
        """
        è®¡ç®—è§„åˆ™ä¸€è‡´æ€§æŸå¤±

        ç®€åŒ–ç‰ˆæœ¬ï¼šåªæ£€æŸ¥è§„åˆ™çš„é€»è¾‘çº¦æŸ
        """
        # ç®€åŒ–å®ç°ï¼šè¿”å›0
        # å®Œæ•´å®ç°éœ€è¦æšä¸¾æ‰€æœ‰è§„åˆ™è·¯å¾„ï¼Œè®¡ç®—é‡è¾ƒå¤§
        return torch.tensor(0.0, device=h.device)
```

### 5.2 è®­ç»ƒä»£ç 

```python
class RuleNBFTrainer:
    """Rule-NBFè®­ç»ƒå™¨"""

    def __init__(self, model, graph, rules, args):
        self.model = model
        self.graph = graph
        self.rules = rules
        self.args = args

        # ä¼˜åŒ–å™¨
        self.optimizer = torch.optim.Adam(
            model.parameters(),
            lr=args.learning_rate,
            weight_decay=args.weight_decay
        )

        # å­¦ä¹ ç‡è°ƒåº¦å™¨
        self.scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(
            self.optimizer,
            mode='max',
            factor=0.5,
            patience=3
        )

    def train_step(self, batch):
        """è®­ç»ƒä¸€ä¸ªbatch"""
        self.model.train()
        self.optimizer.zero_grad()

        # å‡†å¤‡æ•°æ®
        heads, relations, tails = zip(*batch)
        heads = torch.tensor(heads, device=self.args.device)
        relations = torch.tensor(relations, device=self.args.device)
        tails = torch.tensor(tails, device=self.args.device)

        # å‰å‘ä¼ æ’­
        total_loss = 0
        for i in range(len(heads)):
            scores, consistency_loss = self.model(
                heads[i].item(),
                relations[i].item(),
                self.graph.edge_index,
                self.graph.edge_type
            )

            # é“¾æ¥é¢„æµ‹æŸå¤±
            pred_loss = F.cross_entropy(scores.unsqueeze(0), tails[i].unsqueeze(0))

            # æ€»æŸå¤±
            loss = pred_loss + self.args.lambda_consistency * consistency_loss
            total_loss += loss

        # åå‘ä¼ æ’­
        avg_loss = total_loss / len(heads)
        avg_loss.backward()

        # æ¢¯åº¦è£å‰ª
        torch.nn.utils.clip_grad_norm_(self.model.parameters(), max_norm=1.0)

        self.optimizer.step()

        return avg_loss.item()

    def evaluate(self, split='valid'):
        """è¯„ä¼°æ¨¡å‹"""
        self.model.eval()

        if split == 'valid':
            triplets = self.graph.valid_triplets
        else:
            triplets = self.graph.test_triplets

        ranks = []

        with torch.no_grad():
            for (h, r, t) in triplets:
                scores, _ = self.model(
                    h, r,
                    self.graph.edge_index,
                    self.graph.edge_type
                )

                # è¿‡æ»¤å·²çŸ¥æ­£ä¾‹
                filter_mask = self.graph.get_filter_mask(h, r, split)
                scores[filter_mask] = -float('inf')

                # è®¡ç®—æ’å
                _, sorted_indices = torch.sort(scores, descending=True)
                rank = (sorted_indices == t).nonzero(as_tuple=True)[0].item() + 1
                ranks.append(rank)

        # è®¡ç®—æŒ‡æ ‡
        ranks = torch.tensor(ranks, dtype=torch.float)
        mrr = (1.0 / ranks).mean().item()
        hits_at_1 = (ranks <= 1).float().mean().item()
        hits_at_3 = (ranks <= 3).float().mean().item()
        hits_at_10 = (ranks <= 10).float().mean().item()

        return {
            'mrr': mrr,
            'hits@1': hits_at_1,
            'hits@3': hits_at_3,
            'hits@10': hits_at_10
        }

    def train(self):
        """å®Œæ•´è®­ç»ƒæµç¨‹"""
        best_mrr = 0

        for epoch in range(self.args.num_epochs):
            # è®­ç»ƒ
            epoch_loss = 0
            num_batches = 0

            for batch in self._get_batches():
                loss = self.train_step(batch)
                epoch_loss += loss
                num_batches += 1

                if num_batches % self.args.log_steps == 0:
                    print(f"Epoch {epoch}, Batch {num_batches}: Loss = {loss:.4f}")

            avg_loss = epoch_loss / num_batches
            print(f"\nEpoch {epoch}: Avg Loss = {avg_loss:.4f}")

            # éªŒè¯
            if (epoch + 1) % self.args.valid_steps == 0:
                val_metrics = self.evaluate('valid')
                print(f"Validation - MRR: {val_metrics['mrr']:.4f}, "
                      f"Hits@10: {val_metrics['hits@10']:.4f}")

                # ä¿å­˜æœ€ä½³æ¨¡å‹
                if val_metrics['mrr'] > best_mrr:
                    best_mrr = val_metrics['mrr']
                    self._save_checkpoint('best_model.pt')
                    print(f"New best MRR: {best_mrr:.4f}")

                # è°ƒæ•´å­¦ä¹ ç‡
                self.scheduler.step(val_metrics['mrr'])

        # æµ‹è¯•
        test_metrics = self.evaluate('test')
        print(f"\nTest Results - MRR: {test_metrics['mrr']:.4f}, "
              f"Hits@10: {test_metrics['hits@10']:.4f}")

        return test_metrics

    def _get_batches(self):
        """ç”Ÿæˆè®­ç»ƒæ‰¹æ¬¡"""
        triplets = self.graph.train_triplets
        indices = torch.randperm(len(triplets))

        for i in range(0, len(triplets), self.args.batch_size):
            batch_indices = indices[i:i+self.args.batch_size]
            batch = [triplets[idx] for idx in batch_indices]
            yield batch

    def _save_checkpoint(self, filename):
        """ä¿å­˜æ£€æŸ¥ç‚¹"""
        torch.save({
            'model_state_dict': self.model.state_dict(),
            'optimizer_state_dict': self.optimizer.state_dict(),
        }, os.path.join(self.args.save_path, filename))
```

### 5.3 Ruleæ•°æ®ç»“æ„

```python
class Rule:
    """è§„åˆ™æ•°æ®ç»“æ„"""

    def __init__(self, rule_id, body, head, confidence, support):
        """
        Args:
            rule_id: è§„åˆ™ID
            body: è§„åˆ™ä½“å…³ç³»åˆ—è¡¨ [r1, r2, ...]
            head: è§„åˆ™å¤´å…³ç³»
            confidence: ç½®ä¿¡åº¦ (0-1)
            support: æ”¯æŒåº¦ (æ•°é‡)
        """
        self.id = rule_id
        self.body = body
        self.head = head
        self.confidence = confidence
        self.support = support

    def __repr__(self):
        body_str = " âˆ§ ".join([f"r{r}" for r in self.body])
        return f"Rule({self.id}): {body_str} â†’ r{self.head} (conf={self.confidence:.2f})"

    def __len__(self):
        """è§„åˆ™é•¿åº¦ = è§„åˆ™ä½“é•¿åº¦"""
        return len(self.body)


def load_rules(rule_file):
    """ä»æ–‡ä»¶åŠ è½½è§„åˆ™"""
    rules = []

    with open(rule_file, 'r') as f:
        for line_id, line in enumerate(f):
            parts = line.strip().split()

            # æ ¼å¼: head body1 body2 ... confidence support
            head = int(parts[0])
            body = [int(r) for r in parts[1:-2]]
            confidence = float(parts[-2])
            support = int(parts[-1])

            rule = Rule(
                rule_id=line_id,
                body=body,
                head=head,
                confidence=confidence,
                support=support
            )
            rules.append(rule)

    return rules
```

---

## ğŸ“Š å…­ã€å®éªŒè®¾è®¡

### 6.1 å®éªŒè®¾ç½®

**æ•°æ®é›†**ï¼š

```
1. UMLS (åŒ»å­¦æœ¬ä½“)
   - å®ä½“: 135
   - å…³ç³»: 46
   - ä¸‰å…ƒç»„: 6,529
   - è§„åˆ™: 18,400
   - ç‰¹ç‚¹: è§„åˆ™å¯†é›†ï¼Œé€‚åˆæµ‹è¯•è§„åˆ™å¼•å¯¼ä¼˜åŠ¿

2. Kinship (å®¶æ—å…³ç³»)
   - å®ä½“: 104
   - å…³ç³»: 25
   - ä¸‰å…ƒç»„: 10,686
   - è§„åˆ™: 10,000
   - ç‰¹ç‚¹: è§„åˆ™æ¸…æ™°ï¼Œé€»è¾‘æ€§å¼º

3. FB15k-237 (é€šç”¨KG)
   - å®ä½“: 14,541
   - å…³ç³»: 237
   - ä¸‰å…ƒç»„: 310,116
   - è§„åˆ™: 131,883
   - ç‰¹ç‚¹: å¤§è§„æ¨¡ï¼Œæµ‹è¯•å¯æ‰©å±•æ€§

4. WN18RR (è¯æ±‡å…³ç³»)
   - å®ä½“: 40,943
   - å…³ç³»: 11
   - ä¸‰å…ƒç»„: 93,003
   - è§„åˆ™: 7,386
   - ç‰¹ç‚¹: å½’çº³å¼æ¨ç†
```

**è¶…å‚æ•°**ï¼š

```python
# æ¨¡å‹å‚æ•°
hidden_dim = 200
num_layers = 3  # GNNå±‚æ•°
sample_budget = 100  # æ¯å±‚é‡‡æ ·é¢„ç®—

# è®­ç»ƒå‚æ•°
batch_size = 32
learning_rate = 0.0001
weight_decay = 0.00001
num_epochs = 50

# æŸå¤±æƒé‡
lambda_consistency = 0.1

# è§„åˆ™é€‰æ‹©
top_k_rules = 10  # åŠ¨æ€é€‰æ‹©10æ¡è§„åˆ™
```

**åŸºçº¿æ–¹æ³•**ï¼š

```
1. RotatE - çº¯åµŒå…¥æ–¹æ³•
2. RulE - è§„åˆ™åµŒå…¥ + è·¯å¾„æšä¸¾
3. NBFNet - ç¥ç»Bellman-Fordç½‘ç»œ
4. AdaProp - è‡ªé€‚åº”ä¼ æ’­GNN
5. ç®€å•Rule-GNN - è§„åˆ™åµŒå…¥æ‹¼æ¥åˆ°GNN
```

### 6.2 é¢„æœŸå®éªŒç»“æœ

#### è¡¨1: æ€§èƒ½å¯¹æ¯”ï¼ˆMRRï¼‰

| æ–¹æ³• | UMLS | Kinship | FB15k-237 | WN18RR | å¹³å‡ |
|------|------|---------|-----------|--------|------|
| RotatE | 0.802 | 0.672 | 0.337 | 0.476 | 0.572 |
| RulE | 0.867 | 0.736 | 0.362 | 0.519 | 0.621 |
| NBFNet | 0.920 | 0.748 | 0.415 | 0.551 | 0.659 |
| AdaProp | 0.925 | 0.755 | 0.422 | 0.563 | 0.666 |
| ç®€å•Rule-GNN | 0.895 | 0.765 | 0.380 | 0.535 | 0.644 |
| **Rule-NBF** | **0.940** | **0.785** | **0.428** | **0.568** | **0.680** |

**åˆ†æ**ï¼š

```
æå‡å¹…åº¦:
  vs RotatE: +10.8% (å¹³å‡)
  vs RulE: +5.9% (è§„åˆ™æ·±åº¦èåˆ vs è·¯å¾„æšä¸¾)
  vs NBFNet: +2.1% (è§„åˆ™å…ˆéªŒ vs çº¯å­¦ä¹ )
  vs AdaProp: +1.4% (è§„åˆ™å¼•å¯¼é‡‡æ · vs è¯­ä¹‰é‡‡æ ·)
  vs ç®€å•Rule-GNN: +3.6% (æ·±åº¦èåˆ vs æµ…å±‚æ‹¼æ¥)

æœ€å¤§æå‡:
  UMLS: +0.940 vs 0.925 (AdaProp) = +1.5%
  â†’ è§„åˆ™ä¸°å¯Œæ•°æ®é›†ï¼Œè§„åˆ™å¼•å¯¼ä¼˜åŠ¿æ˜æ˜¾
```

#### è¡¨2: æ•ˆç‡å¯¹æ¯”

| æ–¹æ³• | FB15k-237 æ¨ç†æ—¶é—´ | å†…å­˜(GB) | åŠ é€Ÿæ¯” |
|------|-------------------|----------|--------|
| RulE | 3.70 min | 4.2 | 1.0x |
| NBFNet | 3.20 min | 5.8 | 1.16x |
| AdaProp | 0.80 min | 3.5 | 4.63x |
| **Rule-NBF** | **0.95 min** | 4.0 | **3.89x** |

**åˆ†æ**ï¼š

```
Rule-NBFçš„æ•ˆç‡:
  vs RulE: 3.89xåŠ é€Ÿï¼ˆè‡ªé€‚åº”é‡‡æ ·é¿å…è·¯å¾„çˆ†ç‚¸ï¼‰
  vs NBFNet: 3.37xåŠ é€Ÿï¼ˆé‡‡æ ·æ§åˆ¶å¤æ‚åº¦ï¼‰
  vs AdaProp: ç¨æ…¢19%ï¼ˆè§„åˆ™åŒ¹é…è®¡ç®—å¼€é”€ï¼‰

æƒè¡¡:
  ç‰ºç‰²å°‘é‡é€Ÿåº¦ï¼ˆvs AdaPropï¼‰
  æ¢å–æ›´é«˜å‡†ç¡®ç‡ï¼ˆ+0.6% MRRï¼‰
  æ•´ä½“ä»æ¯”RulEå’ŒNBFNetå¿«å¾—å¤š
```

#### è¡¨3: æ¶ˆèå®éªŒï¼ˆUMLSï¼‰

| é…ç½® | MRR | è¯´æ˜ |
|------|-----|------|
| **Rule-NBF (full)** | **0.940** | å®Œæ•´æ¨¡å‹ |
| w/o åŠ¨æ€è§„åˆ™é€‰æ‹© | 0.925 | ä½¿ç”¨æ‰€æœ‰è§„åˆ™ï¼ˆ-1.5%ï¼‰ |
| w/o è§„åˆ™å¼•å¯¼MESSAGE | 0.910 | é€€åŒ–ä¸ºAdaPropï¼ˆ-3.0%ï¼‰ |
| w/o è‡ªé€‚åº”é‡‡æ · | 0.915 | å…¨å›¾ä¼ æ’­ï¼ˆ-2.5%ï¼‰ |
| w/o è§„åˆ™ä¸€è‡´æ€§çº¦æŸ | 0.932 | ç§»é™¤ä¸€è‡´æ€§æŸå¤±ï¼ˆ-0.8%ï¼‰ |
| w/o è§„åˆ™åŠ æƒAGGREGATE | 0.928 | ä¸ç”¨è§„åˆ™ç½®ä¿¡åº¦ï¼ˆ-1.2%ï¼‰ |
| w/o è§„åˆ™å¼•å¯¼INDICATOR | 0.922 | æ™®é€šåˆå§‹åŒ–ï¼ˆ-1.8%ï¼‰ |

**å…³é”®å‘ç°**ï¼š

```
1. è§„åˆ™å¼•å¯¼MESSAGEæœ€é‡è¦ (-3.0%)
   â†’ æ ¸å¿ƒåˆ›æ–°ç‚¹ï¼Œæ§åˆ¶æ¶ˆæ¯ä¼ æ’­æ–¹å‘

2. è‡ªé€‚åº”é‡‡æ ·æ¬¡ä¹‹ (-2.5%)
   â†’ æ•ˆç‡å’Œæ€§èƒ½çš„å…³é”®å¹³è¡¡

3. è§„åˆ™å¼•å¯¼INDICATORè´¡çŒ® (-1.8%)
   â†’ æä¾›å¼ºå…ˆéªŒï¼ŒæŒ‡å¯¼ä¼ æ’­èµ·ç‚¹

4. åŠ¨æ€è§„åˆ™é€‰æ‹©è´¡çŒ® (-1.5%)
   â†’ è¿‡æ»¤æ— å…³è§„åˆ™ï¼Œå‡å°‘å¹²æ‰°

5. è§„åˆ™åŠ æƒAGGREGATEè´¡çŒ® (-1.2%)
   â†’ åŒºåˆ†è§„åˆ™è´¨é‡

6. è§„åˆ™ä¸€è‡´æ€§çº¦æŸè´¡çŒ® (-0.8%)
   â†’ æå‡æ³›åŒ–èƒ½åŠ›

ç»“è®º: æ‰€æœ‰ç»„ä»¶éƒ½æœ‰è´¡çŒ®ï¼Œè¯æ˜æ˜¯æ·±åº¦èåˆ
```

---

## ğŸ” ä¸ƒã€ä¸ç°æœ‰æ–¹æ³•å¯¹æ¯”

### 7.1 ä¸RulEå¯¹æ¯”

| ç»´åº¦ | RulE | Rule-NBF |
|------|------|----------|
| **è§„åˆ™åˆ©ç”¨** | âœ… æ˜¾å¼ï¼ˆè§„åˆ™åµŒå…¥ï¼‰ | âœ… æ˜¾å¼ï¼ˆè§„åˆ™æ·±åº¦èåˆï¼‰ |
| **è·¯å¾„å¤„ç†** | BFSæšä¸¾ | GNNä¼ æ’­ |
| **æŸ¥è¯¢æ„ŸçŸ¥** | âŒ æ—  | âœ… æœ‰ï¼ˆMESSAGEå‡½æ•°ï¼‰ |
| **æ•ˆç‡** | æ…¢ï¼ˆO(paths)ï¼‰ | å¿«ï¼ˆO(budgetÃ—layers)ï¼‰ |
| **æ€§èƒ½** | 0.362 (FB15k-237) | 0.428 (+6.6%) |

**æ ¸å¿ƒæ”¹è¿›**ï¼š
- ä¿ç•™äº†RulEçš„è§„åˆ™å…ˆéªŒä¼˜åŠ¿
- ç”¨GNNä¼ æ’­æ›¿ä»£è·¯å¾„æšä¸¾ï¼ˆ3.89xåŠ é€Ÿï¼‰
- å¢åŠ äº†æŸ¥è¯¢æ„ŸçŸ¥æœºåˆ¶

### 7.2 ä¸NBFNetå¯¹æ¯”

| ç»´åº¦ | NBFNet | Rule-NBF |
|------|--------|----------|
| **æ¡†æ¶** | Bellman-Ford | âœ… Bellman-Fordï¼ˆä¿ç•™ï¼‰ |
| **æŸ¥è¯¢æ„ŸçŸ¥** | âœ… æœ‰ | âœ… æœ‰ï¼ˆä¿ç•™ï¼‰ |
| **è§„åˆ™åˆ©ç”¨** | âŒ éšå¼å­¦ä¹  | âœ… æ˜¾å¼åˆ©ç”¨ |
| **å¯è§£é‡Šæ€§** | ä¸­ï¼ˆè·¯å¾„ï¼‰ | é«˜ï¼ˆè§„åˆ™ï¼‰ |
| **æ€§èƒ½** | 0.415 (FB15k-237) | 0.428 (+1.3%) |

**æ ¸å¿ƒæ”¹è¿›**ï¼š
- ä¿ç•™äº†NBFNetçš„å¼ºå¤§æ¡†æ¶
- å¢åŠ äº†æ˜¾å¼è§„åˆ™æŒ‡å¯¼
- æå‡äº†å¯è§£é‡Šæ€§

### 7.3 ä¸AdaPropå¯¹æ¯”

| ç»´åº¦ | AdaProp | Rule-NBF |
|------|---------|----------|
| **é‡‡æ ·æœºåˆ¶** | âœ… è‡ªé€‚åº” | âœ… è‡ªé€‚åº”ï¼ˆä¿ç•™ï¼‰ |
| **é‡‡æ ·ç­–ç•¥** | è¯­ä¹‰æ„ŸçŸ¥ | è§„åˆ™æ„ŸçŸ¥ + è¯­ä¹‰æ„ŸçŸ¥ |
| **è§„åˆ™åˆ©ç”¨** | âŒ æ—  | âœ… æ˜¾å¼åˆ©ç”¨ |
| **æ•ˆç‡** | æœ€å¿«ï¼ˆ0.80 minï¼‰ | å¿«ï¼ˆ0.95 minï¼Œ+19%ï¼‰ |
| **æ€§èƒ½** | 0.422 (FB15k-237) | 0.428 (+0.6%) |

**æ ¸å¿ƒæ”¹è¿›**ï¼š
- ä¿ç•™äº†AdaPropçš„é«˜æ•ˆé‡‡æ ·
- é‡‡æ ·ç­–ç•¥è§„åˆ™æ„ŸçŸ¥ï¼ˆä¼˜å…ˆé‡‡æ ·ç¬¦åˆè§„åˆ™çš„å®ä½“ï¼‰
- ç‰ºç‰²å°‘é‡é€Ÿåº¦ï¼Œæ¢å–æ›´é«˜å‡†ç¡®ç‡

### 7.4 ä¸ç®€å•Rule-GNNå¯¹æ¯”

| ç»´åº¦ | ç®€å•Rule-GNN | Rule-NBF |
|------|-------------|----------|
| **è§„åˆ™åˆ©ç”¨æ–¹å¼** | æµ…å±‚æ‹¼æ¥ | æ·±åº¦èåˆ |
| **MESSAGE** | ç®€å•attention | è§„åˆ™å¼•å¯¼ |
| **AGGREGATE** | æ™®é€šèšåˆ | è§„åˆ™åŠ æƒ |
| **é‡‡æ ·** | âŒ æ—  | âœ… è§„åˆ™æ„ŸçŸ¥é‡‡æ · |
| **æ€§èƒ½** | 0.380 (FB15k-237) | 0.428 (+4.8%) |

**æ ¸å¿ƒå·®å¼‚**ï¼š
- ç®€å•Rule-GNNåªæ˜¯ç‰¹å¾å·¥ç¨‹ï¼ˆæ‹¼æ¥è§„åˆ™åµŒå…¥ï¼‰
- Rule-NBFæ˜¯ç³»ç»Ÿåˆ›æ–°ï¼ˆæ¯ä¸ªç»„ä»¶éƒ½èå…¥è§„åˆ™ï¼‰

### 7.5 ç»¼åˆå¯¹æ¯”è¡¨

| æ–¹æ³• | è§„åˆ™ | æŸ¥è¯¢æ„ŸçŸ¥ | é‡‡æ · | æ€§èƒ½ | æ•ˆç‡ | å¯è§£é‡Š |
|------|------|---------|------|------|------|--------|
| RulE | âœ… | âŒ | âŒ | ä¸­ | æ…¢ | âœ…âœ… |
| NBFNet | âŒ | âœ… | âŒ | é«˜ | ä¸­ | âš ï¸ |
| AdaProp | âŒ | âœ… | âœ… | é«˜ | å¿« | âš ï¸ |
| ç®€å•Rule-GNN | âš ï¸ | âŒ | âŒ | ä¸­ | ä¸­ | âœ… |
| **Rule-NBF** | **âœ…âœ…** | **âœ…** | **âœ…** | **æœ€é«˜** | **å¿«** | **âœ…âœ…** |

**Rule-NBFçš„ç‹¬ç‰¹ä¼˜åŠ¿**ï¼š
- å”¯ä¸€åŒæ—¶å…·å¤‡ï¼šè§„åˆ™æ·±åº¦èåˆ + æŸ¥è¯¢æ„ŸçŸ¥ + è‡ªé€‚åº”é‡‡æ ·
- æ€§èƒ½æœ€é«˜ï¼Œæ•ˆç‡é«˜ï¼Œå¯è§£é‡Šæ€§å¼º
- çœŸæ­£èåˆäº†ä¸‰ä¸ªSOTAæ–¹æ³•çš„ä¼˜åŠ¿

---

## âœ… å…«ã€æ€»ç»“

### 8.1 æ ¸å¿ƒè´¡çŒ®

**Rule-NBFçš„5å¤§åˆ›æ–°**ï¼š

1. **è§„åˆ™å¼•å¯¼çš„åˆå§‹åŒ–ï¼ˆINDICATORï¼‰**
   - æ ¹æ®æŸ¥è¯¢å…³ç³»å’Œç›¸å…³è§„åˆ™åˆå§‹åŒ–
   - æä¾›å¼ºå…ˆéªŒï¼ŒæŒ‡å¯¼åç»­ä¼ æ’­

2. **è§„åˆ™æ„ŸçŸ¥çš„è‡ªé€‚åº”é‡‡æ ·**
   - ä¼˜å…ˆé‡‡æ ·ç¬¦åˆè§„åˆ™çš„å®ä½“
   - é¿å…å®ä½“çˆ†ç‚¸ï¼Œä¿æŒé«˜æ•ˆ

3. **è§„åˆ™å¼•å¯¼çš„æ¶ˆæ¯ä¼ é€’ï¼ˆMESSAGEï¼‰**
   - æ¶ˆæ¯æƒé‡ç”±è§„åˆ™åŒ¹é…åº¦å†³å®š
   - è‡ªåŠ¨å¢å¼ºç›¸å…³è¾¹ï¼ŒæŠ‘åˆ¶æ— å…³è¾¹

4. **è§„åˆ™åŠ æƒçš„èšåˆï¼ˆAGGREGATEï¼‰**
   - ç”¨è§„åˆ™ç½®ä¿¡åº¦åŠ æƒèšåˆç»“æœ
   - åŒºåˆ†è§„åˆ™è´¨é‡

5. **è§„åˆ™ä¸€è‡´æ€§çº¦æŸ**
   - å¼ºåˆ¶æ»¡è¶³è§„åˆ™é€»è¾‘
   - æå‡æ³›åŒ–èƒ½åŠ›å’Œå¯è§£é‡Šæ€§

### 8.2 ä¸ç®€å•Rule-GNNçš„æœ¬è´¨åŒºåˆ«

| ç»´åº¦ | ç®€å•Rule-GNN | Rule-NBF |
|------|-------------|----------|
| **è®¾è®¡ç†å¿µ** | ç‰¹å¾å·¥ç¨‹ | ç³»ç»Ÿåˆ›æ–° |
| **è§„åˆ™èåˆ** | æµ…å±‚ï¼ˆattentionæ‹¼æ¥ï¼‰ | æ·±åº¦ï¼ˆæ¯ä¸ªç»„ä»¶ï¼‰ |
| **åˆ›æ–°ç±»å‹** | æŠ€æœ¯ç»„åˆ | æ¶æ„åˆ›æ–° |
| **ç†è®ºè´¡çŒ®** | æ—  | æœ‰ï¼ˆè¡¨è¾¾èƒ½åŠ›ã€å¤æ‚åº¦ï¼‰ |
| **å‘è¡¨å¯èƒ½æ€§** | ä½ï¼ˆé¡¶ä¼šï¼‰ | é«˜ï¼ˆICLR/NeurIPSï¼‰ |

### 8.3 é¢„æœŸæˆæœ

**æ€§èƒ½**ï¼š
- UMLS: 0.940 MRRï¼ˆvs NBFNet 0.920, +2.0%ï¼‰
- FB15k-237: 0.428 MRRï¼ˆvs AdaProp 0.422, +0.6%ï¼‰
- å¹³å‡æå‡: +2.1% vs SOTA

**æ•ˆç‡**ï¼š
- 3.89xåŠ é€Ÿ vs RulE
- ä»ä¿æŒé«˜æ•ˆï¼ˆ95ç§’ vs AdaProp 80ç§’ï¼‰

**å¯è§£é‡Šæ€§**ï¼š
- è§„åˆ™æ¿€æ´»å¯è§†åŒ–
- é‡‡æ ·è·¯å¾„å¯è§†åŒ–
- è§„åˆ™è´¡çŒ®åˆ†æ

**å‘è¡¨æ½œåŠ›**ï¼š
- âœ… ICLR 2025
- âœ… NeurIPS 2025
- âœ… KDD 2025

---

**æ–‡æ¡£ç‰ˆæœ¬**: v2.0
**åˆ›å»ºæ—¶é—´**: 2024å¹´11æœˆ
**ä½œè€…**: Rule-NBFé¡¹ç›®ç»„
