# RulE 模型超参数说明文档

本文档详细说明 RulE (Rule Embedding) 模型的所有超参数配置，包括其含义、作用范围、推荐取值范围以及在不同数据集上的具体设置。

## 目录

- [基础配置参数](#基础配置参数)
- [预训练阶段超参数](#预训练阶段超参数)
  - [模型结构参数](#模型结构参数)
  - [训练策略参数](#训练策略参数)
  - [损失函数参数](#损失函数参数)
- [规则落地阶段超参数](#规则落地阶段超参数)
- [不同数据集的超参数对比](#不同数据集的超参数对比)
- [超参数调优建议](#超参数调优建议)

---

## 基础配置参数

### `data_path`
- **类型**: String
- **说明**: 数据集路径，指向包含实体、关系和三元组文件的目录
- **示例**: `"../data/umls"`

### `rule_file`
- **类型**: String
- **说明**: 挖掘得到的逻辑规则文件路径
- **格式**: 每行一条规则，格式为 `rule_head rule_body_1 rule_body_2 ...`
- **示例**: `"../data/umls/mined_rules.txt"`

### `cuda`
- **类型**: Boolean
- **说明**: 是否使用 GPU 加速训练
- **推荐值**: `true` (如果有 GPU)

### `cpu_num`
- **类型**: Integer
- **说明**: CPU 工作线程数，用于数据加载
- **推荐值**: `10`
- **作用**: 影响数据加载速度，建议设为可用 CPU 核心数的一半

### `seed`
- **类型**: Integer
- **说明**: 随机种子，用于保证实验可复现性
- **默认值**: `800`

### `save_path`
- **类型**: String
- **说明**: 模型checkpoint和日志的保存路径
- **示例**: `"umls"` (会保存到 `../outputs/umls/`)

---

## 预训练阶段超参数

预训练阶段联合学习实体嵌入、关系嵌入和规则嵌入。

### 模型结构参数

#### `hidden_dim`
- **类型**: Integer
- **说明**: 嵌入向量的维度
- **作用**:
  - 实体嵌入维度为 `hidden_dim × 2` (用于复数表示)
  - 关系嵌入维度为 `hidden_dim`
  - 规则嵌入维度为 `hidden_dim`
- **取值范围**: 500-2000
- **推荐设置**:
  - 小数据集 (family, kinship, umls): `2000`
  - 中等数据集 (wn18rr, yago): `500`
  - 大数据集 (FB15k-237): `1000`
- **调优建议**: 数据集越大，实体/关系数量越多，可适当增加维度

#### `p_norm`
- **类型**: Integer
- **说明**: 距离度量的范数阶数
- **默认值**: `2` (欧几里得距离)
- **说明**: 用于计算嵌入向量之间的距离，一般使用 L2 范数

### 训练策略参数

#### `batch_size`
- **类型**: Integer
- **说明**: 知识图谱三元组的批次大小（每次迭代训练的三元组样本数）
- **取值范围**: 256-1024
- **推荐设置**:
  - 小数据集 (Family, Kinship): `256`
  - 中等数据集 (UMLS, WN18RR): `512`
  - 大数据集 (FB15k-237, YAGO): `1024`

**详细说明**:

批次大小决定了每次梯度更新时使用多少个训练样本。在RulE模型中，这个参数特指KGE（知识图谱嵌入）训练的批次大小。

**工作原理**:
1. 每个批次包含 `batch_size` 个正样本三元组 (h, r, t)
2. 对于每个正样本，会生成 `negative_sample_size` 个负样本
3. 实际每个批次处理的样本总数 = `batch_size × (1 + negative_sample_size)`
4. 例如: batch_size=256, negative_sample_size=512，则每批次实际处理 256×513 = 131,328 个样本

**对训练的影响**:
- **批次越大**:
  - ✅ 梯度估计更准确，训练更稳定
  - ✅ GPU利用率更高，训练速度更快（到一定程度后饱和）
  - ✅ 有正则化效果，可能提高泛化能力
  - ❌ 内存占用更高
  - ❌ 可能陷入较差的局部最优（泛化能力下降）
  - ❌ 每个epoch的迭代次数减少

- **批次越小**:
  - ✅ 内存占用少
  - ✅ 梯度更新更频繁，可能更快收敛
  - ✅ 引入噪声有助于逃离局部最优
  - ❌ 梯度估计不准确，训练波动大
  - ❌ GPU利用率低

**数据集对比示例**:
- **Family** (batch_size=256): 训练集约3,000个三元组，每个epoch约12批次
- **FB15k-237** (batch_size=1024): 训练集约272,000个三元组，每个epoch约266批次
- **YAGO** (batch_size=1024): 训练集约1,000,000+个三元组，每个epoch约1000+批次

**调优建议**:
1. 从512开始尝试
2. GPU显存充足时逐步增大（512 → 1024 → 2048）
3. 如果出现OOM错误，减半调整
4. 观察验证集性能和训练稳定性
5. 大批次需要配合较高的学习率（按平方根缩放：lr × √(new_batch / old_batch)）

#### `negative_sample_size`
- **类型**: Integer
- **说明**: 每个正样本对应的负样本数量
- **取值范围**: 256-1024
- **推荐值**: `256-512`
- **作用**: 对抗负采样的样本数，影响模型的辨别能力

#### `rule_batch_size`
- **类型**: Integer
- **说明**: 规则训练的批次大小
- **推荐值**: `128-256`
- **作用**: 控制每次迭代中训练的规则数量

#### `rule_negative_size`
- **类型**: Integer
- **说明**: 每条规则的负采样数量
- **推荐值**: `64-128`
- **作用**: 为规则生成负样本，用于训练规则嵌入

#### `learning_rate`
- **类型**: Float
- **说明**: 预训练阶段的学习率（Adam优化器的初始学习率）
- **取值范围**: 0.00005-0.0001 (即 5e-5 到 1e-4)
- **推荐值**:
  - 小数据集 (Family, Kinship, UMLS): `0.0001` (1e-4)
  - 大数据集 (FB15k-237, YAGO, WN18RR): `0.00005` (5e-5)

**详细说明**:

学习率是深度学习中最重要的超参数之一，它控制每次梯度下降时参数更新的步长。

**什么是学习率？**

在梯度下降优化中，参数更新公式为：
```
θ_new = θ_old - learning_rate × ∇Loss
```

- **learning_rate 大**: 参数更新步长大，收敛快但可能不稳定
- **learning_rate 小**: 参数更新步长小，收敛慢但更稳定

**在RulE模型中的应用**:

预训练阶段同时训练三类参数：
1. **实体嵌入** (entity_embedding): 维度 num_entities × hidden_dim × 2
2. **关系嵌入** (relation_embedding): 维度 num_relations × hidden_dim
3. **规则嵌入** (rule_emb): 维度 num_rules × hidden_dim

使用Adam优化器，代码位置(trainer.py:40-44):
```python
optimizer = torch.optim.Adam(
    filter(lambda p: p.requires_grad, self.model.parameters()),
    lr=float(args.learning_rate),
    weight_decay=float(args.weight_decay)
)
```

**学习率调度策略**:

RulE使用**分段常数学习率衰减**策略:

```
Step 0 ──────────► warm_up_steps ──────────► max_steps
  |                      |                       |
  lr                  lr / 10                 lr / 10
(初始学习率)        (衰减10倍)             (保持不变)
```

代码实现 (trainer.py:99-106):
```python
if step >= warm_up_steps:
    current_learning_rate = current_learning_rate / 10
    logging.info('Change learning_rate to %f at step %d' %
                 (current_learning_rate, step))
    optimizer = torch.optim.Adam(
        filter(lambda p: p.requires_grad, model.parameters()),
        lr=current_learning_rate
    )
    warm_up_steps = warm_up_steps * 3  # 下次衰减点延后
```

**实际训练案例**:

**UMLS数据集**:
- learning_rate: 0.0001
- max_steps: 30,000
- warm_up_steps: 15,000 (默认 max_steps / 2)

训练过程:
- Step 0-15,000: lr = 0.0001 (快速学习阶段)
- Step 15,000-30,000: lr = 0.00001 (精调阶段，学习率降至原来的1/10)

**FB15k-237数据集**:
- learning_rate: 0.00005 (5e-5)
- max_steps: 100,000
- warm_up_steps: 50,000

训练过程:
- Step 0-50,000: lr = 0.00005
- Step 50,000-100,000: lr = 0.000005 (5e-6)

**为什么小数据集用大学习率？**

| 数据集规模 | 学习率 | 原因 |
|-----------|--------|------|
| 小 (<10K) | 0.0001 | 数据少，梯度估计噪声大，需要大步长快速探索 |
| 中 (10-50K) | 0.00005-0.0001 | 平衡收敛速度和稳定性 |
| 大 (>100K) | 0.00005 | 数据多，梯度准确，用小学习率稳定训练 |

**学习率与批次大小的关系**:

理论上，批次增大时应相应增大学习率（线性缩放规则）:
```
new_lr = old_lr × √(new_batch / old_batch)  # 平方根缩放
或
new_lr = old_lr × (new_batch / old_batch)   # 线性缩放
```

示例:
- batch_size=256, lr=0.0001
- 增大到 batch_size=512 → lr ≈ 0.00014 (平方根缩放)
- 增大到 batch_size=1024 → lr ≈ 0.0002

**学习率过大的症状**:
1. ❌ **训练loss震荡**: 上下波动剧烈，不收敛
2. ❌ **Loss变为NaN**: 梯度爆炸，参数变为无穷大
3. ❌ **验证集性能差**: 无法找到好的局部最优
4. ❌ **参数更新过大**: 每步更新后模型性能大幅下降

观察日志示例（learning_rate过大）:
```
Step 100: loss=2.345
Step 200: loss=1.823
Step 300: loss=3.567   ← 突然上升
Step 400: loss=NaN     ← 发散
```

**学习率过小的症状**:
1. ⚠️ **收敛极慢**: 几万步后loss仍然很高
2. ⚠️ **陷入局部最优**: 过早收敛到次优解
3. ⚠️ **训练时间过长**: 需要非常多的步数才能达到目标

观察日志示例（learning_rate过小）:
```
Step 1000: loss=4.235
Step 2000: loss=4.198   ← 下降缓慢
Step 3000: loss=4.165
Step 10000: loss=3.987  ← 依然在慢慢下降
```

**不同数据集的学习率设置对比**:

| 数据集 | 训练集大小 | learning_rate | warm_up_steps | 衰减后lr |
|--------|-----------|---------------|---------------|----------|
| Family | 3,007 | 0.0001 | 25,000 | 0.00001 |
| Kinship | 8,544 | 0.0001 | 15,000 | 0.00001 |
| UMLS | 5,216 | 0.0001 | 15,000 | 0.00001 |
| WN18RR | 86,835 | 0.00005 | 30,000 | 0.000005 |
| FB15k-237 | 272,115 | 0.00005 | 50,000 | 0.000005 |
| YAGO | 1,079,040 | 0.0001 | 30,000 | 0.00001 |

**特殊情况 - YAGO**: 虽然是超大数据集，但使用了0.0001的学习率。原因：
- 实体数极多（123,182），关系较少（37）
- 需要大学习率来快速学习稠密的实体嵌入
- 通过early warm_up_steps（30,000步即衰减）来控制

**调优学习率的方法**:

**方法一: 学习率范围测试 (LR Range Test)**
1. 从极小值开始（1e-6）
2. 每几百步将学习率翻倍
3. 记录loss变化
4. 选择loss下降最快时的学习率
5. 实际训练时用该值的 1/2 或 1/3

**方法二: 观察训练曲线**
1. 使用推荐值开始训练
2. 观察前1000步的loss曲线:
   - 下降平滑且稳定 → 学习率合适
   - 下降缓慢 → 增大1.5-2倍
   - 震荡剧烈 → 减小到 1/2 或 1/3
3. 根据观察调整后重新训练

**方法三: 网格搜索**
```
候选值: [1e-5, 5e-5, 1e-4, 5e-4]
对每个值训练5000步
选择验证集MRR最高的
```

**与其他参数的配合**:

1. **与 batch_size**:
   - batch_size 大 → 可用较大的 learning_rate
   - batch_size 小 → 用较小的 learning_rate

2. **与 weight_rule**:
   - weight_rule 大（规则权重高）→ 可能需要较小learning_rate（因为总梯度变大）
   - weight_rule 小 → 可以用推荐的learning_rate

3. **与 regularization**:
   - regularization > 0 → 可以用稍大的learning_rate（正则化有稳定作用）
   - regularization = 0 → 按推荐值

**实战技巧**:

1. **初期训练**: 用推荐值或稍小的值，确保训练稳定
2. **如果收敛慢**: 逐步增大（×1.5），直到出现震荡
3. **找到震荡临界**: 回退到震荡前的值
4. **最终训练**: 用找到的最佳值训练完整模型

**调试日志示例**:

好的学习率 (0.0001):
```
Step 100: loss=3.245  (fact: 2.1, rule: 1.145)
Step 200: loss=2.987  (fact: 1.9, rule: 1.087)  ← 稳定下降
Step 300: loss=2.756  (fact: 1.7, rule: 1.056)
Step 1000: loss=1.89  (fact: 1.1, rule: 0.79)
```

学习率过大 (0.001):
```
Step 100: loss=3.245  (fact: 2.1, rule: 1.145)
Step 200: loss=5.432  (fact: 3.8, rule: 1.632)  ← 突然上升
Step 300: loss=NaN    (fact: NaN, rule: NaN)   ← 训练崩溃
```

学习率过小 (0.00001):
```
Step 100: loss=4.156  (fact: 2.8, rule: 1.356)
Step 200: loss=4.142  (fact: 2.79, rule: 1.352) ← 几乎不变
Step 300: loss=4.129  (fact: 2.77, rule: 1.359)
Step 1000: loss=4.015 (fact: 2.65, rule: 1.365) ← 下降极慢
```

#### `max_steps`
- **类型**: Integer
- **说明**: 预训练阶段的最大迭代步数（总的梯度更新次数）
- **取值范围**: 15000-100000
- **推荐设置**:
  - 小数据集 (family, kinship, umls): `30000-50000`
  - 中等数据集 (wn18rr): `60000`
  - 大数据集 (FB15k-237, YAGO): `100000`

**详细说明**:

`max_steps` 是预训练阶段的总训练步数，每一步对应一次前向传播和反向传播（梯度更新）。这是控制训练时长最直接的参数。

**步数（Steps）vs 轮数（Epochs）**:
- **1 step** = 处理1个batch的数据 + 1次梯度更新
- **1 epoch** = 遍历完整个训练集1次
- **关系**: `steps_per_epoch = 训练集大小 / batch_size`
- **总轮数**: `total_epochs = max_steps / steps_per_epoch`

**实际案例计算**:

1. **UMLS数据集**:
   - 训练集大小: 5,216个三元组
   - batch_size: 256
   - steps_per_epoch: 5216 / 256 ≈ 20步
   - max_steps: 30,000
   - 实际训练轮数: 30000 / 20 = **1,500 epochs**

2. **FB15k-237数据集**:
   - 训练集大小: 272,115个三元组
   - batch_size: 1024
   - steps_per_epoch: 272115 / 1024 ≈ 266步
   - max_steps: 100,000
   - 实际训练轮数: 100000 / 266 ≈ **376 epochs**

3. **YAGO3-10数据集**:
   - 训练集大小: 1,079,040个三元组
   - batch_size: 1024
   - steps_per_epoch: 1079040 / 1024 ≈ 1054步
   - max_steps: 100,000
   - 实际训练轮数: 100000 / 1054 ≈ **95 epochs**

**关键观察**:
- 小数据集虽然max_steps较小，但实际训练轮数很多（1000+轮）
- 大数据集max_steps虽大，但实际训练轮数适中（100-400轮）
- 原因：小数据集需要更多轮次来充分学习规则和嵌入关系

**训练时长估算**:
假设每步训练时间为 `t` 秒：
- **总训练时间** = `max_steps × t`
- 典型情况: t ≈ 0.5-2秒/步（取决于硬件和数据集）
- 例如: max_steps=50000, t=1秒/步 → 总时长约14小时

**与其他参数的配合**:

1. **valid_steps**: 每1000步验证一次
   - max_steps=30000 → 总共验证30次
   - max_steps=100000 → 总共验证100次

2. **warm_up_steps**: 学习率预热步数
   - 默认: warm_up_steps = max_steps / 2
   - UMLS: warm_up_steps = 15000（前15000步正常学习率，之后降低）
   - YAGO: warm_up_steps = 30000（指定值）

3. **log_steps**: 每100步打印一次日志
   - max_steps=30000 → 打印300次日志
   - 便于监控训练进度

**训练阶段划分**:
```
Step 0 ──────► warm_up_steps ──────► max_steps
    |              |                      |
    |              |                      |
  开始      学习率衰减点              训练结束
           (lr → lr/10)
```

**如何判断max_steps是否足够**:

观察验证集MRR曲线:
- **持续上升**: 增大max_steps（+20000~50000）
- **早期收敛后平稳**: 可以减少max_steps节省时间
- **震荡不稳定**: 可能学习率过大或batch_size太小
- **先升后降**: 出现过拟合，减少max_steps或增加正则化

**不同规模数据集的策略**:

| 数据集规模 | 三元组数量 | max_steps | 实际epochs | 训练时长估计 |
|-----------|-----------|-----------|-----------|------------|
| 极小 (<5K) | 3,000 | 30,000 | 2,500+ | 8-12小时 |
| 小 (5-10K) | 5,000 | 30,000 | 1,500 | 8-15小时 |
| 中 (10-50K) | 40,000 | 60,000 | 400 | 15-30小时 |
| 大 (100K-500K) | 270,000 | 100,000 | 380 | 1-2天 |
| 超大 (>500K) | 1,000,000+ | 100,000 | 100 | 2-4天 |

**调优建议**:
1. **初始设置**: 根据数据集规模选择推荐值
2. **观察收敛**: 每1000步查看验证集MRR
3. **早停策略**: 如果连续5次验证无提升，可提前停止
4. **时间预算**: 如果时间有限，可先用较小的max_steps（如20000）快速实验
5. **最终训练**: 确定好其他超参数后，用足够大的max_steps训练最终模型

#### `warm_up_steps`
- **类型**: Integer / null
- **说明**: 学习率预热步数，之后学习率会衰减
- **默认值**: `null` (自动设为 `max_steps / 2`)
- **作用**: 前期使用较高学习率快速收敛，后期降低学习率精调

#### `valid_steps`
- **类型**: Integer
- **说明**: 每隔多少步在验证集上评估一次
- **推荐值**: `1000`
- **作用**: 用于选择最佳模型checkpoint

#### `log_steps`
- **类型**: Integer
- **说明**: 每隔多少步打印一次训练日志
- **推荐值**: `100`

#### `save_checkpoint_steps`
- **类型**: Integer
- **说明**: 每隔多少步保存一次checkpoint
- **推荐值**: `10`

### 损失函数参数

#### `gamma_fact`
- **类型**: Float
- **说明**: 知识图谱三元组的margin值γ
- **取值范围**: 6.0-24.0
- **推荐设置**:
  - 一般数据集: `6.0-9.0`
  - YAGO (大规模): `24.0`
- **作用**: 控制正负样本之间的间隔，值越大要求区分度越高

#### `gamma_rule`
- **类型**: Float
- **说明**: 规则嵌入的margin值γ
- **取值范围**: 1.0-24.0
- **推荐设置**:
  - Family: `1.0`
  - WN18RR: `2.0`
  - Kinship: `5.0`
  - UMLS: `8.0`
  - FB15k-237, YAGO: `9.0-24.0`
- **作用**: 控制规则头和规则体之间的嵌入距离

#### `weight_rule`
- **类型**: Float
- **说明**: 规则损失在总损失中的权重
- **取值范围**: 0.5-10
- **推荐设置**:
  - WN18RR: `0.5`
  - UMLS, Family: `1.0`
  - Kinship, FB15k-237: `3.0`
  - YAGO: `10.0`
- **作用**: 平衡知识图谱三元组损失和规则损失
- **调优建议**: 规则质量高、数量多的数据集可增大该值

#### `regularization`
- **类型**: Float
- **说明**: L2 正则化系数（也称为权重衰减）
- **取值范围**: 0-0.1
- **推荐值**:
  - 无正则化: `0` (Family, FB15k-237, YAGO)
  - 使用正则化: `0.1` (WN18RR, Kinship, UMLS)

**详细说明**:

正则化是防止模型过拟合的重要技术。L2正则化通过在损失函数中添加参数的L2范数惩罚项，使模型倾向于学习更小的权重值。

**什么是L2正则化？**

不使用正则化时的损失函数：
```
Loss = Loss_fact + Loss_rule
```

使用L2正则化后：
```
Loss = Loss_fact + Loss_rule + regularization × (||entity_emb||² + ||relation_emb||²)
```

其中：
- `||entity_emb||²`: 所有实体嵌入的L2范数平方和
- `||relation_emb||²`: 所有关系嵌入的L2范数平方和
- `regularization`: 正则化系数，控制惩罚强度

**在RulE模型中的应用**:

代码实现 (trainer.py:197-208):
```python
if args.regularization:
    # 对实体嵌入施加L2惩罚
    regularization = args.regularization * (
        ent[0].norm(p=2)**2 +  # head embeddings
        ent[1].norm(p=2)**2    # tail embeddings
    ) / ent[0].shape[0]

    loss = loss + regularization
else:
    regularization = torch.tensor([0])
```

**注意**: 只对**实体嵌入**施加正则化，不对关系嵌入和规则嵌入正则化。

**为什么只正则化实体嵌入？**

1. **实体数量多**: 数据集中实体数量远多于关系数量
   - UMLS: 135个实体 vs 46个关系
   - FB15k-237: 14,541个实体 vs 237个关系
   - YAGO: 123,182个实体 vs 37个关系

2. **过拟合风险**: 实体嵌入参数量大，更容易过拟合
   - 实体参数量 = num_entities × hidden_dim × 2
   - 关系参数量 = num_relations × hidden_dim
   - 例如 UMLS: 实体参数 540,000 vs 关系参数 92,000

3. **规则嵌入特殊性**: 规则嵌入已经通过 margin-based loss 约束

**不同数据集的正则化策略**:

| 数据集 | regularization | 原因 |
|--------|----------------|------|
| Family | 0 | 实体少（3,007），规则密集，不易过拟合 |
| Kinship | 0.1 | 实体虽少（104）但训练轮数多，需正则化 |
| UMLS | 0 | 医学数据质量高，不需要正则化 |
| WN18RR | 0.1 | 实体多（40,943），需要正则化 |
| FB15k-237 | 0 | 已有负采样和margin约束 |
| YAGO | 0 | 超大规模，训练本身有正则效果 |

**正则化系数的影响**:

**regularization = 0 (无正则化)**:
- ✅ 模型容量更大，可以学习复杂模式
- ✅ 训练集性能可能更好
- ❌ 可能过拟合，验证集性能差
- ❌ 嵌入向量可能过大

**regularization = 0.1 (中等正则化)**:
- ✅ 防止过拟合，泛化能力强
- ✅ 嵌入向量更小，更稳定
- ✅ 验证集性能通常更好
- ❌ 模型容量受限
- ❌ 训练集性能可能略降

**regularization > 0.1 (强正则化)**:
- ✅ 极强的泛化能力
- ❌ 可能欠拟合
- ❌ 训练集和验证集性能都下降

**正则化系数的选择方法**:

**方法一: 观察过拟合**
1. 训练时不使用正则化 (regularization=0)
2. 观察训练集loss和验证集MRR:
   - 训练集loss持续下降但验证集MRR不升反降 → 过拟合，需正则化
   - 两者都稳定提升 → 不需要正则化
3. 如果需要正则化，从0.01开始尝试

**方法二: 网格搜索**
```
候选值: [0, 0.01, 0.05, 0.1]
在验证集上选择MRR最高的
```

**方法三: 根据数据集特点**
- 实体数 < 1000 → regularization = 0
- 实体数 1000-10000 → regularization = 0 或 0.01
- 实体数 > 10000 → regularization = 0.1

**训练日志对比**:

**无正则化 (regularization=0)**:
```
Step 1000: loss=1.89 (fact: 1.1, rule: 0.79, reg: 0.00)
Step 2000: loss=1.45 (fact: 0.85, rule: 0.60, reg: 0.00)
Step 3000: loss=1.12 (fact: 0.65, rule: 0.47, reg: 0.00)

Valid Step 3000: MRR=0.385, H@10=0.62
```

**使用正则化 (regularization=0.1)**:
```
Step 1000: loss=2.15 (fact: 1.1, rule: 0.79, reg: 0.26)  ← 正则化惩罚
Step 2000: loss=1.78 (fact: 0.88, rule: 0.62, reg: 0.28)
Step 3000: loss=1.52 (fact: 0.72, rule: 0.52, reg: 0.28)

Valid Step 3000: MRR=0.398, H@10=0.65  ← 验证集性能更好
```

**实际案例 - WN18RR**:

WN18RR使用 regularization=0.1 的原因：
- 实体数量大（40,943个）
- 关系数量少（11个）
- 容易在实体嵌入上过拟合
- 正则化显著提升验证集MRR

训练曲线对比：
```
| Steps | reg=0 (MRR) | reg=0.1 (MRR) | 差异 |
|-------|-------------|---------------|------|
| 10000 | 0.425       | 0.418         | -0.7% |
| 30000 | 0.448       | 0.452         | +0.9% | ← 正则化开始发挥作用
| 60000 | 0.451       | 0.461         | +2.2% | ← 最终性能提升
```

**与其他参数的配合**:

1. **与 learning_rate**:
   - regularization > 0 → 可以用稍大的learning_rate
   - regularization = 0 → 按常规选择learning_rate

2. **与 hidden_dim**:
   - hidden_dim 大 → 建议使用正则化（参数多，易过拟合）
   - hidden_dim 小 → 可以不用正则化

3. **与 max_steps**:
   - max_steps 大（训练时间长）→ 更需要正则化
   - max_steps 小 → 可能不需要正则化

**Grounding阶段的正则化**:

在规则落地阶段，`weight_decay`参数控制正则化（trainer.py:396-399）:
```python
optimizer = torch.optim.Adam(
    filter(lambda p: p.requires_grad, self.model.parameters()),
    lr=float(args.g_lr),
    weight_decay=float(args.weight_decay)  # Grounding阶段的正则化
)
```

**所有数据集都使用 `weight_decay=0`**，原因：
- Grounding阶段只训练MLP参数（参数量小）
- 训练轮数少（10-20轮），不易过拟合
- MLP已经使用LayerNorm，有正则效果

**调优建议**:

1. **首次训练**: 从 regularization=0 开始
2. **观察过拟合**:
   - 训练loss下降但验证MRR下降 → 增加正则化到0.01
   - 训练和验证都正常 → 保持0
3. **网格搜索**: [0, 0.01, 0.05, 0.1]
4. **最终模型**: 选择验证集MRR最高的值

**常见问题**:

**Q: 正则化系数设为0.5会怎样？**
A: 过强的正则化会导致欠拟合：
```
Step 10000: loss=5.2 (fact: 2.1, rule: 1.5, reg: 1.6)  ← 损失被正则项主导
Valid MRR: 0.25  ← 性能极差
```

**Q: 能否对规则嵌入也正则化？**
A: 不推荐。规则嵌入已经通过margin-based loss约束，额外正则化会影响规则学习。

**Q: 预训练和Grounding用不同的正则化系数？**
A: 是的：
- 预训练: 使用 `regularization`（0或0.1）
- Grounding: 使用 `weight_decay`（通常为0）

#### `disable_adv`
- **类型**: Boolean
- **说明**: 是否禁用对抗负采样
- **推荐值**: `false`
- **作用**: `true` 时使用均匀负采样，`false` 时使用对抗负采样

#### `adversarial_temperature`
- **类型**: Float
- **说明**: 对抗负采样的温度系数
- **取值范围**: 0.25-1.0
- **推荐值**: `0.5-1.0`
- **作用**: 控制负样本采样的分布，值越大采样越均匀

#### `uni_weight`
- **类型**: Boolean
- **说明**: 是否使用统一权重
- **推荐值**: `false`
- **作用**: `false` 时使用类似 word2vec 的子采样加权策略

---

## 规则落地阶段超参数

规则落地阶段固定预训练的嵌入，只训练用于聚合规则特征的MLP参数。

### `mlp_rule_dim`
- **类型**: Integer
- **说明**: MLP 规则特征的维度
- **取值范围**: 16-100
- **推荐设置**:
  - FB15k-237, WN18RR, YAGO: `16-50`
  - 其他数据集: `100`
- **作用**: 控制规则特征向量的大小

### `g_lr` (Grounding Learning Rate)
- **类型**: Float
- **说明**: 规则落地阶段的学习率
- **取值范围**: 0.0001-0.01
- **推荐设置**:
  - 小数据集: `0.0001-0.0005`
  - 中等数据集: `0.005`
  - 大数据集: `0.01`
- **注意**: 该阶段学习率一般比预训练阶段高

### `g_batch_size`
- **类型**: Integer
- **说明**: 规则落地（Grounding）训练的批次大小
- **取值范围**: 4-32
- **推荐设置**:
  - YAGO (超大规模): `4`
  - Family, Kinship (小规模): `32`
  - UMLS, WN18RR, FB15k-237: `16-32`

**详细说明**:

`g_batch_size` 是规则落地阶段的批次大小，与预训练阶段的 `batch_size` 有本质区别。这个参数对内存消耗的影响非常大。

**为什么Grounding批次要小？**

规则落地阶段的计算过程与普通训练完全不同：

1. **图遍历操作**: 对每个查询 (h, r)，需要：
   - 检索所有头为r的规则
   - 对每条规则进行多跳图传播
   - 统计规则落地到各个候选实体的次数

2. **内存密集型**:
   - 需要在GPU上维护整个知识图谱的邻接表
   - 每个批次都要为所有实体创建评分向量
   - 规则传播涉及稀疏矩阵运算

3. **计算复杂度高**:
   - 假设有 N 个实体, R 条规则, L 是规则平均长度
   - 每个查询的复杂度: O(R × L × N × 平均出度)

**工作流程示例**:

假设 g_batch_size = 16:
```
批次中的16个查询: [(h₁,r₁), (h₂,r₂), ..., (h₁₆,r₁₆)]

对于查询 (h₁, r₁):
1. 找到关系r₁的所有规则，例如3条规则:
   Rule1: r₁ ← r_a ∧ r_b (规则长度=2)
   Rule2: r₁ ← r_c ∧ r_d ∧ r_e (规则长度=3)
   Rule3: r₁ ← r_f (规则长度=1)

2. 从h₁开始，沿着规则体传播:
   Rule1: h₁ --r_a--> {候选集1} --r_b--> {最终候选集}
   Rule2: h₁ --r_c--> {候选集1} --r_d--> {候选集2} --r_e--> {最终候选集}
   Rule3: h₁ --r_f--> {最终候选集}

3. 统计每个实体被规则覆盖的次数

4. 对所有候选实体打分（维度: num_entities）

5. 合并16个查询的结果，计算损失，更新参数
```

**内存消耗分析**:

以 FB15k-237 为例:
- 实体数: 14,541
- 关系数: 237
- 规则数: ~1000条

每个查询需要的显存:
- 候选评分向量: 14,541 × 4 bytes = 58KB
- 规则传播中间结果: 约 1-10MB（取决于规则复杂度）
- 邻接表和索引: 常驻显存 500MB-2GB

如果 g_batch_size = 32:
- 总显存需求: 32 × 10MB + 2GB ≈ 2.3GB（仅计算中间结果）
- 加上模型参数和梯度: 可能需要 6-8GB

如果 g_batch_size = 4:
- 总显存需求: 4 × 10MB + 2GB ≈ 2.04GB
- 显著降低峰值内存

**不同数据集的批次大小选择**:

| 数据集 | 实体数 | 关系数 | 规则数 | g_batch_size | 原因 |
|--------|--------|--------|--------|--------------|------|
| **Family** | 3,007 | 12 | ~50 | 32 | 实体少，规则简单，可用大批次 |
| **Kinship** | 104 | 25 | ~100 | 32 | 实体很少，内存充足 |
| **UMLS** | 135 | 46 | ~200 | 16 | 实体少但规则多 |
| **WN18RR** | 40,943 | 11 | ~500 | 32 | 实体多但关系少，规则传播简单 |
| **FB15k-237** | 14,541 | 237 | ~1000 | 32 | 中等规模，平衡设置 |
| **YAGO3-10** | 123,182 | 37 | ~2000 | 4 | 实体数极多，必须用小批次 |

**实际训练对比**:

**小批次 (g_batch_size=4)**:
- ✅ 内存安全，不易OOM
- ✅ 适合超大规模数据集
- ❌ 训练速度慢（每个epoch时间长）
- ❌ 梯度估计噪声大

**大批次 (g_batch_size=32)**:
- ✅ 训练速度快
- ✅ 梯度估计准确
- ✅ GPU利用率高
- ❌ 可能OOM
- ❌ 不适合大规模数据集

**训练速度对比**:

假设数据集有 10,000 个测试查询:
- g_batch_size=4: 需要 10000/4 = 2500批次
- g_batch_size=16: 需要 10000/16 = 625批次
- g_batch_size=32: 需要 10000/32 = 313批次

如果每批次耗时相同（实际大批次稍快），批次数少的训练快4-8倍。

**与 num_iters 的配合**:

规则落地训练的总更新次数 = `数据集大小 / g_batch_size × num_iters`

例如 FB15k-237:
- 训练集大小: 272,115个三元组
- g_batch_size: 32
- num_iters: 20
- 每轮批次数: 272115 / 32 ≈ 8,504批次
- 总更新次数: 8504 × 20 = 170,080次

**调优建议**:
1. **首次训练**: 从16开始（安全的中间值）
2. **出现OOM**: 立即减半 (16→8→4)
3. **显存充足**: 尝试加倍 (16→32)
4. **超大数据集**: 直接用4或8
5. **观察GPU利用率**:
   - 利用率<50%且无OOM: 可增大批次
   - 利用率>90%: 批次合适
   - 频繁OOM: 必须减小批次

**特殊情况处理**:

如果即使 g_batch_size=1 仍然OOM:
1. 减小 hidden_dim (降低嵌入维度)
2. 减小 mlp_rule_dim (降低MLP特征维度)
3. 使用梯度累积（修改代码实现）
4. 使用CPU训练（会很慢）

### `num_iters`
- **类型**: Integer
- **说明**: 规则落地训练的迭代轮数（遍历整个训练集的次数）
- **推荐值**: `10-20`
- **推荐设置**:
  - Family, Kinship (小数据集): `10`
  - UMLS, WN18RR, FB15k-237, YAGO: `20`

**详细说明**:

`num_iters` 是规则落地（Grounding）阶段的训练轮数，与预训练阶段的 `max_steps` 在概念上不同。

**迭代（Iteration）vs 步数（Steps）**:

在Grounding阶段:
- **1 iteration (迭代)** = 完整遍历训练集1次 = 1 epoch
- **1 step** = 处理1个batch + 1次梯度更新
- **关系**: `steps_per_iteration = 训练集大小 / g_batch_size`
- **总步数**: `total_steps = num_iters × steps_per_iteration`

**与预训练阶段的对比**:

| 阶段 | 主要参数 | 含义 | 典型范围 |
|------|---------|------|---------|
| 预训练 | max_steps | 总梯度更新次数 | 30,000-100,000步 |
| Grounding | num_iters | 遍历训练集次数 | 10-20轮 |

为什么Grounding用"轮数"而不是"步数"？
- Grounding需要系统性地覆盖所有查询模式
- 每轮都会重新打乱数据，提供不同的训练顺序
- 一般10-20轮就能充分训练MLP参数

**实际案例计算**:

1. **UMLS数据集**:
   - 训练集: 5,216个三元组
   - g_batch_size: 16
   - num_iters: 20
   - 每轮步数: 5216 / 16 ≈ 326步
   - 总步数: 326 × 20 = **6,520步**
   - 训练时长: 约2-4小时（取决于硬件）

2. **FB15k-237数据集**:
   - 训练集: 272,115个三元组
   - g_batch_size: 32
   - num_iters: 20
   - 每轮步数: 272115 / 32 ≈ 8,504步
   - 总步数: 8504 × 20 = **170,080步**
   - 训练时长: 约1-2天

3. **YAGO3-10数据集**:
   - 训练集: 1,079,040个三元组
   - g_batch_size: 4
   - num_iters: 20
   - 每轮步数: 1079040 / 4 ≈ 269,760步
   - 总步数: 269760 × 20 = **5,395,200步**
   - 训练时长: 约3-5天

**为什么小数据集用10轮，大数据集用20轮？**

**小数据集 (num_iters=10)**:
- 训练样本少，容易过拟合
- MLP参数量相对较少
- 10轮已经足够收敛
- 更多轮次可能导致过拟合

**大数据集 (num_iters=20)**:
- 训练样本多，需要更多轮次充分学习
- 规则模式复杂，需要更多遍历
- 20轮收敛更充分
- 过拟合风险较小

**训练过程示例**:

假设 num_iters = 20，在 Family 数据集上:

```
Iteration 1/20:
  - 重新打乱训练集
  - 按关系分组，批次化
  - 遍历所有批次 (约94批)
  - 在验证集上评估
  - 保存checkpoint (如果是最佳)

Iteration 2/20:
  - 重新打乱训练集（顺序与第1轮不同）
  - 再次遍历所有批次
  - 评估...

...

Iteration 20/20:
  - 最后一轮训练
  - 最终评估
  - 选择最佳模型
```

**每轮的验证和保存**:

代码逻辑（trainer.py:419-456）:
```python
for k in range(num_iters):
    logging.info('| Iteration: {}/{}'.format(k + 1, num_iters))

    # 训练一轮
    self.train_step(...)

    # 在验证集上评估
    valid_mrr_iter = self.evaluate('valid', ...)

    # 如果验证集性能提升，保存模型
    if valid_mrr_iter > best_valid_mrr:
        best_valid_mrr = valid_mrr_iter
        self.save(...)
```

这意味着:
- 每轮结束都会验证
- 总共验证 `num_iters` 次
- 自动保存最佳模型

**实际训练曲线示例**:

典型的验证集MRR随迭代轮数变化:

```
Iteration    Valid MRR    说明
---------    ---------    ----
1            0.250        初始阶段，快速提升
2            0.280
3            0.310
4            0.335
5            0.355
...
10           0.420        小数据集此时可能已接近收敛
...
15           0.445        大数据集继续提升
16           0.448
17           0.449        开始趋于平稳
18           0.450
19           0.450        性能稳定
20           0.451        最终结果
```

**如何选择 num_iters**:

1. **默认策略**:
   - 小数据集 (<10K三元组): 10轮
   - 大数据集 (>100K三元组): 20轮

2. **观察收敛**:
   - 如果前10轮验证集MRR还在上升: 增加到20或30
   - 如果前5轮就平稳: 可以减少到10
   - 如果出现过拟合（验证集下降）: 减少轮数

3. **时间预算**:
   - 时间充足: 用20-30轮，确保充分训练
   - 时间紧张: 用10轮，快速得到结果
   - 快速实验: 用5轮，验证想法

**与其他参数的配合**:

1. **与 g_batch_size**:
   ```
   总更新次数 = (训练集大小 / g_batch_size) × num_iters

   相同总更新次数的不同组合:
   - g_batch_size=8, num_iters=40
   - g_batch_size=16, num_iters=20  ← 推荐平衡
   - g_batch_size=32, num_iters=10
   ```

2. **与 g_lr**:
   - 更多轮次 → 可用较小学习率（充分收敛）
   - 更少轮次 → 可用较大学习率（快速收敛）

3. **与 print_every**:
   - print_every=1000: 每1000批次打印一次
   - 如果每轮8500批次，每轮打印8-9次
   - num_iters=20，总共打印160-180次

**早停策略**:

虽然代码没有实现自动早停，但可以手动监控:

```
如果连续5轮验证集MRR无提升:
  - 可以提前停止训练
  - 使用已保存的最佳模型
  - 节省训练时间
```

例如:
- 设置 num_iters=30
- 第15轮达到最佳性能 (MRR=0.450)
- 第16-20轮无提升
- 可以在第20轮手动停止，不必等到第30轮

**不同阶段的迭代对比**:

| 阶段 | 概念 | 参数 | 典型值 | 实际轮数 |
|------|------|------|--------|---------|
| 预训练 | 步数优先 | max_steps | 30,000-100,000 | 100-2,500轮 |
| Grounding | 轮数优先 | num_iters | 10-20 | 10-20轮 |

**调优建议**:

1. **首次训练**: 使用推荐值（小数据集10，大数据集20）
2. **观察曲线**: 记录每轮的验证集MRR
3. **判断收敛**:
   - 还在上升 → 增加轮数
   - 已经平稳 → 保持不变
   - 出现过拟合 → 减少轮数
4. **时间权衡**: 在性能和时间之间找平衡
5. **最终模型**: 确定好参数后，可以用更多轮次（如30-50）训练最终模型

### `alpha`
- **类型**: Float
- **说明**: 融合KGE分数的权重系数
- **取值范围**: 1.0-5.0
- **推荐设置**:
  - WN18RR: `1.0`
  - UMLS: `2.0`
  - 其他: `3.0`
- **作用**: 在 `evaluate_t()` 中将规则分数与KGE分数结合: `score = rule_score + alpha * kge_score`
- **调优建议**: 如果KGE效果好，可增大alpha；如果规则质量高，可减小alpha

### `smoothing`
- **类型**: Float
- **说明**: 标签平滑系数
- **取值范围**: 0.2-0.5
- **推荐值**: `0.2-0.3`
- **作用**: 防止过拟合，计算方式: `target = target * smoothing + one_hot * (1 - smoothing)`

### `batch_per_epoch`
- **类型**: Integer
- **说明**: 每个epoch处理的批次数上限
- **推荐值**: `1000000`
- **作用**: 控制每轮训练的数据量，一般设为较大值

### `print_every`
- **类型**: Integer
- **说明**: 每隔多少批次打印一次训练信息
- **取值范围**: 10-1000
- **推荐设置**:
  - 小数据集: `10`
  - 大数据集: `1000`

### `weight_decay`
- **类型**: Float
- **说明**: 权重衰减系数 (L2正则化)
- **推荐值**: `0`
- **作用**: 防止过拟合，一般在规则落地阶段不使用

---

## 不同数据集的超参数对比

### 关键超参数对比表

| 数据集 | hidden_dim | gamma_fact | gamma_rule | weight_rule | max_steps | g_lr | alpha | smoothing |
|--------|------------|------------|------------|-------------|-----------|------|-------|-----------|
| **Family** | 2000 | 6.0 | 1.0 | 1.0 | 50000 | 0.0001 | 3.0 | 0.2 |
| **Kinship** | 2000 | 6.0 | 5.0 | 3.0 | 30000 | 0.0005 | 3.0 | 0.2 |
| **UMLS** | 2000 | 6.0 | 8.0 | 1.0 | 30000 | 0.0001 | 2.0 | 0.2 |
| **WN18RR** | 500 | 6.0 | 2.0 | 0.5 | 60000 | 0.005 | 1.0 | 0.3 |
| **FB15k-237** | 1000 | 9.0 | 9.0 | 3.0 | 100000 | 0.005 | 3.0 | 0.2 |
| **YAGO3-10** | 500 | 24.0 | 24.0 | 10.0 | 100000 | 0.01 | 3.0 | 0.2 |

### 数据集特点分析

#### **小规模数据集** (Family, Kinship)
- **特点**: 实体和关系较少，但规则密集
- **策略**:
  - 使用较大的 `hidden_dim` (2000)
  - 较短的训练步数 (30000-50000)
  - 较小的学习率 (0.0001)
  - 较少的grounding迭代 (10轮)

#### **医学领域数据集** (UMLS)
- **特点**: 中等规模，规则质量高
- **策略**:
  - 大嵌入维度 (2000)
  - 较高的 `gamma_rule` (8.0)
  - 较小的 `alpha` (2.0) - 更依赖规则推理

#### **词汇网络** (WN18RR)
- **特点**: 关系数量少但质量高
- **策略**:
  - 中等嵌入维度 (500)
  - 较低的 `weight_rule` (0.5)
  - 较低的 `alpha` (1.0)
  - 较高的 `smoothing` (0.3)

#### **大规模数据集** (FB15k-237)
- **特点**: 实体和关系数量多
- **策略**:
  - 较高的 `gamma_fact` 和 `gamma_rule` (9.0)
  - 较大的批次大小 (1024)
  - 长训练时间 (100000步)
  - 小的 `mlp_rule_dim` (16)

#### **超大规模数据集** (YAGO3-10)
- **特点**: 实体数量极多，三元组密集
- **策略**:
  - 非常高的margin值 (24.0)
  - 很高的 `weight_rule` (10.0)
  - 最高的 `g_lr` (0.01)
  - 最小的 `g_batch_size` (4) - 避免内存溢出

---

## 超参数调优建议

### 1. 嵌入维度 (`hidden_dim`)
- **起始值**: 从 500 开始
- **调优方向**:
  - 如果模型欠拟合，增大维度到 1000 或 2000
  - 如果内存不足，减小维度
- **经验**: 小数据集反而可以用大维度，因为规则密集

### 2. Margin值 (`gamma_fact`, `gamma_rule`)
- **起始值**: `gamma_fact=6`, `gamma_rule=5`
- **调优方向**:
  - 如果验证集性能不佳，尝试增大margin
  - 两个margin一般设为接近的值
  - 大规模数据集需要更大的margin

### 3. 规则权重 (`weight_rule`)
- **起始值**: `1.0`
- **调优方向**:
  - 观察训练日志中 `fact_loss` 和 `rule_loss` 的比例
  - 如果规则质量高、数量多，增大该值到 3-10
  - 如果规则噪声大，减小该值到 0.5

### 4. 学习率 (`learning_rate`, `g_lr`)
- **预训练学习率**: 从 0.00005 开始
- **Grounding学习率**: 从 0.001 开始
- **调优技巧**:
  - 预训练学习率要小，避免破坏嵌入结构
  - Grounding学习率可以大一些，因为只训练MLP
  - 使用 warm_up 策略

### 5. Alpha值 (`alpha`)
- **起始值**: `3.0`
- **调优方向**:
  - 先单独评估规则分数和KGE分数的效果
  - 如果KGE好，增大alpha；如果规则好，减小alpha
  - 通过网格搜索找最优值: [1.0, 2.0, 3.0, 5.0]

### 6. 训练步数 (`max_steps`, `num_iters`)
- **策略**:
  - 观察验证集MRR曲线
  - 如果持续上升，增加训练步数
  - 如果早期就收敛，可减少步数节省时间
  - Grounding阶段一般 10-20 轮足够

### 7. 批次大小 (`batch_size`, `g_batch_size`)
- **原则**:
  - 尽量用最大的批次（在内存允许范围内）
  - Grounding阶段批次要小，因为需要图遍历
  - 如果出现OOM错误，优先减小 `g_batch_size`

### 8. 负采样参数
- **负采样数量**: 一般是批次大小的 1-2 倍
- **对抗温度**: 0.5-1.0 之间
- **建议**: 先用对抗负采样，如果训练不稳定再换均匀采样

---

## 调参流程建议

### 阶段一: 基础配置
1. 设置数据路径和基本参数
2. 根据数据集规模选择 `hidden_dim`
3. 使用默认的 margin 和权重值

### 阶段二: 预训练调优
1. 调整 `learning_rate` 和 `max_steps`
2. 观察训练日志，平衡 `weight_rule`
3. 根据验证集表现调整 `gamma_fact` 和 `gamma_rule`
4. 实验不同的负采样策略

### 阶段三: Grounding调优
1. 固定预训练参数
2. 调整 `g_lr` 和 `num_iters`
3. 尝试不同的 `alpha` 值
4. 微调 `smoothing` 和 `mlp_rule_dim`

### 阶段四: 精细调优
1. 网格搜索关键参数组合
2. 进行多次实验取平均值
3. 分析错误案例，针对性调整

---

## 常见问题

### Q1: 训练过程中loss为NaN
**可能原因**:
- 学习率过大
- Margin值设置不当
- 梯度爆炸

**解决方案**:
- 减小学习率 (减半)
- 增加梯度裁剪
- 检查数据是否有异常值

### Q2: 验证集性能不提升
**可能原因**:
- 模型容量不足
- 训练步数不够
- 超参数不匹配

**解决方案**:
- 增大 `hidden_dim`
- 延长 `max_steps`
- 调整 `weight_rule` 平衡两个损失

### Q3: 内存溢出 (OOM)
**解决方案**:
- 减小 `g_batch_size` (最关键)
- 减小 `batch_size`
- 减小 `hidden_dim`
- 减少负采样数量

### Q4: Grounding阶段没有改进
**可能原因**:
- 预训练不充分
- `g_lr` 过小或过大
- `alpha` 设置不当

**解决方案**:
- 确保预训练充分收敛
- 调整 `g_lr` 到 0.001-0.01
- 尝试不同的 `alpha` 值

---

## 参数配置模板

### 新数据集快速开始模板

```json
{
    "data_path": "../data/your_dataset",
    "rule_file": "../data/your_dataset/mined_rules.txt",
    "cuda": true,
    "cpu_num": 10,
    "seed": 800,

    // 预训练参数
    "batch_size": 512,
    "negative_sample_size": 512,
    "rule_batch_size": 256,
    "rule_negative_size": 128,
    "hidden_dim": 1000,
    "gamma_fact": 6.0,
    "gamma_rule": 6.0,
    "learning_rate": 0.0001,
    "weight_rule": 1.0,
    "max_steps": 50000,
    "valid_steps": 1000,

    // Grounding参数
    "mlp_rule_dim": 50,
    "g_lr": 0.001,
    "g_batch_size": 16,
    "num_iters": 20,
    "alpha": 3.0,
    "smoothing": 0.2,

    // 其他参数
    "regularization": 0,
    "disable_adv": false,
    "adversarial_temperature": 0.5,
    "p_norm": 2,
    "save_path": "your_dataset"
}
```

根据实际数据集规模和特点，参考上述各数据集配置进行调整。

---

**文档版本**: v1.0
**最后更新**: 2025-01
