# RulEæ¨¡å‹å®Œæ•´æµç¨‹ç¤ºä¾‹

> **ç›®æ ‡**ï¼šé€šè¿‡ä¸€ä¸ªå…·ä½“ä¾‹å­ï¼Œä»å¤´åˆ°å°¾æ¼”ç¤ºRulEæ¨¡å‹å¦‚ä½•å·¥ä½œ
>
> **ç¤ºä¾‹æŸ¥è¯¢**ï¼šå›¾çµï¼ˆAlan Turingï¼‰çš„å›½ç±æ˜¯ä»€ä¹ˆï¼Ÿ

---

## ç›®å½•

1. [èƒŒæ™¯è®¾å®š](#1-èƒŒæ™¯è®¾å®š)
2. [é˜¶æ®µ1ï¼šé¢„è®­ç»ƒ - å­¦ä¹ åµŒå…¥](#2-é˜¶æ®µ1é¢„è®­ç»ƒ---å­¦ä¹ åµŒå…¥)
3. [é˜¶æ®µ2ï¼šè§„åˆ™Groundingè®­ç»ƒ](#3-é˜¶æ®µ2è§„åˆ™groundingè®­ç»ƒ)
4. [é˜¶æ®µ3ï¼šæ¨ç†é¢„æµ‹](#4-é˜¶æ®µ3æ¨ç†é¢„æµ‹)
5. [å®Œæ•´æ•°æ®æµ](#5-å®Œæ•´æ•°æ®æµ)

---

## 1. èƒŒæ™¯è®¾å®š

### 1.1 çŸ¥è¯†å›¾è°±æ•°æ®

å‡è®¾æˆ‘ä»¬æœ‰ä»¥ä¸‹çŸ¥è¯†å›¾è°±äº‹å®ï¼š

```
å®ä½“ï¼ˆEntitiesï¼‰:
  - Alan Turingï¼ˆå›¾çµï¼‰
  - Londonï¼ˆä¼¦æ•¦ï¼‰
  - Cambridgeï¼ˆå‰‘æ¡¥ï¼‰
  - Bletchley Parkï¼ˆå¸ƒè±åˆ‡åˆ©å›­ï¼‰
  - UKï¼ˆè‹±å›½ï¼‰
  - USAï¼ˆç¾å›½ï¼‰
  - Alonzo Churchï¼ˆä¸˜å¥‡ï¼‰

å…³ç³»ï¼ˆRelationsï¼‰:
  - born_inï¼ˆå‡ºç”Ÿäºï¼‰
  - city_ofï¼ˆåŸå¸‚å±äºï¼‰
  - nationalityï¼ˆå›½ç±ï¼‰
  - works_atï¼ˆå·¥ä½œäºï¼‰
  - org_countryï¼ˆç»„ç»‡æ‰€åœ¨å›½ï¼‰
  - friend_ofï¼ˆæœ‹å‹ï¼‰

ä¸‰å…ƒç»„äº‹å®ï¼ˆTriplesï¼‰:
  (Turing, born_in, London)
  (Turing, born_in, Cambridge)        # å¤šä¸ªå‡ºç”Ÿåœ°
  (London, city_of, UK)
  (Cambridge, city_of, UK)
  (Turing, works_at, Bletchley_Park)
  (Bletchley_Park, org_country, UK)
  (Turing, friend_of, Church)
  (Church, nationality, USA)
  (Turing, nationality, UK)            # è¿™æ˜¯æˆ‘ä»¬è¦é¢„æµ‹çš„ï¼
```

### 1.2 æŒ–æ˜çš„é€»è¾‘è§„åˆ™

ä½¿ç”¨RNNLogicç­‰å·¥å…·ä»æ•°æ®ä¸­æŒ–æ˜å‡ºçš„è§„åˆ™ï¼š

```
Rule1: born_in(x,y) âˆ§ city_of(y,z) â†’ nationality(x,z)
       (å‡ºç”Ÿåœ°æ‰€å±å›½ â†’ å›½ç±)

Rule2: friend_of(x,y) âˆ§ nationality(y,z) â†’ nationality(x,z)
       (æœ‹å‹çš„å›½ç± â†’ è‡ªå·±å›½ç±)

Rule3: works_at(x,y) âˆ§ org_country(y,z) â†’ nationality(x,z)
       (å·¥ä½œå•ä½æ‰€åœ¨å›½ â†’ å›½ç±)

Rule4: visits(x,y) âˆ§ located_in(y,z) â†’ nationality(x,z)
       (è®¿é—®è¿‡çš„åœ°æ–¹ â†’ å›½ç±)  # è¿™æ˜¯å™ªå£°è§„åˆ™ï¼
```

### 1.3 ä»»åŠ¡ç›®æ ‡

```
è®­ç»ƒé›†æŸ¥è¯¢: å·²çŸ¥æ‰€æœ‰äº‹å®
éªŒè¯é›†æŸ¥è¯¢: (Turing, nationality, ?)
æµ‹è¯•é›†æŸ¥è¯¢: é¢„æµ‹å…¶ä»–å®ä½“çš„å›½ç±

ç›®æ ‡: å­¦ä¹ èƒ½å¤Ÿå‡†ç¡®é¢„æµ‹å›½ç±çš„æ¨¡å‹
```

---

## 2. é˜¶æ®µ1ï¼šé¢„è®­ç»ƒ - å­¦ä¹ åµŒå…¥

### 2.1 åˆå§‹åŒ–

```python
# è¶…å‚æ•°è®¾å®š
hidden_dim = 3          # å®é™…ä¸­æ˜¯500-2000ï¼Œè¿™é‡Œç®€åŒ–ä¸º3ç»´
gamma_fact = 9.0        # Triplet margin
gamma_rule = 8.0        # Rule margin
num_entities = 7
num_relations = 6
num_rules = 4

# åˆå§‹åŒ–åµŒå…¥ï¼ˆéšæœºï¼‰
entity_embedding = nn.Embedding(7, 3*2)  # RotatEéœ€è¦2å€ç»´åº¦ï¼ˆå¤æ•°ï¼‰
relation_embedding = nn.Embedding(6, 3)   # å…³ç³»æ˜¯è§’åº¦
rule_embedding = nn.Parameter(torch.zeros(4, 3))  # è§„åˆ™åµŒå…¥
```

### 2.2 è®­ç»ƒæ•°æ®æ‰¹æ¬¡

```python
# Batch 1: Tripletæ•°æ®
positive_triplet = (Turing, born_in, London)
negative_triplet = (Turing, born_in, USA)  # è´Ÿé‡‡æ ·

# Batch 2: Ruleæ•°æ®
positive_rule = [Rule1_id, 2, nationality, born_in, city_of]
negative_rule = [Rule1_id, 2, nationality, born_in, works_at]  # æ›¿æ¢ä¸€ä¸ªå…³ç³»
```

### 2.3 å‰å‘ä¼ æ’­ - Triplet Loss

```python
# ============ Tripletéƒ¨åˆ†ï¼ˆRotatEï¼‰============

# 1. æå–åµŒå…¥
h_turing = entity_embedding[Turing]  # [3*2] = [6]ç»´
r_born_in = relation_embedding[born_in]  # [3]ç»´
t_london = entity_embedding[London]  # [6]ç»´

# 2. RotatEè®¡ç®—åˆ†æ•°
# å°†å®ä½“åµŒå…¥åˆ†ä¸ºå®éƒ¨å’Œè™šéƒ¨
h_re, h_im = h_turing[:3], h_turing[3:]  # å„[3]ç»´
t_re, t_im = t_london[:3], t_london[3:]

# å…³ç³»æ˜¯æ—‹è½¬ï¼ˆè½¬ä¸ºå¤æ•°ï¼‰
r_phase = r_born_in  # [3]ç»´è§’åº¦
r_re = torch.cos(r_phase)  # [cos(Î¸1), cos(Î¸2), cos(Î¸3)]
r_im = torch.sin(r_phase)  # [sin(Î¸1), sin(Î¸2), sin(Î¸3)]

# å¤æ•°ä¹˜æ³•: h â—¦ r
result_re = h_re * r_re - h_im * r_im
result_im = h_re * r_im + h_im * r_re

# è·ç¦»: d = |h â—¦ r - t|
distance_re = result_re - t_re
distance_im = result_im - t_im
distance = torch.sqrt(distance_re**2 + distance_im**2).sum()

# å¾—åˆ†ï¼ˆè¶Šé«˜è¶Šå¥½ï¼‰
pos_score = gamma_fact - distance

# 3. å¯¹è´Ÿæ ·æœ¬é‡å¤ç›¸åŒè®¡ç®—
t_usa = entity_embedding[USA]
# ... è®¡ç®—è¿‡ç¨‹ç›¸åŒ ...
neg_score = gamma_fact - distance_neg

# 4. Triplet Loss
triplet_loss = max(0, margin - (pos_score - neg_score))
```

**ç¬¬1ä¸ªepochåçš„åµŒå…¥ï¼ˆç¤ºä¾‹å€¼ï¼‰**ï¼š

```python
# å®ä½“åµŒå…¥ï¼ˆå¤æ•°å½¢å¼ï¼Œ[å®éƒ¨; è™šéƒ¨]ï¼‰
entity_embedding[Turing] = [0.2, 0.5, -0.3 | 0.1, -0.2, 0.4]
entity_embedding[London] = [0.3, 0.4, -0.1 | 0.2, -0.1, 0.3]
entity_embedding[UK] = [0.8, 0.9, 0.2 | 0.5, 0.3, 0.6]

# å…³ç³»åµŒå…¥ï¼ˆè§’åº¦ï¼‰
relation_embedding[born_in] = [0.5, 1.2, -0.3]
relation_embedding[city_of] = [0.8, -0.5, 0.9]
relation_embedding[nationality] = [1.3, 0.7, 0.6]
```

### 2.4 å‰å‘ä¼ æ’­ - Rule Loss

```python
# ============ Ruleéƒ¨åˆ† ============

# 1. æå–è§„åˆ™ä¿¡æ¯
rule_id = 0  # Rule1
rule_head = nationality
rule_body = [born_in, city_of]

# 2. æå–åµŒå…¥
rule_emb = rule_embedding[rule_id]  # [3]ç»´ï¼Œåˆå§‹ä¸º[0,0,0]
head_emb = relation_embedding[nationality]  # [1.3, 0.7, 0.6]
body_emb_1 = relation_embedding[born_in]    # [0.5, 1.2, -0.3]
body_emb_2 = relation_embedding[city_of]    # [0.8, -0.5, 0.9]

# 3. è®¡ç®—è§„åˆ™ä½“ç»„åˆ
body_sum = body_emb_1 + body_emb_2
         = [0.5, 1.2, -0.3] + [0.8, -0.5, 0.9]
         = [1.3, 0.7, 0.6]

# 4. è®¡ç®—è·ç¦»
# ç†æƒ³æƒ…å†µ: body_sum + rule_emb â‰ˆ head_emb
distance = torch.norm(body_sum + rule_emb - head_emb, p=1)
         = ||(1.3 + 0.0 - 1.3)|| + ||(0.7 + 0.0 - 0.7)|| + ||(0.6 + 0.0 - 0.6)||
         = 0.0  # å®Œç¾åŒ¹é…ï¼

# 5. è§„åˆ™å¾—åˆ†
pos_rule_score = gamma_rule - distance
               = 8.0 - 0.0
               = 8.0

# 6. è´Ÿæ ·æœ¬è§„åˆ™å¾—åˆ†
# è´Ÿè§„åˆ™: born_in âˆ§ works_at â†’ nationalityï¼ˆè¯­ä¹‰ä¸é€šï¼‰
neg_body_emb_2 = relation_embedding[works_at]  # å‡è®¾ä¸º[1.5, 0.2, -0.8]
neg_body_sum = body_emb_1 + neg_body_emb_2
             = [0.5, 1.2, -0.3] + [1.5, 0.2, -0.8]
             = [2.0, 1.4, -1.1]

neg_distance = torch.norm(neg_body_sum + rule_emb - head_emb, p=1)
             = ||[2.0 - 1.3]|| + ||[1.4 - 0.7]|| + ||[-1.1 - 0.6]||
             = 0.7 + 0.7 + 1.7
             = 3.1

neg_rule_score = gamma_rule - neg_distance
               = 8.0 - 3.1
               = 4.9

# 7. Rule Loss
rule_loss = max(0, margin - (pos_rule_score - neg_rule_score))
          = max(0, 1.0 - (8.0 - 4.9))
          = max(0, -2.1)
          = 0.0  # å·²ç»å¾ˆå¥½äº†
```

### 2.5 è”åˆè®­ç»ƒ

```python
# æ€»æŸå¤±
total_loss = triplet_loss + alpha * rule_loss
           = 0.5 + 1.0 * 0.0
           = 0.5

# åå‘ä¼ æ’­
total_loss.backward()

# æ›´æ–°æ‰€æœ‰å‚æ•°
optimizer.step()

# æ›´æ–°åçš„åµŒå…¥ä¼šæ›´å¥½åœ°æ»¡è¶³ï¼š
# 1. ä¸‰å…ƒç»„äº‹å®ï¼ˆé€šè¿‡triplet_lossï¼‰
# 2. é€»è¾‘è§„åˆ™ï¼ˆé€šè¿‡rule_lossï¼‰
```

**è®­ç»ƒ30000æ­¥åçš„åµŒå…¥ï¼ˆæ”¶æ•›å€¼ï¼‰**ï¼š

```python
# å…³ç³»åµŒå…¥ï¼ˆç»è¿‡è®­ç»ƒä¼˜åŒ–ï¼‰
relation_embedding[born_in] = [0.5, 1.2, -0.3]
relation_embedding[city_of] = [0.8, -0.5, 0.9]
relation_embedding[nationality] = [1.3, 0.7, 0.6]
relation_embedding[works_at] = [0.6, 0.8, -0.2]
relation_embedding[org_country] = [0.7, -0.1, 0.8]
relation_embedding[friend_of] = [0.3, 0.4, 0.1]

# è§„åˆ™åµŒå…¥ï¼ˆå­¦åˆ°çš„æ®‹å·®æ ¡æ­£å‘é‡ï¼‰
rule_embedding[Rule1] = [0.0, 0.0, 0.0]   # Rule1å®Œç¾ï¼Œä¸éœ€è¦æ ¡æ­£
rule_embedding[Rule2] = [-0.2, 0.1, -0.1] # Rule2éœ€è¦å°æ ¡æ­£
rule_embedding[Rule3] = [0.0, 0.0, -0.1]  # Rule3éœ€è¦å¾®è°ƒ
rule_embedding[Rule4] = [-2.5, 1.8, 3.2]  # Rule4æ˜¯å™ªå£°ï¼Œéœ€è¦å¤§æ ¡æ­£ä½†ä»æ— æ³•ä¿®å¤
```

### 2.6 éªŒè¯è§„åˆ™è´¨é‡

```python
# è®¡ç®—æ¯æ¡è§„åˆ™çš„ç½®ä¿¡åº¦

# Rule1: born_in âˆ§ city_of â†’ nationality
body_sum_1 = [0.5, 1.2, -0.3] + [0.8, -0.5, 0.9] = [1.3, 0.7, 0.6]
distance_1 = ||[1.3, 0.7, 0.6] + [0.0, 0.0, 0.0] - [1.3, 0.7, 0.6]|| = 0.0
confidence_1 = 8.0 - 0.0 = 8.0 â­â­â­â­â­

# Rule2: friend_of âˆ§ nationality â†’ nationality
body_sum_2 = [0.3, 0.4, 0.1] + [1.3, 0.7, 0.6] = [1.6, 1.1, 0.7]
distance_2 = ||[1.6, 1.1, 0.7] + [-0.2, 0.1, -0.1] - [1.3, 0.7, 0.6]|| = 0.6
confidence_2 = 8.0 - 0.6 = 7.4 â­â­â­â­

# Rule3: works_at âˆ§ org_country â†’ nationality
body_sum_3 = [0.6, 0.8, -0.2] + [0.7, -0.1, 0.8] = [1.3, 0.7, 0.6]
distance_3 = ||[1.3, 0.7, 0.6] + [0.0, 0.0, -0.1] - [1.3, 0.7, 0.6]|| = 0.1
confidence_3 = 8.0 - 0.1 = 7.9 â­â­â­â­â­

# Rule4: visits âˆ§ located_in â†’ nationalityï¼ˆå™ªå£°è§„åˆ™ï¼‰
body_sum_4 = [2.1, 0.3, 1.5] + [0.9, -0.4, 1.2] = [3.0, -0.1, 2.7]
distance_4 = ||[3.0, -0.1, 2.7] + [-2.5, 1.8, 3.2] - [1.3, 0.7, 0.6]|| = 6.4
confidence_4 = 8.0 - 6.4 = 1.6 â­

# æ€»ç»“ï¼š
# âœ“ å¥½è§„åˆ™ï¼ˆRule1,3ï¼‰å­¦åˆ°äº†é«˜ç½®ä¿¡åº¦ï¼ˆ8.0, 7.9ï¼‰
# âœ“ ä¸€èˆ¬è§„åˆ™ï¼ˆRule2ï¼‰å­¦åˆ°äº†ä¸­ç­‰ç½®ä¿¡åº¦ï¼ˆ7.4ï¼‰
# âœ“ åè§„åˆ™ï¼ˆRule4ï¼‰å­¦åˆ°äº†ä½ç½®ä¿¡åº¦ï¼ˆ1.6ï¼‰
```

---

## 3. é˜¶æ®µ2ï¼šè§„åˆ™Groundingè®­ç»ƒ

### 3.1 ç›®æ ‡

è®­ç»ƒMLPç½‘ç»œï¼Œå­¦ä¹ å¦‚ä½•èšåˆå¤šæ¡è§„åˆ™çš„é¢„æµ‹ç»“æœã€‚

**å…³é”®**ï¼šè¿™ä¸ªé˜¶æ®µ**å†»ç»“æ‰€æœ‰åµŒå…¥**ï¼Œåªè®­ç»ƒMLPå‚æ•°ã€‚

```python
# å†»ç»“é¢„è®­ç»ƒçš„åµŒå…¥
entity_embedding.requires_grad = False
relation_embedding.requires_grad = False
rule_embedding.requires_grad = False

# åªè®­ç»ƒMLP
mlp_feature = nn.Parameter(torch.randn(4, 100))  # 4æ¡è§„åˆ™ â†’ 100ç»´ç‰¹å¾
score_model = MLP(100, [128, 1])  # MLP: 100 â†’ 128 â†’ 1
```

### 3.2 è®­ç»ƒæ ·æœ¬

```python
# è®­ç»ƒæ ·æœ¬: (Turing, nationality, UK)
sample = [Turing_id, nationality_id, UK_id]
```

### 3.3 å‰å‘ä¼ æ’­ - Grounding

#### æ­¥éª¤1ï¼šæ‰¾åˆ°é€‚ç”¨çš„è§„åˆ™

```python
query_relation = nationality

applicable_rules = relation2rules[nationality]
# è¿”å›: [Rule1, Rule2, Rule3, Rule4]
```

#### æ­¥éª¤2ï¼šå¯¹æ¯æ¡è§„åˆ™è¿›è¡Œè·¯å¾„æšä¸¾ï¼ˆGroundingï¼‰

**Rule1: born_in âˆ§ city_of â†’ nationality**

```python
# åˆå§‹åŒ–
current_entities = one_hot(Turing)  # [1, 0, 0, 0, 0, 0, 0]
                                    # ç¬¬0ä½æ˜¯Turing

# ç¬¬1è·³: born_in
edge_index_born_in = [[Turing_id, Turing_id],    # æºèŠ‚ç‚¹
                      [London_id, Cambridge_id]]  # ç›®æ ‡èŠ‚ç‚¹
edge_weight = [1.0, 1.0]

# ä½¿ç”¨scatter_addä¼ æ’­
next_entities = scatter_add(
    src=current_entities[edge_index[0]] * edge_weight,  # [1.0, 1.0]
    index=edge_index[1],  # [London_id, Cambridge_id]
    dim_size=num_entities
)
# ç»“æœ: [0, 0, 1.0, 1.0, 0, 0, 0]
#           â†‘    â†‘
#        London Cambridge

current_entities = next_entities

# ç¬¬2è·³: city_of
edge_index_city_of = [[London_id, Cambridge_id],  # æºèŠ‚ç‚¹
                      [UK_id, UK_id]]              # ç›®æ ‡èŠ‚ç‚¹
edge_weight = [1.0, 1.0]

# å†æ¬¡ä¼ æ’­
next_entities = scatter_add(
    src=current_entities[edge_index[0]] * edge_weight,  # [1.0, 1.0]
    index=edge_index[1],  # [UK_id, UK_id]
    dim_size=num_entities
)
# ç»“æœ: [0, 0, 0, 0, 0, 2.0, 0]
#                       â†‘
#                      UK (2æ¡è·¯å¾„ï¼)

grounding_count_Rule1 = next_entities
# grounding_count_Rule1[UK] = 2.0
```

**Rule2: friend_of âˆ§ nationality â†’ nationality**

```python
# ç¬¬1è·³: friend_of
# Turing --friend_of--> Church
next_entities = [0, 0, 0, 0, 0, 0, 1.0]  # Church

# ç¬¬2è·³: nationality
# Church --nationality--> USA
next_entities = [0, 0, 0, 0, 0, 0, 1.0]  # USA

grounding_count_Rule2 = next_entities
# grounding_count_Rule2[UK] = 0.0
# grounding_count_Rule2[USA] = 1.0
```

**Rule3: works_at âˆ§ org_country â†’ nationality**

```python
# ç¬¬1è·³: works_at
# Turing --works_at--> Bletchley_Park
next_entities = [0, 0, 0, 0, 1.0, 0, 0]  # Bletchley_Park

# ç¬¬2è·³: org_country
# Bletchley_Park --org_country--> UK
next_entities = [0, 0, 0, 0, 0, 1.0, 0]  # UK

grounding_count_Rule3 = next_entities
# grounding_count_Rule3[UK] = 1.0
```

**Rule4: visits âˆ§ located_in â†’ nationality**

```python
# ç¬¬1è·³: visits
# æ²¡æœ‰visitsè¾¹ï¼
next_entities = [0, 0, 0, 0, 0, 0, 0]

grounding_count_Rule4 = next_entities
# grounding_count_Rule4[UK] = 0.0
```

#### æ­¥éª¤3ï¼šè®¡ç®—è§„åˆ™ç½®ä¿¡åº¦

```python
# ä½¿ç”¨é¢„è®­ç»ƒé˜¶æ®µå­¦åˆ°çš„è§„åˆ™åµŒå…¥è®¡ç®—ç½®ä¿¡åº¦
confidence_Rule1 = 8.0  # ä»é˜¶æ®µ1å­¦åˆ°çš„
confidence_Rule2 = 7.4
confidence_Rule3 = 7.9
confidence_Rule4 = 1.6
```

#### æ­¥éª¤4ï¼šæ„å»ºSoft Multi-hot Encoding

```python
# å¯¹å€™é€‰å®ä½“UKï¼Œæ„å»ºè§„åˆ™æ¿€æ´»å‘é‡

v_UK = [
    confidence_Rule1 * grounding_count_Rule1[UK],  # 8.0 Ã— 2.0 = 16.0
    confidence_Rule2 * grounding_count_Rule2[UK],  # 7.4 Ã— 0.0 = 0.0
    confidence_Rule3 * grounding_count_Rule3[UK],  # 7.9 Ã— 1.0 = 7.9
    confidence_Rule4 * grounding_count_Rule4[UK],  # 1.6 Ã— 0.0 = 0.0
]
# v_UK = [16.0, 0.0, 7.9, 0.0]

# å¯¹å€™é€‰å®ä½“USA
v_USA = [
    8.0 Ã— 0.0,  # 0.0
    7.4 Ã— 1.0,  # 7.4
    7.9 Ã— 0.0,  # 0.0
    1.6 Ã— 0.0,  # 0.0
]
# v_USA = [0.0, 7.4, 0.0, 0.0]
```

#### æ­¥éª¤5ï¼šMLPèšåˆå’Œè¯„åˆ†

```python
# å°†è§„åˆ™æ¿€æ´»å‘é‡è½¬æ¢ä¸ºMLPè¾“å…¥ç‰¹å¾
# ä½¿ç”¨å¯å­¦ä¹ çš„çŸ©é˜µ mlp_feature [4, 100]
feature_UK = torch.mm(v_UK.unsqueeze(0), mlp_feature)  # [1, 100]

# é€šè¿‡MLPå¾—åˆ°è§„åˆ™å¾—åˆ†
rule_score_UK = score_model(feature_UK)  # [1, 1]
# å‡è®¾è¾“å‡º: 0.85

# åŒç†è®¡ç®—USA
feature_USA = torch.mm(v_USA.unsqueeze(0), mlp_feature)
rule_score_USA = score_model(feature_USA)
# å‡è®¾è¾“å‡º: 0.32

# æ‰€æœ‰å€™é€‰çš„è§„åˆ™å¾—åˆ†
rule_scores = [
    score_UK=0.85,
    score_USA=0.32,
    score_France=0.05,
    ...
]
```

### 3.4 æŸå¤±è®¡ç®—å’Œåå‘ä¼ æ’­

```python
# çœŸå®æ ‡ç­¾: UK
target = UK_id

# ä½¿ç”¨äº¤å‰ç†µæŸå¤±ï¼ˆå¸¦label smoothingï¼‰
loss = cross_entropy_with_smoothing(
    logits=rule_scores,  # [num_entities]
    target=target,
    smoothing=0.2
)

# åå‘ä¼ æ’­ï¼ˆåªæ›´æ–°MLPå‚æ•°ï¼‰
loss.backward()
optimizer.step()  # åªæ›´æ–° mlp_feature å’Œ score_model

# è®­ç»ƒå¤šä¸ªepochåï¼ŒMLPå­¦ä¼š:
# - é«˜å¾—åˆ†è§„åˆ™ï¼ˆRule1: 16.0ï¼‰â†’ é«˜è´¡çŒ®
# - ä¸­ç­‰è§„åˆ™ï¼ˆRule3: 7.9ï¼‰â†’ ä¸­ç­‰è´¡çŒ®
# - ä½å¾—åˆ†è§„åˆ™ï¼ˆRule2: 7.4, Rule4: 1.6ï¼‰â†’ ä½è´¡çŒ®
```

---

## 4. é˜¶æ®µ3ï¼šæ¨ç†é¢„æµ‹

### 4.1 æµ‹è¯•æŸ¥è¯¢

```python
# æµ‹è¯•: é¢„æµ‹å›¾çµçš„å›½ç±
query = (Turing, nationality, ?)
```

### 4.2 å®Œæ•´æ¨ç†æµç¨‹

#### Part A: KGEæ¨ç†ï¼ˆä½¿ç”¨RotatEï¼‰

```python
# å¯¹æ¯ä¸ªå€™é€‰å®ä½“è®¡ç®—KGEå¾—åˆ†

# å€™é€‰1: UK
h = entity_embedding[Turing]  # [6]ç»´
r = relation_embedding[nationality]  # [3]ç»´
t_uk = entity_embedding[UK]  # [6]ç»´

distance_uk = RotatE_distance(h, r, t_uk)
kge_score_uk = gamma_fact - distance_uk
# å‡è®¾: 9.0 - 0.5 = 8.5

# å€™é€‰2: USA
t_usa = entity_embedding[USA]
distance_usa = RotatE_distance(h, r, t_usa)
kge_score_usa = gamma_fact - distance_usa
# å‡è®¾: 9.0 - 3.2 = 5.8

# å€™é€‰3: France
t_france = entity_embedding[France]
kge_score_france = 9.0 - 7.5 = 1.5
```

#### Part B: è§„åˆ™æ¨ç†ï¼ˆä½¿ç”¨è®­ç»ƒå¥½çš„Groundingæ¨¡å‹ï¼‰

```python
# æ­¥éª¤1-4: ä¸è®­ç»ƒé˜¶æ®µç›¸åŒï¼Œè¿›è¡Œgroundingå’Œæ„å»ºç‰¹å¾
v_UK = [16.0, 0.0, 7.9, 0.0]
v_USA = [0.0, 7.4, 0.0, 0.0]
v_France = [0.0, 0.0, 0.0, 0.0]

# æ­¥éª¤5: é€šè¿‡è®­ç»ƒå¥½çš„MLPè®¡ç®—è§„åˆ™å¾—åˆ†
rule_score_uk = MLP(v_UK) = 0.92
rule_score_usa = MLP(v_USA) = 0.35
rule_score_france = MLP(v_France) = 0.05
```

#### Part C: ç»¼åˆå¾—åˆ†

```python
# è¶…å‚æ•°
beta = 0.5  # è§„åˆ™æƒé‡

# æœ€ç»ˆå¾—åˆ† = KGEå¾—åˆ† + beta Ã— è§„åˆ™å¾—åˆ†
final_score_uk = kge_score_uk + beta * rule_score_uk
               = 8.5 + 0.5 Ã— 0.92
               = 8.5 + 0.46
               = 8.96  â­â­â­â­â­

final_score_usa = kge_score_usa + beta * rule_score_usa
                = 5.8 + 0.5 Ã— 0.35
                = 5.8 + 0.175
                = 5.975  â­â­â­

final_score_france = kge_score_france + beta * rule_score_france
                   = 1.5 + 0.5 Ã— 0.05
                   = 1.525  â­

# æ’åº
æ’å1: UK (8.96)     âœ“ æ­£ç¡®ç­”æ¡ˆï¼
æ’å2: USA (5.975)
æ’å3: France (1.525)
...

# é¢„æµ‹ç»“æœ: UK
```

### 4.3 ä¸ºä»€ä¹ˆUKå¾—åˆ†æœ€é«˜ï¼Ÿ

**åˆ†è§£åˆ†æ**ï¼š

```
UKçš„å¾—åˆ†æ¥æº:
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
1. KGEéƒ¨åˆ†è´¡çŒ®: 8.5
   - å®ä½“å’Œå…³ç³»åµŒå…¥çš„å‡ ä½•è·ç¦»å¾ˆè¿‘
   - è¯´æ˜: æ¨¡å‹ä»ä¸‰å…ƒç»„ä¸­å­¦åˆ°äº†"Turing-nationality-UK"çš„æ¨¡å¼

2. è§„åˆ™éƒ¨åˆ†è´¡çŒ®: 0.46 (= 0.5 Ã— 0.92)
   æ¥è‡ª3æ¡æ¿€æ´»çš„è§„åˆ™:

   Rule1 (born_in âˆ§ city_of):
     â€¢ è·¯å¾„æ•°: 2æ¡
       - Turing â†’ London â†’ UK
       - Turing â†’ Cambridge â†’ UK
     â€¢ ç½®ä¿¡åº¦: 8.0
     â€¢ è´¡çŒ®: 8.0 Ã— 2.0 = 16.0  â† æœ€å¤§è´¡çŒ®ï¼

   Rule3 (works_at âˆ§ org_country):
     â€¢ è·¯å¾„æ•°: 1æ¡
       - Turing â†’ Bletchley_Park â†’ UK
     â€¢ ç½®ä¿¡åº¦: 7.9
     â€¢ è´¡çŒ®: 7.9 Ã— 1.0 = 7.9

   Rule2, Rule4: æœªæ¿€æ´»æˆ–ç½®ä¿¡åº¦ä½

   MLPèšåˆ: [16.0, 0.0, 7.9, 0.0] â†’ 0.92

3. æ€»åˆ†: 8.5 + 0.46 = 8.96 âœ“
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

USAçš„å¾—åˆ†æ¥æº:
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
1. KGEéƒ¨åˆ†: 5.8
   - è·ç¦»è¾ƒè¿œï¼ˆæ²¡å­¦åˆ°Turing-USAçš„å…³è”ï¼‰

2. è§„åˆ™éƒ¨åˆ†: 0.175 (= 0.5 Ã— 0.35)
   åªæœ‰Rule2æ¿€æ´»:

   Rule2 (friend_of âˆ§ nationality):
     â€¢ è·¯å¾„: Turing â†’ Church â†’ USA
     â€¢ ç½®ä¿¡åº¦: 7.4ï¼ˆä¸­ç­‰ï¼Œæœ‹å‹çš„å›½ç±ä¸ä¸€å®šç›¸åŒï¼‰
     â€¢ è´¡çŒ®: 7.4 Ã— 1.0 = 7.4

   MLPèšåˆ: [0.0, 7.4, 0.0, 0.0] â†’ 0.35

3. æ€»åˆ†: 5.8 + 0.175 = 5.975 âœ—
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

ç»“è®º:
UKèƒœå‡ºæ˜¯å› ä¸º:
âœ“ KGEæ”¯æŒå¼º (8.5 vs 5.8)
âœ“ è§„åˆ™æ”¯æŒå¼º (0.92 vs 0.35)
âœ“ å¤šæ¡é«˜è´¨é‡è§„åˆ™ + å¤šæ¡è·¯å¾„ = é«˜ç½®ä¿¡åº¦
```

---

## 5. å®Œæ•´æ•°æ®æµ

### 5.1 ç«¯åˆ°ç«¯æµç¨‹å›¾

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     è¾“å…¥: çŸ¥è¯†å›¾è°±                            â”‚
â”‚  Entities: Turing, London, UK, ...                          â”‚
â”‚  Relations: born_in, city_of, nationality, ...              â”‚
â”‚  Triples: (Turing, born_in, London), ...                    â”‚
â”‚  Rules: born_in âˆ§ city_of â†’ nationality, ...                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              é˜¶æ®µ1: é¢„è®­ç»ƒ (30000 steps)                      â”‚
â”‚                                                             â”‚
â”‚  Batchè®­ç»ƒ:                                                  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”               â”‚
â”‚  â”‚ Tripletæ•°æ®      â”‚  â”‚ Ruleæ•°æ®         â”‚               â”‚
â”‚  â”‚ (h, r, t)       â”‚  â”‚ [rule_id, ...]  â”‚               â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜               â”‚
â”‚           â†“                     â†“                           â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”               â”‚
â”‚  â”‚ RotatE Loss     â”‚  â”‚ RulE Loss       â”‚               â”‚
â”‚  â”‚ Î³ - ||hâ—¦r-t||   â”‚  â”‚ Î³ - ||Î£ráµ¢+R-r|| â”‚               â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜               â”‚
â”‚           â†“                     â†“                           â”‚
â”‚          Loss = L_triplet + Î± Ã— L_rule                     â”‚
â”‚                       â†“                                     â”‚
â”‚              æ›´æ–°æ‰€æœ‰åµŒå…¥å‚æ•°                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â†“
                   ä¿å­˜checkpoint
                            â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚           é˜¶æ®µ2: Groundingè®­ç»ƒ (20 epochs)                    â”‚
â”‚                                                             â”‚
â”‚  å†»ç»“åµŒå…¥ï¼Œåªè®­ç»ƒMLP:                                         â”‚
â”‚  entity_embedding.requires_grad = False                     â”‚
â”‚  relation_embedding.requires_grad = False                   â”‚
â”‚  rule_embedding.requires_grad = False                       â”‚
â”‚                                                             â”‚
â”‚  Sample: (Turing, nationality, UK)                         â”‚
â”‚           â†“                                                 â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”          â”‚
â”‚  â”‚  å¯¹æ¯æ¡è§„åˆ™è¿›è¡ŒGrounding                      â”‚          â”‚
â”‚  â”‚                                              â”‚          â”‚
â”‚  â”‚  Rule1: born_in âˆ§ city_of                   â”‚          â”‚
â”‚  â”‚  Turing â†’ London â†’ UK     (2æ¡è·¯å¾„)          â”‚          â”‚
â”‚  â”‚  Turing â†’ Cambridge â†’ UK                     â”‚          â”‚
â”‚  â”‚  count[UK] = 2.0                            â”‚          â”‚
â”‚  â”‚                                              â”‚          â”‚
â”‚  â”‚  Rule2: friend_of âˆ§ nationality             â”‚          â”‚
â”‚  â”‚  count[USA] = 1.0                           â”‚          â”‚
â”‚  â”‚                                              â”‚          â”‚
â”‚  â”‚  Rule3: works_at âˆ§ org_country              â”‚          â”‚
â”‚  â”‚  count[UK] = 1.0                            â”‚          â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜          â”‚
â”‚           â†“                                                 â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”          â”‚
â”‚  â”‚  è®¡ç®—è§„åˆ™ç½®ä¿¡åº¦ï¼ˆä½¿ç”¨rule_embeddingï¼‰         â”‚          â”‚
â”‚  â”‚  confidence = Î³ - distance                  â”‚          â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜          â”‚
â”‚           â†“                                                 â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”          â”‚
â”‚  â”‚  æ„å»ºSoft Multi-hot Encoding                â”‚          â”‚
â”‚  â”‚  v[i] = confidence[i] Ã— count[i]            â”‚          â”‚
â”‚  â”‚  v_UK = [16.0, 0.0, 7.9, 0.0]               â”‚          â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜          â”‚
â”‚           â†“                                                 â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”          â”‚
â”‚  â”‚  MLPèšåˆ â†’ è§„åˆ™å¾—åˆ†                          â”‚          â”‚
â”‚  â”‚  feature = v Ã— mlp_feature                  â”‚          â”‚
â”‚  â”‚  score = MLP(feature)                       â”‚          â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜          â”‚
â”‚           â†“                                                 â”‚
â”‚       Cross-Entropy Loss                                   â”‚
â”‚           â†“                                                 â”‚
â”‚   åªæ›´æ–°MLPå‚æ•°ï¼ˆmlp_feature, score_modelï¼‰                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â†“
                 ä¿å­˜grounding.pt
                            â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  é˜¶æ®µ3: æ¨ç†é¢„æµ‹                              â”‚
â”‚                                                             â”‚
â”‚  Query: (Turing, nationality, ?)                           â”‚
â”‚           â†“                                                 â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”          â”‚
â”‚  â”‚  KGEæ¨ç† (RotatE)  â”‚  â”‚  è§„åˆ™æ¨ç† (Grounding) â”‚          â”‚
â”‚  â”‚                    â”‚  â”‚                     â”‚          â”‚
â”‚  â”‚  å¯¹æ¯ä¸ªå€™é€‰:        â”‚  â”‚  1. è·¯å¾„æšä¸¾         â”‚          â”‚
â”‚  â”‚  score = Î³-||hâ—¦r-tâ”‚â”‚  â”‚  2. è®¡ç®—ç½®ä¿¡åº¦       â”‚          â”‚
â”‚  â”‚                    â”‚  â”‚  3. æ„å»ºç‰¹å¾å‘é‡     â”‚          â”‚
â”‚  â”‚  UK: 8.5          â”‚  â”‚  4. MLPèšåˆ         â”‚          â”‚
â”‚  â”‚  USA: 5.8         â”‚  â”‚                     â”‚          â”‚
â”‚  â”‚  France: 1.5      â”‚  â”‚  UK: 0.92           â”‚          â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚  USA: 0.35          â”‚          â”‚
â”‚                          â”‚  France: 0.05       â”‚          â”‚
â”‚                          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜          â”‚
â”‚           â†“                        â†“                        â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”          â”‚
â”‚  â”‚         ç»¼åˆå¾—åˆ†                             â”‚          â”‚
â”‚  â”‚  final = kge_score + Î² Ã— rule_score         â”‚          â”‚
â”‚  â”‚                                              â”‚          â”‚
â”‚  â”‚  UK: 8.5 + 0.5Ã—0.92 = 8.96  â† Winner!      â”‚          â”‚
â”‚  â”‚  USA: 5.8 + 0.5Ã—0.35 = 5.975               â”‚          â”‚
â”‚  â”‚  France: 1.5 + 0.5Ã—0.05 = 1.525            â”‚          â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜          â”‚
â”‚           â†“                                                 â”‚
â”‚      é¢„æµ‹ç»“æœ: UK âœ“                                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 5.2 å…³é”®å‚æ•°æ±‡æ€»

```python
# æ¨¡å‹å‚æ•°
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
entity_embedding: [7, 6]     # 7ä¸ªå®ä½“ï¼Œ6ç»´ï¼ˆå¤æ•°ï¼‰
relation_embedding: [6, 3]   # 6ä¸ªå…³ç³»ï¼Œ3ç»´ï¼ˆè§’åº¦ï¼‰
rule_embedding: [4, 3]       # 4æ¡è§„åˆ™ï¼Œ3ç»´ï¼ˆæ®‹å·®ï¼‰
mlp_feature: [4, 100]        # è§„åˆ™ç‰¹å¾æ˜ å°„
score_model: MLP(100â†’128â†’1)  # å¾—åˆ†ç½‘ç»œ

# è¶…å‚æ•°
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
hidden_dim = 3               # åµŒå…¥ç»´åº¦
gamma_fact = 9.0             # Triplet margin
gamma_rule = 8.0             # Rule margin
alpha = 1.0                  # Rule lossæƒé‡
beta = 0.5                   # æ¨ç†æ—¶è§„åˆ™å¾—åˆ†æƒé‡
learning_rate = 0.00005      # é¢„è®­ç»ƒå­¦ä¹ ç‡
g_lr = 0.0001                # Groundingå­¦ä¹ ç‡
max_steps = 30000            # é¢„è®­ç»ƒæ­¥æ•°
num_iters = 20               # Groundingè½®æ•°
batch_size = 256             # Triplet batch size
rule_batch_size = 128        # Rule batch size

# è®­ç»ƒåçš„åµŒå…¥ï¼ˆç¤ºä¾‹å€¼ï¼‰
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
relation_embedding:
  born_in:      [0.5, 1.2, -0.3]
  city_of:      [0.8, -0.5, 0.9]
  nationality:  [1.3, 0.7, 0.6]
  works_at:     [0.6, 0.8, -0.2]
  org_country:  [0.7, -0.1, 0.8]
  friend_of:    [0.3, 0.4, 0.1]

rule_embedding:
  Rule1: [0.0, 0.0, 0.0]    # å®Œç¾è§„åˆ™
  Rule2: [-0.2, 0.1, -0.1]  # éœ€è¦å°æ ¡æ­£
  Rule3: [0.0, 0.0, -0.1]   # éœ€è¦å¾®è°ƒ
  Rule4: [-2.5, 1.8, 3.2]   # å™ªå£°è§„åˆ™

è§„åˆ™ç½®ä¿¡åº¦:
  Rule1: 8.0 â­â­â­â­â­
  Rule2: 7.4 â­â­â­â­
  Rule3: 7.9 â­â­â­â­â­
  Rule4: 1.6 â­
```

### 5.3 æ¨ç†ç»“æœè§£é‡Š

```
æŸ¥è¯¢: (Turing, nationality, ?)
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

é¢„æµ‹ç­”æ¡ˆ: UK
ç½®ä¿¡åº¦: 8.96 / 10
æ’å: 1 / 7

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
ä¸ºä»€ä¹ˆé¢„æµ‹UKï¼Ÿ
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

âœ“ åŸºäºåµŒå…¥çš„è¯æ® (KGEå¾—åˆ†: 8.5):
  - entity_embeddingå’Œrelation_embeddingçš„å‡ ä½•å…³ç³»
  - ä»å¤§é‡ä¸‰å…ƒç»„ä¸­å­¦ä¹ åˆ°çš„æ¨¡å¼

âœ“ åŸºäºè§„åˆ™çš„è¯æ® (è§„åˆ™å¾—åˆ†: 0.92):

  Rule1 (ç½®ä¿¡åº¦ 8.0): born_in âˆ§ city_of â†’ nationality
    è·¯å¾„1: Turing â†’ born_in â†’ London â†’ city_of â†’ UK
    è·¯å¾„2: Turing â†’ born_in â†’ Cambridge â†’ city_of â†’ UK
    è´¡çŒ®: 8.0 Ã— 2.0 = 16.0 â­â­â­

  Rule3 (ç½®ä¿¡åº¦ 7.9): works_at âˆ§ org_country â†’ nationality
    è·¯å¾„1: Turing â†’ works_at â†’ Bletchley_Park â†’ org_country â†’ UK
    è´¡çŒ®: 7.9 Ã— 1.0 = 7.9 â­â­â­

  æ€»è§„åˆ™è´¡çŒ®: MLP([16.0, 0.0, 7.9, 0.0]) = 0.92

âœ“ ç»¼åˆåˆ¤æ–­:
  æœ€ç»ˆå¾—åˆ† = 8.5 (KGE) + 0.5 Ã— 0.92 (è§„åˆ™) = 8.96

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
ä¸ºä»€ä¹ˆä¸æ˜¯USAï¼Ÿ
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

âœ— KGEå¾—åˆ†ä½ (5.8):
  - è®­ç»ƒæ•°æ®ä¸­æ²¡æœ‰(Turing, nationality, USA)
  - åµŒå…¥ç©ºé—´è·ç¦»è¿œ

âœ— è§„åˆ™æ”¯æŒå¼± (0.35):
  åªæœ‰Rule2æ¿€æ´»:
  Rule2 (ç½®ä¿¡åº¦ 7.4): friend_of âˆ§ nationality â†’ nationality
    è·¯å¾„: Turing â†’ friend_of â†’ Church â†’ nationality â†’ USA
    è´¡çŒ®: 7.4 Ã— 1.0 = 7.4

  é—®é¢˜: ç½®ä¿¡åº¦ä¸­ç­‰ï¼ˆæœ‹å‹çš„å›½ç±â‰ è‡ªå·±å›½ç±ï¼‰
       åªæœ‰1æ¡è§„åˆ™æ”¯æŒ

âœ— æ€»åˆ†: 5.8 + 0.5 Ã— 0.35 = 5.975 < 8.96

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
```

---

## 6. æ ¸å¿ƒæœºåˆ¶æ€»ç»“

### 6.1 ä¸‰ä¸ªå…³é”®ç»„ä»¶

```
1. çŸ¥è¯†å›¾è°±åµŒå…¥ (RotatE)
   â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
   ä½œç”¨: å­¦ä¹ å®ä½“å’Œå…³ç³»çš„å‘é‡è¡¨ç¤º
   è¾“å…¥: ä¸‰å…ƒç»„ (h, r, t)
   è¾“å‡º: å¾—åˆ† Î³ - ||h â—¦ r - t||
   ä¼˜åŠ¿: æ³›åŒ–èƒ½åŠ›å¼ºï¼Œèƒ½å¤„ç†ä¸å®Œæ•´æ•°æ®

2. è§„åˆ™åµŒå…¥ (Rule Embedding)
   â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
   ä½œç”¨: å­¦ä¹ è§„åˆ™çš„è´¨é‡/ç½®ä¿¡åº¦
   è¾“å…¥: è§„åˆ™ râ‚ âˆ§ râ‚‚ â†’ râ‚ƒ
   è¾“å‡º: ç½®ä¿¡åº¦ Î³ - ||Î£ráµ¢ + R - râ‚ƒ||
   ä¼˜åŠ¿: åŒºåˆ†å¥½è§„åˆ™å’Œåè§„åˆ™

3. è½¯è§„åˆ™æ¨ç† (Soft Grounding)
   â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
   ä½œç”¨: æ ¹æ®è§„åˆ™è´¨é‡å’Œè·¯å¾„æ•°é‡åŠ æƒæ¨ç†
   è¾“å…¥: è§„åˆ™ + å›¾ç»“æ„
   è¾“å‡º: åŠ æƒåçš„è§„åˆ™å¾—åˆ†
   ä¼˜åŠ¿: é²æ£’ï¼Œå¯è§£é‡Š
```

### 6.2 ä¸ºä»€ä¹ˆRulEæœ‰æ•ˆï¼Ÿ

```
ä¼ ç»ŸKGEçš„é—®é¢˜:
âŒ åªçœ‹ä¸‰å…ƒç»„ï¼Œå¿½ç•¥é€»è¾‘è§„åˆ™
âŒ é»‘ç›’ï¼Œä¸å¯è§£é‡Š
âŒ æ³›åŒ–èƒ½åŠ›æœ‰é™

ä¼ ç»Ÿè§„åˆ™æ¨ç†çš„é—®é¢˜:
âŒ ç¡¬åŒ¹é…ï¼Œå¤ªè„†å¼±
âŒ æ— æ³•å¤„ç†å™ªå£°è§„åˆ™
âŒ è§„åˆ™å¿…é¡»å®Œå…¨åŒ¹é…æ‰ç”Ÿæ•ˆ

RulEçš„ä¼˜åŠ¿:
âœ“ è”åˆå­¦ä¹ ï¼šKGE + è§„åˆ™ï¼Œäº’ç›¸å¢å¼º
âœ“ è½¯æ¨ç†ï¼šæ ¹æ®ç½®ä¿¡åº¦åŠ æƒï¼Œä¸æ˜¯0/1
âœ“ è‡ªåŠ¨è¯„ä¼°ï¼šè§„åˆ™åµŒå…¥å­¦ä¹ è§„åˆ™è´¨é‡
âœ“ å¯è§£é‡Šï¼šå¯ä»¥çœ‹åˆ°å“ªäº›è§„åˆ™è¢«æ¿€æ´»
âœ“ é²æ£’æ€§ï¼šå¤šæ¡è§„åˆ™æŠ•ç¥¨ï¼Œé™ä½å™ªå£°å½±å“
```

### 6.3 å…³é”®åˆ›æ–°ç‚¹

```
1. ç»Ÿä¸€åµŒå…¥ç©ºé—´
   â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
   å®ä½“ã€å…³ç³»ã€è§„åˆ™éƒ½åµŒå…¥åˆ°åŒä¸€ç©ºé—´
   â†’ å¯ä»¥ç«¯åˆ°ç«¯è”åˆä¼˜åŒ–

2. è§„åˆ™ç½®ä¿¡åº¦å­¦ä¹ 
   â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
   ä¸æ˜¯äººå·¥è®¾å®šè§„åˆ™æƒé‡
   â†’ ä»æ•°æ®ä¸­è‡ªåŠ¨å­¦ä¹ å“ªäº›è§„åˆ™å¯ä¿¡

3. è½¯è§„åˆ™æ¨ç†
   â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
   ä¸æ˜¯ç¡¬æ€§åº”ç”¨è§„åˆ™ï¼ˆif-thenï¼‰
   â†’ æ ¹æ®ç½®ä¿¡åº¦å’Œè·¯å¾„æ•°åŠ æƒï¼ˆsoft votingï¼‰

4. åˆ†é˜¶æ®µè®­ç»ƒ
   â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
   å…ˆå­¦åµŒå…¥ï¼Œå†å­¦èšåˆ
   â†’ æ›´ç¨³å®šï¼Œæ›´å®¹æ˜“æ”¶æ•›
```

---

## 7. å®Œæ•´ç¤ºä¾‹çš„Pythonä¼ªä»£ç 

```python
import torch
import torch.nn as nn
from torch_scatter import scatter_add

# ========== é˜¶æ®µ1: é¢„è®­ç»ƒ ==========
class PreTraining:
    def __init__(self, num_entities=7, num_relations=6, num_rules=4, dim=3):
        # åˆå§‹åŒ–åµŒå…¥
        self.entity_emb = nn.Embedding(num_entities, dim * 2)  # å¤æ•°
        self.relation_emb = nn.Embedding(num_relations, dim)   # è§’åº¦
        self.rule_emb = nn.Parameter(torch.zeros(num_rules, dim))

        self.gamma_fact = 9.0
        self.gamma_rule = 8.0

    def forward_triplet(self, h, r, t):
        """è®¡ç®—Tripletå¾—åˆ†ï¼ˆRotatEï¼‰"""
        h_emb = self.entity_emb(h)  # [batch, dim*2]
        r_emb = self.relation_emb(r)  # [batch, dim]
        t_emb = self.entity_emb(t)

        # åˆ†ç¦»å¤æ•°
        h_re, h_im = h_emb[..., :3], h_emb[..., 3:]
        t_re, t_im = t_emb[..., :3], t_emb[..., 3:]

        # æ—‹è½¬
        r_re, r_im = torch.cos(r_emb), torch.sin(r_emb)
        result_re = h_re * r_re - h_im * r_im
        result_im = h_re * r_im + h_im * r_re

        # è·ç¦»
        distance = torch.sqrt(
            (result_re - t_re)**2 + (result_im - t_im)**2
        ).sum(dim=-1)

        return self.gamma_fact - distance

    def forward_rule(self, rule_sample):
        """è®¡ç®—è§„åˆ™å¾—åˆ†"""
        rule_id = rule_sample[:, 0]
        rule_length = rule_sample[:, 1]
        rule_head = rule_sample[:, 2]
        rule_body = rule_sample[:, 3:]

        # ç´¯åŠ è§„åˆ™ä½“
        body_sum = torch.zeros_like(self.relation_emb(rule_head))
        for i in range(rule_length.max()):
            mask = (i < rule_length)
            body_sum[mask] += self.relation_emb(rule_body[mask, i])

        # è®¡ç®—è·ç¦»
        rule_emb_vec = self.rule_emb[rule_id]
        head_emb = self.relation_emb(rule_head)
        distance = torch.norm(body_sum + rule_emb_vec - head_emb, p=1, dim=-1)

        return self.gamma_rule - distance

    def train(self, triplet_data, rule_data, steps=30000):
        optimizer = torch.optim.Adam(self.parameters(), lr=5e-5)

        for step in range(steps):
            # Triplet batch
            h, r, t_pos, t_neg = triplet_data.sample()
            pos_score = self.forward_triplet(h, r, t_pos)
            neg_score = self.forward_triplet(h, r, t_neg)
            loss_triplet = torch.relu(1.0 - (pos_score - neg_score)).mean()

            # Rule batch
            rule_pos, rule_neg = rule_data.sample()
            pos_rule_score = self.forward_rule(rule_pos)
            neg_rule_score = self.forward_rule(rule_neg)
            loss_rule = torch.relu(1.0 - (pos_rule_score - neg_rule_score)).mean()

            # è”åˆæŸå¤±
            loss = loss_triplet + loss_rule

            optimizer.zero_grad()
            loss.backward()
            optimizer.step()

            if step % 1000 == 0:
                print(f"Step {step}, Loss: {loss.item():.4f}")


# ========== é˜¶æ®µ2: Groundingè®­ç»ƒ ==========
class GroundingTraining:
    def __init__(self, pretrained_model, num_rules=4, mlp_dim=100):
        # å†»ç»“é¢„è®­ç»ƒå‚æ•°
        self.entity_emb = pretrained_model.entity_emb
        self.relation_emb = pretrained_model.relation_emb
        self.rule_emb = pretrained_model.rule_emb

        for param in [self.entity_emb, self.relation_emb, self.rule_emb]:
            param.requires_grad = False

        # å¯è®­ç»ƒçš„MLPå‚æ•°
        self.mlp_feature = nn.Parameter(torch.randn(num_rules, mlp_dim))
        self.score_model = nn.Sequential(
            nn.Linear(mlp_dim, 128),
            nn.ReLU(),
            nn.Linear(128, 1)
        )

        self.gamma_rule = 8.0

    def grounding(self, h, rule_body, graph):
        """è·¯å¾„æšä¸¾"""
        current = torch.zeros(graph.num_entities)
        current[h] = 1.0

        for relation in rule_body:
            # è·å–é‚»æ¥è¡¨
            edge_index, edge_weight = graph.adjacency[relation]

            # ä¼ æ’­
            current = scatter_add(
                src=current[edge_index[0]] * edge_weight,
                index=edge_index[1],
                dim=0,
                dim_size=graph.num_entities
            )

        return current  # grounding count

    def compute_confidence(self, rule_id, rule_body, rule_head):
        """è®¡ç®—è§„åˆ™ç½®ä¿¡åº¦"""
        body_sum = sum([self.relation_emb(r) for r in rule_body])
        rule_vec = self.rule_emb[rule_id]
        head_vec = self.relation_emb(rule_head)

        distance = torch.norm(body_sum + rule_vec - head_vec, p=1)
        return self.gamma_rule - distance

    def forward(self, h, query_r, graph, applicable_rules):
        """å®Œæ•´çš„groundingæ¨ç†"""
        # å¯¹æ¯ä¸ªå€™é€‰å®ä½“æ„å»ºç‰¹å¾
        num_entities = graph.num_entities
        features = torch.zeros(num_entities, self.mlp_feature.size(1))

        for rule in applicable_rules:
            # 1. è·¯å¾„æšä¸¾
            grounding_count = self.grounding(h, rule.body, graph)

            # 2. è§„åˆ™ç½®ä¿¡åº¦
            confidence = self.compute_confidence(rule.id, rule.body, rule.head)

            # 3. æ„å»ºç‰¹å¾
            rule_contribution = confidence * grounding_count  # [num_entities]
            rule_feature = self.mlp_feature[rule.id]  # [mlp_dim]

            # ç´¯åŠ 
            features += rule_contribution.unsqueeze(-1) * rule_feature

        # 4. MLPè¯„åˆ†
        scores = self.score_model(features).squeeze(-1)  # [num_entities]

        return scores

    def train(self, train_data, graph, epochs=20):
        optimizer = torch.optim.Adam(
            list(self.score_model.parameters()) + [self.mlp_feature],
            lr=1e-4
        )

        for epoch in range(epochs):
            for h, r, t in train_data:
                # æ‰¾åˆ°é€‚ç”¨çš„è§„åˆ™
                applicable_rules = graph.relation2rules[r]

                # å‰å‘ä¼ æ’­
                scores = self.forward(h, r, graph, applicable_rules)

                # äº¤å‰ç†µæŸå¤±
                loss = F.cross_entropy(scores.unsqueeze(0), t.unsqueeze(0))

                optimizer.zero_grad()
                loss.backward()
                optimizer.step()

            print(f"Epoch {epoch}, Loss: {loss.item():.4f}")


# ========== é˜¶æ®µ3: æ¨ç† ==========
class Inference:
    def __init__(self, pretrained_model, grounding_model):
        self.pretrained = pretrained_model
        self.grounding = grounding_model
        self.beta = 0.5  # è§„åˆ™æƒé‡

    def predict(self, h, r, graph):
        """å®Œæ•´æ¨ç†æµç¨‹"""
        # 1. KGEå¾—åˆ†
        kge_scores = []
        for t in range(graph.num_entities):
            score = self.pretrained.forward_triplet(h, r, t)
            kge_scores.append(score.item())
        kge_scores = torch.tensor(kge_scores)

        # 2. è§„åˆ™å¾—åˆ†
        applicable_rules = graph.relation2rules[r]
        rule_scores = self.grounding.forward(h, r, graph, applicable_rules)

        # 3. ç»¼åˆå¾—åˆ†
        final_scores = kge_scores + self.beta * rule_scores

        # 4. æ’åº
        ranked = torch.argsort(final_scores, descending=True)

        return ranked, final_scores


# ========== ä½¿ç”¨ç¤ºä¾‹ ==========
if __name__ == "__main__":
    # åˆ›å»ºçŸ¥è¯†å›¾è°±
    graph = KnowledgeGraph(
        entities=["Turing", "London", "Cambridge", "Bletchley_Park", "UK", "USA", "Church"],
        relations=["born_in", "city_of", "nationality", "works_at", "org_country", "friend_of"],
        triples=[
            ("Turing", "born_in", "London"),
            ("Turing", "born_in", "Cambridge"),
            ("London", "city_of", "UK"),
            ("Cambridge", "city_of", "UK"),
            ("Turing", "works_at", "Bletchley_Park"),
            ("Bletchley_Park", "org_country", "UK"),
            ("Turing", "friend_of", "Church"),
            ("Church", "nationality", "USA"),
            ("Turing", "nationality", "UK"),
        ],
        rules=[
            Rule(0, "nationality", ["born_in", "city_of"]),
            Rule(1, "nationality", ["friend_of", "nationality"]),
            Rule(2, "nationality", ["works_at", "org_country"]),
            Rule(3, "nationality", ["visits", "located_in"]),
        ]
    )

    # é˜¶æ®µ1: é¢„è®­ç»ƒ
    print("=== é˜¶æ®µ1: é¢„è®­ç»ƒ ===")
    pretrained_model = PreTraining()
    pretrained_model.train(triplet_data, rule_data, steps=30000)

    # é˜¶æ®µ2: Groundingè®­ç»ƒ
    print("\n=== é˜¶æ®µ2: Groundingè®­ç»ƒ ===")
    grounding_model = GroundingTraining(pretrained_model)
    grounding_model.train(train_data, graph, epochs=20)

    # é˜¶æ®µ3: æ¨ç†
    print("\n=== é˜¶æ®µ3: æ¨ç†é¢„æµ‹ ===")
    inference = Inference(pretrained_model, grounding_model)

    # æŸ¥è¯¢: (Turing, nationality, ?)
    h = graph.entity2id["Turing"]
    r = graph.relation2id["nationality"]

    ranked, scores = inference.predict(h, r, graph)

    print(f"æŸ¥è¯¢: (Turing, nationality, ?)")
    print(f"\né¢„æµ‹ç»“æœ:")
    for i in range(3):
        entity_id = ranked[i]
        entity_name = graph.id2entity[entity_id]
        score = scores[entity_id]
        print(f"  æ’å{i+1}: {entity_name} (å¾—åˆ†: {score:.4f})")

    # è¾“å‡º:
    # æŸ¥è¯¢: (Turing, nationality, ?)
    #
    # é¢„æµ‹ç»“æœ:
    #   æ’å1: UK (å¾—åˆ†: 8.9600)
    #   æ’å2: USA (å¾—åˆ†: 5.9750)
    #   æ’å3: France (å¾—åˆ†: 1.5250)
```

---

## 8. æ€»ç»“

### 8.1 æ ¸å¿ƒæµç¨‹å›é¡¾

```
è¾“å…¥æ•°æ®
  â†“
[é¢„è®­ç»ƒ] å­¦ä¹ åµŒå…¥ï¼ˆentity, relation, ruleï¼‰
  â†“
[Groundingè®­ç»ƒ] å­¦ä¹ MLPèšåˆè§„åˆ™
  â†“
[æ¨ç†] KGEå¾—åˆ† + è§„åˆ™å¾—åˆ† â†’ æœ€ç»ˆé¢„æµ‹
```

### 8.2 ä¸ºä»€ä¹ˆè¿™ä¸ªä¾‹å­é‡è¦ï¼Ÿ

```
âœ“ å®Œæ•´å±•ç¤ºäº†3ä¸ªé˜¶æ®µçš„æ•°æ®æµ
âœ“ ç”¨å…·ä½“æ•°å­—è¯´æ˜æ¯ä¸€æ­¥è®¡ç®—
âœ“ è§£é‡Šäº†ä¸ºä»€ä¹ˆUKå¾—åˆ†æœ€é«˜
âœ“ å¯¹æ¯”äº†å¥½è§„åˆ™å’Œåè§„åˆ™çš„è¡Œä¸º
âœ“ å±•ç¤ºäº†è½¯è§„åˆ™æ¨ç†çš„ä¼˜åŠ¿
```

### 8.3 å…³é”®è¦ç‚¹

```
1. è§„åˆ™åµŒå…¥å­¦ä¹ "è§„åˆ™è´¨é‡"
   â†’ å¥½è§„åˆ™ï¼ˆRule1ï¼‰ç½®ä¿¡åº¦8.0
   â†’ åè§„åˆ™ï¼ˆRule4ï¼‰ç½®ä¿¡åº¦1.6

2. è·¯å¾„æšä¸¾ç»Ÿè®¡"æ”¯æŒè¯æ®"
   â†’ UKæœ‰2æ¡è·¯å¾„ï¼ˆRule1ï¼‰+ 1æ¡è·¯å¾„ï¼ˆRule3ï¼‰
   â†’ USAåªæœ‰1æ¡è·¯å¾„ï¼ˆRule2ï¼‰

3. è½¯è§„åˆ™æ¨ç† = ç½®ä¿¡åº¦ Ã— è·¯å¾„æ•°
   â†’ è´¨é‡ Ã— æ•°é‡ = è´¡çŒ®
   â†’ å¤šæ¡è§„åˆ™æŠ•ç¥¨ï¼Œç»¼åˆå†³ç­–

4. KGEå’Œè§„åˆ™äº’è¡¥
   â†’ KGEæä¾›åŸºç¡€å¾—åˆ†
   â†’ è§„åˆ™æä¾›é€»è¾‘æ¨ç†
   â†’ ç»¼åˆå¾—åˆ†æ›´å‡†ç¡®
```

---

**è¿™å°±æ˜¯RulEæ¨¡å‹çš„å®Œæ•´å·¥ä½œæµç¨‹ï¼** ğŸ¯
