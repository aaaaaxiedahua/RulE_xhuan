# Rule-GNN æ¨¡å‹æ¶æ„è¯¦è§£

## ğŸ“‘ ç›®å½•

1. [æ¨¡å‹æ¦‚è¿°](#1-æ¨¡å‹æ¦‚è¿°)
2. [æ•´ä½“æ¶æ„](#2-æ•´ä½“æ¶æ„)
3. [è¾“å…¥æ•°æ®](#3-è¾“å…¥æ•°æ®)
4. [æ ¸å¿ƒç»„ä»¶](#4-æ ¸å¿ƒç»„ä»¶)
5. [å®Œæ•´å‰å‘ä¼ æ’­æµç¨‹](#5-å®Œæ•´å‰å‘ä¼ æ’­æµç¨‹)
6. [æ•°å­¦å…¬å¼è¯¦è§£](#6-æ•°å­¦å…¬å¼è¯¦è§£)
7. [è®­ç»ƒæµç¨‹](#7-è®­ç»ƒæµç¨‹)
8. [æ¨ç†æµç¨‹](#8-æ¨ç†æµç¨‹)
9. [ä¸ RulE çš„å¯¹æ¯”](#9-ä¸-rule-çš„å¯¹æ¯”)

---

## 1. æ¨¡å‹æ¦‚è¿°

### 1.1 ä»€ä¹ˆæ˜¯ Rule-GNNï¼Ÿ

**Rule-GNN** æ˜¯ä¸€ä¸ªå°†**é€»è¾‘è§„åˆ™**ä¸**å›¾ç¥ç»ç½‘ç»œ (GNN)** ç»“åˆçš„çŸ¥è¯†å›¾è°±æ¨ç†æ¨¡å‹ã€‚å®ƒé€šè¿‡ GNN çš„æ¶ˆæ¯ä¼ é€’æœºåˆ¶æ›¿ä»£ä¼ ç»Ÿçš„è·¯å¾„æšä¸¾æ–¹æ³•ï¼Œå®ç°é«˜æ•ˆçš„è§„åˆ™æ„ŸçŸ¥æ¨ç†ã€‚

### 1.2 æ ¸å¿ƒæ€æƒ³

```
ä¼ ç»Ÿæ–¹æ³•ï¼ˆRulE Groundingï¼‰:
  æ˜¾å¼æšä¸¾æ‰€æœ‰æ»¡è¶³è§„åˆ™çš„è·¯å¾„
  å¤æ‚åº¦: O(B^L)  B=åˆ†æ”¯å› å­, L=è§„åˆ™é•¿åº¦

Rule-GNN:
  ç”¨ GNN éšå¼èšåˆè§„åˆ™ä¿¡æ¯
  å¤æ‚åº¦: O(EÃ—L)  E=è¾¹æ•°, L=GNNå±‚æ•°
```

### 1.3 å…³é”®åˆ›æ–°

1. **è§„åˆ™æ„ŸçŸ¥çš„æ³¨æ„åŠ›æœºåˆ¶**: æ³¨æ„åŠ›æƒé‡ç”±è§„åˆ™åµŒå…¥è°ƒæ§
2. **å¤šå±‚æ¶ˆæ¯ä¼ é€’**: Lå±‚GNNå¯¹åº”L-hopè§„åˆ™
3. **ç«¯åˆ°ç«¯å­¦ä¹ **: é¢„è®­ç»ƒåµŒå…¥ + GNNå¾®è°ƒ

---

## 2. æ•´ä½“æ¶æ„

### 2.1 æ¨¡å‹æµç¨‹å›¾

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         è¾“å…¥é˜¶æ®µ                                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ 1. æŸ¥è¯¢: (h, r)                                                  â”‚
â”‚ 2. çŸ¥è¯†å›¾è°±: G = (V, E)                                          â”‚
â”‚ 3. é€»è¾‘è§„åˆ™: R = {râ‚, râ‚‚, ..., râ‚–}                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      é¢„è®­ç»ƒåµŒå…¥åŠ è½½                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ â€¢ å®ä½“åµŒå…¥: Hâ° = [hâ‚, hâ‚‚, ..., hâ‚™] âˆˆ â„â¿Ë£áµˆ                      â”‚
â”‚ â€¢ å…³ç³»åµŒå…¥: R = [râ‚, râ‚‚, ..., râ‚˜] âˆˆ â„áµË£áµˆ                       â”‚
â”‚ â€¢ è§„åˆ™åµŒå…¥: Î¦ = [Ï†â‚, Ï†â‚‚, ..., Ï†â‚–] âˆˆ â„áµË£áµˆ                       â”‚
â”‚                                                                 â”‚
â”‚ æ¥æº: RulE é¢„è®­ç»ƒï¼ˆRotatE + è§„åˆ™å­¦ä¹ ï¼‰                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   è§„åˆ™æ¿€æ´» (Rule Activation)                     â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ è¾“å…¥: æŸ¥è¯¢å…³ç³» r                                                 â”‚
â”‚ è¾“å‡º: æ¿€æ´»è§„åˆ™é›† Râ‚ = {Ï†áµ¢ | head(ruleáµ¢) = r}                   â”‚
â”‚                                                                 â”‚
â”‚ ç¤ºä¾‹: æŸ¥è¯¢ "treats" å…³ç³»                                         â”‚
â”‚   â†’ æ¿€æ´»è§„åˆ™: ["diagnoses âˆ§ treats â†’ treats",                   â”‚
â”‚                "causes âˆ§ treats â†’ treats"]                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              GNN æ¶ˆæ¯ä¼ é€’ (L å±‚, L = è§„åˆ™æœ€å¤§é•¿åº¦)                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                 â”‚
â”‚  Layer 1:  HÂ¹ = RuleGNN_Conv(Hâ°, E, Râ‚)                        â”‚
â”‚            â†“                                                    â”‚
â”‚  Layer 2:  HÂ² = RuleGNN_Conv(HÂ¹, E, Râ‚)                        â”‚
â”‚            â†“                                                    â”‚
â”‚  Layer L:  Há´¸ = RuleGNN_Conv(Há´¸â»Â¹, E, Râ‚)                      â”‚
â”‚                                                                 â”‚
â”‚  æ¯å±‚åšä»€ä¹ˆ:                                                     â”‚
â”‚  1. è§„åˆ™æ„ŸçŸ¥çš„æ³¨æ„åŠ›è®¡ç®—                                         â”‚
â”‚  2. å…³ç³»ç‰¹å®šçš„æ¶ˆæ¯ç”Ÿæˆ                                           â”‚
â”‚  3. æ¶ˆæ¯èšåˆåˆ°ç›®æ ‡èŠ‚ç‚¹                                           â”‚
â”‚  4. LayerNorm + ReLU + Dropout                                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                       å®ä½“æ‰“åˆ† (Scoring)                         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ è¾“å…¥: Há´¸[h], Há´¸ (å¤´å®ä½“åµŒå…¥, æ‰€æœ‰å®ä½“åµŒå…¥)                       â”‚
â”‚                                                                 â”‚
â”‚ è®¡ç®—: score(h, r, t) = MLP([Há´¸[h] âŠ• Há´¸[t]])                    â”‚
â”‚                                                                 â”‚
â”‚ è¾“å‡º: scores âˆˆ â„â¿ (å¯¹æ‰€æœ‰nä¸ªå®ä½“çš„å¾—åˆ†)                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      è¾“å‡ºé˜¶æ®µ                                    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ è®­ç»ƒ: è®¡ç®—æŸå¤± (BCEWithLogitsLoss)                              â”‚
â”‚ æ¨ç†: æ’åºè¾“å‡º Top-K é¢„æµ‹                                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 2.2 ä¸‰é˜¶æ®µæµç¨‹

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  é˜¶æ®µ 1:     â”‚      â”‚  é˜¶æ®µ 2:     â”‚      â”‚  é˜¶æ®µ 3:     â”‚
â”‚  RulE é¢„è®­ç»ƒ â”‚ â”€â”€â”€â†’ â”‚  å¯¼å‡ºåµŒå…¥    â”‚ â”€â”€â”€â†’ â”‚  Rule-GNN    â”‚
â”‚  (RotatE)   â”‚      â”‚             â”‚      â”‚  è®­ç»ƒ        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
      â”‚                      â”‚                      â”‚
      â†“                      â†“                      â†“
  å­¦ä¹ åµŒå…¥              entity_emb            å›ºå®šåµŒå…¥
  â€¢ entity            relation_emb           åªè®­ç»ƒGNN
  â€¢ relation          rule_emb               å’ŒMLPå‚æ•°
  â€¢ rule
```

---

## 3. è¾“å…¥æ•°æ®

### 3.1 çŸ¥è¯†å›¾è°±æ•°æ®

#### å›¾ç»“æ„

```python
# èŠ‚ç‚¹
V = {eâ‚, eâ‚‚, ..., eâ‚™}  # n ä¸ªå®ä½“

# è¾¹
E = {(h, r, t) | h, t âˆˆ V, r âˆˆ R}  # ä¸‰å…ƒç»„é›†åˆ

# ç¤ºä¾‹ (UMLS åŒ»å­¦çŸ¥è¯†å›¾è°±)
å®ä½“: "é˜¿å¸åŒ¹æ—", "å¤´ç—›", "å‘çƒ§"
å…³ç³»: "treats" (æ²»ç–—), "causes" (å¼•èµ·)
ä¸‰å…ƒç»„: (é˜¿å¸åŒ¹æ—, treats, å¤´ç—›)
```

**PyTorch Geometric æ ¼å¼**:

```python
# è¾¹ç´¢å¼•
edge_index: Tensor[2, num_edges]
# [[srcâ‚, srcâ‚‚, srcâ‚ƒ, ...],    â† æºèŠ‚ç‚¹
#  [dstâ‚, dstâ‚‚, dstâ‚ƒ, ...]]    â† ç›®æ ‡èŠ‚ç‚¹

# è¾¹ç±»å‹
edge_type: Tensor[num_edges]
# [râ‚, râ‚‚, râ‚ƒ, ...]             â† å…³ç³»ID

# ç¤ºä¾‹
edge_index = [[0, 1, 2],       # èŠ‚ç‚¹ 0â†’3, 1â†’4, 2â†’5
              [3, 4, 5]]
edge_type = [5, 3, 5]          # å…³ç³» 5, 3, 5
```

**é‡è¦**: åŒ…å«æ­£å‘å’Œé€†å‘å…³ç³»

```python
# æ­£å‘å…³ç³»
(h, r, t)  â†’ å…³ç³»ID = r

# é€†å‘å…³ç³»
(t, râ»Â¹, h) â†’ å…³ç³»ID = r + num_relations

# ä¾‹å¦‚: num_relations = 46
# æ­£å‘ ID: 0-45
# é€†å‘ ID: 46-91
```

### 3.2 é€»è¾‘è§„åˆ™

#### è§„åˆ™æ ¼å¼

```
è§„åˆ™: râ‚ âˆ§ râ‚‚ âˆ§ ... âˆ§ râ‚– â†’ r_head

è¡¨ç¤º: [rule_id, r_head, râ‚, râ‚‚, ..., râ‚–]
```

**ç¤ºä¾‹** (åŒ»å­¦çŸ¥è¯†å›¾è°±):

```
è§„åˆ™1: diagnoses âˆ§ treats â†’ treats
å«ä¹‰: å¦‚æœ (X diagnoses Y) ä¸” (Y treats Z)ï¼Œåˆ™ (X treats Z)
è¡¨ç¤º: [0, 5, 3, 5]  (rule_id=0, head=5, body=[3,5])

è§„åˆ™2: causes âˆ§ treats â†’ prevents
å«ä¹‰: å¦‚æœ (X causes Y) ä¸” (Y treats Z)ï¼Œåˆ™ (X prevents Z)
è¡¨ç¤º: [1, 8, 2, 5]
```

#### relation2rules æ˜ å°„

```python
relation2rules: Dict[int, List[List[int]]]

# ç¤ºä¾‹
relation2rules = {
    5: [  # å…³ç³» "treats" ä½œä¸º head çš„è§„åˆ™
        [0, 5, 3, 5],      # è§„åˆ™0
        [2, 5, 1, 4, 5]    # è§„åˆ™2
    ],
    8: [  # å…³ç³» "prevents" ä½œä¸º head çš„è§„åˆ™
        [1, 8, 2, 5]       # è§„åˆ™1
    ]
}
```

### 3.3 æŸ¥è¯¢

```python
# è®­ç»ƒæ—¶çš„æŸ¥è¯¢æ ¼å¼
queries: Tensor[batch_size, 2]
# [[hâ‚, râ‚],
#  [hâ‚‚, râ‚‚],
#  ...]

# ç¤ºä¾‹:
# queries = [[10, 5],    # å®ä½“10ï¼Œå…³ç³»5
#            [12, 3]]    # å®ä½“12ï¼Œå…³ç³»3

# ä»»åŠ¡: é¢„æµ‹å°¾å®ä½“ tï¼Œä½¿å¾— (h, r, t) æˆç«‹
```

### 3.4 é¢„è®­ç»ƒåµŒå…¥

æ¥è‡ª RulE é¢„è®­ç»ƒé˜¶æ®µ:

```python
# 1. å®ä½“åµŒå…¥ (å¤æ•°å½¢å¼ï¼Œå–å®éƒ¨)
entity_embedding: Tensor[num_entities, hidden_dim]
# [135, 2000] for UMLS

# 2. å…³ç³»åµŒå…¥
relation_embedding: Tensor[num_relations, hidden_dim]
# [46, 2000] for UMLS (åªæœ‰æ­£å‘å…³ç³»)

# 3. è§„åˆ™åµŒå…¥
rule_embedding: Tensor[num_rules, hidden_dim]
# [587, 2000] for UMLS
```

**é€†å…³ç³»å¤„ç†**:

```python
# Rule-GNN éœ€è¦æ­£å‘+é€†å‘å…³ç³»
relation_embedding_full: Tensor[num_relations*2, hidden_dim]

# æ„å»ºæ–¹å¼:
relation_embedding_full[0:46] = relation_embedding       # æ­£å‘
relation_embedding_full[46:92] = -relation_embedding     # é€†å‘(å–è´Ÿ)
```

---

### 3.5 è§„åˆ™æ¿€æ´»æœºåˆ¶è¯¦è§£ â­âš ï¸

**æ¶æ„å®šä½**: è§„åˆ™æ¿€æ´»æ˜¯**é¢„å¤„ç†æ­¥éª¤**,å‘ç”Ÿåœ¨**åŠ è½½åµŒå…¥ä¹‹åã€GNNå‰å‘ä¼ æ’­ä¹‹å‰**,ä¸å±äºåµŒå…¥éƒ¨åˆ†ä¹Ÿä¸å±äºGNNéƒ¨åˆ†ã€‚

```
åŠ è½½é¢„è®­ç»ƒåµŒå…¥  â†’  [è§„åˆ™æ¿€æ´»]  â†’  GNN æ¶ˆæ¯ä¼ é€’  â†’  MLP æ‰“åˆ†
   (é™æ€)          (åŠ¨æ€ç­›é€‰)      (ç‰¹å¾æ›´æ–°)     (æœ€ç»ˆå¾—åˆ†)
```

#### 3.5.1 ä»€ä¹ˆæ˜¯è§„åˆ™æ¿€æ´»?

å¯¹äºæ¯ä¸ªæŸ¥è¯¢ `(h, r)`,æˆ‘ä»¬åªéœ€è¦æ¿€æ´»é‚£äº› **head = r** çš„è§„åˆ™,å…¶ä»–è§„åˆ™ä¸å½“å‰æŸ¥è¯¢æ— å…³ã€‚

**ç¤ºä¾‹**:

```python
# æŸ¥è¯¢: (é˜¿å¸åŒ¹æ—, treats, ?)
query_relation = "treats"  # ID: 5

# æ‰€æœ‰è§„åˆ™
rule_0: diagnoses âˆ§ treats â†’ treats      # head = treats âœ… æ¿€æ´»
rule_1: causes âˆ§ treats â†’ prevents       # head = prevents âŒ ä¸æ¿€æ´»
rule_2: symptom âˆ§ treats â†’ treats        # head = treats âœ… æ¿€æ´»
rule_3: treats âˆ§ diagnoses â†’ diagnoses   # head = diagnoses âŒ ä¸æ¿€æ´»

# æ¿€æ´»çš„è§„åˆ™: [rule_0, rule_2]
active_rule_ids = [0, 2]
```

**ä¸ºä»€ä¹ˆéœ€è¦æ¿€æ´»?**

1. **æ•ˆç‡**: é¿å…åœ¨GNNä¸­è®¡ç®—æ— å…³è§„åˆ™ (587ä¸ªè§„åˆ™ä¸­åªæœ‰å‡ åä¸ªä¸æŸ¥è¯¢ç›¸å…³)
2. **è¯­ä¹‰**: åªæœ‰headä¸æŸ¥è¯¢å…³ç³»ç›¸åŒçš„è§„åˆ™æ‰èƒ½ç”¨äºæ¨ç†è¯¥å…³ç³»
3. **å†…å­˜**: å‡å°‘æ³¨æ„åŠ›æœºåˆ¶ä¸­çš„è§„åˆ™æ•°é‡ (ä»587é™åˆ°~20-30)

#### 3.5.2 relation2rules æ˜ å°„

**æ•°æ®ç»“æ„**:

```python
relation2rules: Dict[int, List[List[int]]]

# æ ¼å¼
{
    relation_id: [
        [rule_id_1, head, body_1, body_2, ...],
        [rule_id_2, head, body_1, body_2, ...],
        ...
    ]
}
```

**UMLS ç¤ºä¾‹**:

```python
relation2rules = {
    5: [  # å…³ç³» "treats" (ID=5) ä½œä¸º head çš„è§„åˆ™
        [0, 5, 3, 5],      # rule_0: diagnoses(3) âˆ§ treats(5) â†’ treats(5)
        [2, 5, 1, 4, 5],   # rule_2: symptom(1) âˆ§ causes(4) âˆ§ treats(5) â†’ treats(5)
        [10, 5, 5, 3],     # rule_10: treats(5) âˆ§ diagnoses(3) â†’ treats(5)
        ...                 # å…±çº¦ 25 æ¡è§„åˆ™
    ],
    3: [  # å…³ç³» "diagnoses" (ID=3)
        [5, 3, 1, 3],
        [8, 3, 3, 5],
        ...
    ],
    ...
}
```

**æ„å»ºæ–¹å¼** (åœ¨ RulE æ¨¡å‹ä¸­):

```python
# åœ¨ model.py çš„ RulE.set_rules() æ–¹æ³•ä¸­
def set_rules(self, rules):
    """
    æ„å»º relation2rules æ˜ å°„

    Args:
        rules: [[rule_id, head, body...], ...]
    """
    self.relation2rules = {}

    for rule in rules:
        rule_id, head, *body = rule

        if head not in self.relation2rules:
            self.relation2rules[head] = []

        self.relation2rules[head].append(rule)

    # ç¤ºä¾‹ç»“æœ:
    # relation2rules[5] = [
    #     [0, 5, 3, 5],
    #     [2, 5, 1, 4, 5],
    #     ...
    # ]
```

#### 3.5.3 è§„åˆ™æ¿€æ´»çš„å®Œæ•´ä»£ç å®ç°

**ä»£ç ä½ç½®**: `rule_gnn_trainer.py:617-639`

```python
def get_active_rules(self, query_relations):
    """
    è·å–æŸ¥è¯¢å…³ç³»å¯¹åº”çš„æ¿€æ´»è§„åˆ™

    Args:
        query_relations: [batch_size] æŸ¥è¯¢å…³ç³» ID

    Returns:
        rule_ids: [num_active_rules] æ¿€æ´»çš„è§„åˆ™ ID (å»é‡)
    """
    active_rules = set()  # ä½¿ç”¨é›†åˆå»é‡

    for r in query_relations:
        r_item = r.item() if torch.is_tensor(r) else r

        # ä» self.relation2rules æŸ¥æ‰¾è§„åˆ™
        if r_item in self.relation2rules:
            for rule in self.relation2rules[r_item]:
                rule_id = rule[0]  # rule æ ¼å¼: [rule_id, head, body...]
                active_rules.add(rule_id)

    # è½¬æ¢ä¸º tensor
    rule_ids = torch.tensor(list(active_rules), dtype=torch.long, device=self.device)

    return rule_ids
```

**è¯¦ç»†æ­¥éª¤è§£æ**:

```python
# === ç¤ºä¾‹: batch_size=16 ===

# è¾“å…¥: 16ä¸ªæŸ¥è¯¢çš„å…³ç³»
query_relations = tensor([5, 3, 5, 8, 5, 3, ...])  # [16]
#                          â†‘  â†‘  â†‘  â†‘
#                       treats, diagnoses, treats, prevents

# æ­¥éª¤1: åˆå§‹åŒ–é›†åˆ
active_rules = set()  # {}

# æ­¥éª¤2: éå†æ¯ä¸ªæŸ¥è¯¢å…³ç³»
for r in query_relations:
    # r = 5 (ç¬¬ä¸€ä¸ªæŸ¥è¯¢)
    if 5 in relation2rules:
        # relation2rules[5] = [[0,5,3,5], [2,5,1,4,5], [10,5,5,3], ...]
        for rule in relation2rules[5]:
            rule_id = rule[0]  # 0, 2, 10, ...
            active_rules.add(rule_id)

    # r = 3 (ç¬¬äºŒä¸ªæŸ¥è¯¢)
    if 3 in relation2rules:
        for rule in relation2rules[3]:
            rule_id = rule[0]
            active_rules.add(rule_id)  # è‡ªåŠ¨å»é‡

    # ... ç»§ç»­éå†

# æ­¥éª¤3: è½¬æ¢ä¸º tensor
# active_rules = {0, 2, 5, 8, 10, 15, 18, ...}  (å»é‡åçº¦25ä¸ª)
rule_ids = torch.tensor([0, 2, 5, 8, 10, 15, 18, ...], device='cuda')
# [25]  (å‡è®¾16ä¸ªæŸ¥è¯¢å…±æ¿€æ´»25ä¸ªè§„åˆ™)

return rule_ids
```

#### 3.5.4 æ¿€æ´»è§„åˆ™çš„æ•°é‡ç»Ÿè®¡

**UMLS æ•°æ®é›†ç»Ÿè®¡**:

```python
# æ€»è§„åˆ™æ•°
total_rules = 587

# æ¯ä¸ªå…³ç³»å¹³å‡è§„åˆ™æ•°
avg_rules_per_relation = 587 / 46 â‰ˆ 12.8

# å•ä¸ªæŸ¥è¯¢æ¿€æ´»çš„è§„åˆ™æ•°
# å‡è®¾æŸ¥è¯¢å…³ç³»ä¸º "treats"
relation2rules[5] åŒ…å«çº¦ 25 æ¡è§„åˆ™

# batch_size=16 çš„æŸ¥è¯¢æ¿€æ´»çš„è§„åˆ™æ•° (å»é‡å)
# å‡è®¾16ä¸ªæŸ¥è¯¢æ¶‰åŠ5ç§ä¸åŒå…³ç³»
# æ¯ç§å…³ç³»å¹³å‡12.8æ¡è§„åˆ™
# å»é‡åçº¦ 12.8 Ã— 5 = 64 æ¡è§„åˆ™

# å®é™…è§‚å¯Ÿ: é€šå¸¸åœ¨ 20-40 æ¡è§„åˆ™
```

**æ¿€æ´»ç‡**:

```
æ¿€æ´»è§„åˆ™æ•° / æ€»è§„åˆ™æ•° = 25 / 587 â‰ˆ 4.3%

æ„ä¹‰: åªè®¡ç®—çº¦ 4.3% çš„è§„åˆ™,å¤§å¹…æå‡æ•ˆç‡
```

#### 3.5.5 è§„åˆ™æ¿€æ´»åœ¨è®­ç»ƒå’Œæ¨ç†ä¸­çš„ä½œç”¨

**è®­ç»ƒé˜¶æ®µ** (`rule_gnn_trainer.py:766-810`):

```python
def train_epoch(self, optimizer, args):
    """è®­ç»ƒä¸€ä¸ª epoch"""
    self.model.train()

    for batch_idx, batch in enumerate(train_loader):
        # è§£åŒ…æ‰¹æ¬¡
        all_h, all_r, all_t, target, edges_to_remove = batch
        all_h = all_h.squeeze(0).to(self.device)     # [16]
        all_r = all_r.squeeze(0).to(self.device)     # [16]
        target = target.squeeze(0).to(self.device)   # [16, 135]

        # æ„å»ºæŸ¥è¯¢
        queries = torch.stack([all_h, all_r], dim=1)  # [16, 2]

        # ======= å…³é”®: è·å–æ¿€æ´»è§„åˆ™ =======
        rule_ids = self.get_active_rules(all_r)  # [num_active_rules]

        if len(rule_ids) == 0:
            continue  # æ²¡æœ‰è§„åˆ™,è·³è¿‡æ­¤ batch

        # å‰å‘ä¼ æ’­ (ä¼ å…¥æ¿€æ´»çš„è§„åˆ™)
        scores = self.model(queries, self.edge_index, self.edge_type,
                           rule_ids, candidates=None)
        # scores: [16, 135]

        # æŸå¤±è®¡ç®—
        loss = nn.BCEWithLogitsLoss()(scores, target)

        # åå‘ä¼ æ’­
        optimizer.zero_grad()
        loss.backward()
        optimizer.step()
```

**æ¨ç†é˜¶æ®µ** (`rule_gnn_trainer.py:865-916`):

```python
def evaluate(self, dataset, split='valid'):
    """è¯„ä¼°æ¨¡å‹"""
    self.model.eval()

    for batch in eval_loader:
        pos_samples, filter_mask = batch
        pos_samples = pos_samples.to(self.device)  # [batch_size, 3]

        # æŸ¥è¯¢
        queries = pos_samples[:, :2]  # [batch_size, 2]

        # ======= è·å–æ¿€æ´»è§„åˆ™ =======
        rule_ids = self.get_active_rules(queries[:, 1])

        if len(rule_ids) == 0:
            # æ²¡æœ‰è§„åˆ™,ä½¿ç”¨æ‰€æœ‰è§„åˆ™ (é™çº§ç­–ç•¥)
            rule_ids = torch.arange(len(self.rules), dtype=torch.long, device=self.device)

        # å‰å‘ä¼ æ’­
        scores = self.model(queries, self.edge_index, self.edge_type,
                           rule_ids, candidates=None)
        # scores: [batch_size, num_entities]

        # è¿‡æ»¤å·²çŸ¥ä¸‰å…ƒç»„
        scores = scores.masked_fill(filter_mask.bool(), -1e9)

        # è®¡ç®—æ’å...
```

#### 3.5.6 æ¿€æ´»è§„åˆ™ä¼ é€’åˆ° GNN å±‚

è§„åˆ™æ¿€æ´»å,`rule_ids` è¢«ä¼ é€’åˆ°æ¯ä¸€å±‚ GNN:

```python
# åœ¨ RuleGNN.forward() ä¸­ (rule_gnn_model.py:263-327)
def forward(self, queries, edge_index, edge_type, rule_ids, candidates=None):
    """
    Args:
        rule_ids: [num_active_rules]  â† æ¿€æ´»çš„è§„åˆ™
    """
    # åˆå§‹åŒ–èŠ‚ç‚¹ç‰¹å¾
    h = self.entity_embedding.weight  # [num_entities, hidden_dim]

    # å¤šå±‚ä¼ æ’­
    for layer_idx, conv in enumerate(self.conv_layers):
        h = conv(h, edge_index, edge_type, rule_ids)  # â† ä¼ å…¥è§„åˆ™
        #                                    â†‘
        #                         æ¯å±‚éƒ½ä½¿ç”¨ç›¸åŒçš„æ¿€æ´»è§„åˆ™

    # ... åç»­æ‰“åˆ†
```

**åœ¨ GNN å±‚å†…éƒ¨** (`rule_gnn_model.py:55-169`):

```python
def RuleAwareGraphConv.forward(self, x, edge_index, edge_type, rule_ids):
    """
    Args:
        rule_ids: [num_active_rules]  â† ä»å¤–éƒ¨ä¼ å…¥
    """
    # è·å–è§„åˆ™åµŒå…¥
    h_R = self.rule_embedding(rule_ids)  # [num_active_rules, in_dim]
    #                          â†‘
    #                    åªå–æ¿€æ´»çš„è§„åˆ™åµŒå…¥

    # éå†æ¯ä¸ªæ¿€æ´»çš„è§„åˆ™
    for rule_idx, rule_id in enumerate(rule_ids):
        h_rule = h_R[rule_idx]  # [in_dim]

        # è®¡ç®—è¯¥è§„åˆ™ä¸‹çš„æ³¨æ„åŠ›æƒé‡
        attn_weights = ...

        # è®¡ç®—è¯¥è§„åˆ™ä¸‹çš„æ¶ˆæ¯
        messages = ...

        # ç´¯ç§¯
        combined_messages += messages

    # å¹³å‡æ‰€æœ‰è§„åˆ™çš„æ¶ˆæ¯
    combined_messages /= len(rule_ids)

    # ... åç»­èšåˆ
```

#### 3.5.7 å®Œæ•´æ•°æ®æµç¤ºæ„å›¾

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   è¾“å…¥: æŸ¥è¯¢ batch                           â”‚
â”‚   queries = [[hâ‚, râ‚], [hâ‚‚, râ‚‚], ..., [hâ‚â‚†, râ‚â‚†]]          â”‚
â”‚                                                             â”‚
â”‚   ç¤ºä¾‹: râ‚=5, râ‚‚=3, râ‚ƒ=5, râ‚„=8, ...                         â”‚
â”‚        (treats, diagnoses, treats, prevents, ...)           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              æ­¥éª¤1: æå–æŸ¥è¯¢å…³ç³»                             â”‚
â”‚   query_relations = [5, 3, 5, 8, ...]  # [16]               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              æ­¥éª¤2: æŸ¥æ‰¾ relation2rules                      â”‚
â”‚                                                             â”‚
â”‚   relation2rules[5] = [[0,5,3,5], [2,5,1,4,5], ...]  â† 25æ¡ â”‚
â”‚   relation2rules[3] = [[5,3,1,3], [8,3,3,5], ...]    â† 18æ¡ â”‚
â”‚   relation2rules[8] = [[12,8,2,5], ...]              â† 10æ¡ â”‚
â”‚   ...                                                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              æ­¥éª¤3: æå– rule_id å¹¶å»é‡                      â”‚
â”‚                                                             â”‚
â”‚   active_rules = {0, 2, 5, 8, 10, 12, 15, ...}  â† setå»é‡   â”‚
â”‚                                                             â”‚
â”‚   rule_ids = [0, 2, 5, 8, 10, 12, 15, ...]  â† è½¬ä¸ºtensor    â”‚
â”‚              [30]  (å‡è®¾å»é‡å30æ¡)                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              æ­¥éª¤4: ä¼ å…¥ GNN å‰å‘ä¼ æ’­                        â”‚
â”‚                                                             â”‚
â”‚   scores = model(queries, edge_index, edge_type, rule_ids) â”‚
â”‚                                                   â†‘          â”‚
â”‚                                         åªä½¿ç”¨è¿™30æ¡è§„åˆ™      â”‚
â”‚                                                             â”‚
â”‚   åœ¨GNNå†…éƒ¨:                                                 â”‚
â”‚     h_R = rule_embedding(rule_ids)  # [30, 2000]            â”‚
â”‚                          â†‘                                  â”‚
â”‚                    åªå–30æ¡è§„åˆ™çš„åµŒå…¥                         â”‚
â”‚                    (è€Œä¸æ˜¯å…¨éƒ¨587æ¡)                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              è¾“å‡º: æ‰€æœ‰å®ä½“çš„å¾—åˆ†                             â”‚
â”‚   scores: [16, 135]                                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

#### 3.5.8 ä¸åµŒå…¥å’ŒGNNçš„åŒºåˆ«

| å¯¹æ¯”é¡¹ | é¢„è®­ç»ƒåµŒå…¥ | è§„åˆ™æ¿€æ´» | GNN æ¶ˆæ¯ä¼ é€’ |
|-------|-----------|---------|-------------|
| **å‘ç”Ÿæ—¶æœº** | è®­ç»ƒå‰(é¢„è®­ç»ƒé˜¶æ®µ) | æ¯ä¸ª batch å‰ | å‰å‘ä¼ æ’­ä¸­ |
| **ä½œç”¨** | åˆå§‹åŒ–å®ä½“/å…³ç³»/è§„åˆ™å‘é‡ | ç­›é€‰ç›¸å…³è§„åˆ™ | æ›´æ–°èŠ‚ç‚¹ç‰¹å¾ |
| **è¾“å…¥** | ä¸‰å…ƒç»„ + è§„åˆ™ | æŸ¥è¯¢å…³ç³» | èŠ‚ç‚¹ç‰¹å¾ + è¾¹ + è§„åˆ™ |
| **è¾“å‡º** | åµŒå…¥çŸ©é˜µ | rule_ids | æ›´æ–°åçš„èŠ‚ç‚¹ç‰¹å¾ |
| **æ˜¯å¦å¯å­¦ä¹ ** | æ˜¯(é¢„è®­ç»ƒæ—¶) | **å¦**(çº¯æŸ¥æ‰¾) | æ˜¯(GNNå‚æ•°) |
| **åŠ¨æ€æ€§** | é™æ€(å›ºå®š) | **åŠ¨æ€**(æŸ¥è¯¢ç›¸å…³) | åŠ¨æ€(æ¯å±‚æ›´æ–°) |

**å…³é”®åŒºåˆ†**:

```python
# 1. é¢„è®­ç»ƒåµŒå…¥: é™æ€çš„çŸ©é˜µ
entity_embedding = [[0.1, -0.2, ...],    # å®ä½“0
                    [0.5, 0.3, ...],     # å®ä½“1
                    ...]                 # [135, 2000]
# è®­ç»ƒå‰åŠ è½½,è®­ç»ƒä¸­å›ºå®š

# 2. è§„åˆ™æ¿€æ´»: åŠ¨æ€çš„ç­›é€‰
def get_active_rules(query_relations):
    # æ ¹æ®æŸ¥è¯¢åŠ¨æ€é€‰æ‹©è§„åˆ™
    return rule_ids  # [num_active_rules]
# æ¯ä¸ª batch éƒ½ä¸åŒ,ä½†ä¸æ¶‰åŠå­¦ä¹ 

# 3. GNN æ¶ˆæ¯ä¼ é€’: å¯å­¦ä¹ çš„æ›´æ–°
def forward(h, edge_index, rule_ids):
    # ä½¿ç”¨ W_r, W_q, W_k ç­‰å¯å­¦ä¹ å‚æ•°
    h_new = GNN_layer(h, edge_index, rule_ids)
    return h_new
# è®­ç»ƒæ—¶æ›´æ–°å‚æ•°
```

#### 3.5.9 æ€§èƒ½å½±å“åˆ†æ

**ä¸æ¿€æ´» (ä½¿ç”¨å…¨éƒ¨è§„åˆ™)**:

```python
# å‡è®¾ä¸åšè§„åˆ™æ¿€æ´»
rule_ids = torch.arange(587)  # ä½¿ç”¨å…¨éƒ¨587æ¡è§„åˆ™

# GNN å±‚å†…éƒ¨è®¡ç®—é‡
for rule_idx in range(587):  # éå†587æ¬¡
    h_rule = h_R[rule_idx]
    messages = compute_messages(...)  # [13420, 2000]
    combined_messages += messages

# æ€»è®¡ç®—é‡: 587 Ã— 13420 Ã— 2000 = 15.7 billion operations
# å†…å­˜å ç”¨: 587 Ã— 13420 Ã— 2000 Ã— 4 bytes â‰ˆ 62.8 GB  â† OOM!
```

**æ¿€æ´»å (åªç”¨ç›¸å…³è§„åˆ™)**:

```python
# ä½¿ç”¨è§„åˆ™æ¿€æ´»
rule_ids = get_active_rules(query_relations)  # [30] (å‡è®¾30æ¡)

# GNN å±‚å†…éƒ¨è®¡ç®—é‡
for rule_idx in range(30):  # éå†30æ¬¡
    h_rule = h_R[rule_idx]
    messages = compute_messages(...)  # [13420, 2000]
    combined_messages += messages

# æ€»è®¡ç®—é‡: 30 Ã— 13420 Ã— 2000 = 804 million operations
# å†…å­˜å ç”¨: 80MB (å¯æ¥å—)

# æ€§èƒ½æå‡: 15.7B / 804M â‰ˆ 19.5 å€åŠ é€Ÿ
```

#### 3.5.10 è¾¹ç•Œæƒ…å†µå¤„ç†

**æƒ…å†µ1: æ²¡æœ‰æ¿€æ´»çš„è§„åˆ™**

```python
# è®­ç»ƒæ—¶
if len(rule_ids) == 0:
    continue  # è·³è¿‡æ­¤ batch

# æ¨ç†æ—¶ (é™çº§ç­–ç•¥)
if len(rule_ids) == 0:
    # ä½¿ç”¨æ‰€æœ‰è§„åˆ™ (ä¿è¯è‡³å°‘æœ‰è¾“å‡º)
    rule_ids = torch.arange(num_rules, device=device)
```

**æƒ…å†µ2: æ–°å…³ç³» (ä¸åœ¨ relation2rules ä¸­)**

```python
# æ•°æ®é¢„å¤„ç†æ—¶åº”è¯¥ç¡®ä¿æ‰€æœ‰å…³ç³»éƒ½æœ‰è§„åˆ™
# å¦‚æœè®­ç»ƒæ—¶é‡åˆ°æ–°å…³ç³»:
if r not in relation2rules:
    print(f"Warning: No rules for relation {r}")
    # ç­–ç•¥1: è·³è¿‡
    # ç­–ç•¥2: ä½¿ç”¨é€šç”¨è§„åˆ™
    # ç­–ç•¥3: ä½¿ç”¨æ‰€æœ‰è§„åˆ™
```

---

### 3.6 edge_index å’Œ edge_type è¯¦è§£ â­

è¿™ä¸¤ä¸ªæ•°æ®ç»“æ„æ˜¯ Rule-GNN çš„æ ¸å¿ƒè¾“å…¥ï¼Œç”¨äºè¡¨ç¤ºæ•´ä¸ªçŸ¥è¯†å›¾è°±çš„ç»“æ„ã€‚

#### 3.5.1 edge_index: è¾¹ç´¢å¼•çŸ©é˜µ

**å®šä¹‰**: å­˜å‚¨æ‰€æœ‰è¾¹çš„æºèŠ‚ç‚¹å’Œç›®æ ‡èŠ‚ç‚¹

```python
edge_index: Tensor[2, num_edges]

# ç¬¬0è¡Œ: æ‰€æœ‰è¾¹çš„æºèŠ‚ç‚¹ (head entities)
# ç¬¬1è¡Œ: æ‰€æœ‰è¾¹çš„ç›®æ ‡èŠ‚ç‚¹ (tail entities)
```

**å®Œæ•´ç¤ºä¾‹** (UMLSæ•°æ®é›†):

```python
# === åŸå§‹ä¸‰å…ƒç»„ ===
ä¸‰å…ƒç»„1: (é˜¿å¸åŒ¹æ—=0, treats=5, å¤´ç—›=10)
ä¸‰å…ƒç»„2: (æ„Ÿå†’=1, causes=3, å¤´ç—›=20)
ä¸‰å…ƒç»„3: (é˜¿å¸åŒ¹æ—=0, prevents=2, å‘çƒ§=15)
ä¸‰å…ƒç»„4: (è¯ç‰©=5, treats=5, å¤´ç—›=10)

# === è½¬æ¢ä¸º edge_index ===
edge_index = tensor([
    [0, 1, 0, 5],      # ç¬¬0è¡Œ: æºèŠ‚ç‚¹ [é˜¿å¸åŒ¹æ—, æ„Ÿå†’, é˜¿å¸åŒ¹æ—, è¯ç‰©]
    [10, 20, 15, 10]   # ç¬¬1è¡Œ: ç›®æ ‡èŠ‚ç‚¹ [å¤´ç—›, å¤´ç—›, å‘çƒ§, å¤´ç—›]
])
# å½¢çŠ¶: [2, 4]

# === åŒ…å«é€†å‘è¾¹å ===
# æ¯æ¡è¾¹éƒ½ä¼šç”Ÿæˆä¸€æ¡é€†å‘è¾¹
æ­£å‘è¾¹1: 0 â†’ 10  (é˜¿å¸åŒ¹æ— treats å¤´ç—›)
é€†å‘è¾¹1: 10 â†’ 0  (å¤´ç—› treatsâ»Â¹ é˜¿å¸åŒ¹æ—)

edge_index = tensor([
    [0, 10,  1, 20,  0, 15,  5, 10],    # æºèŠ‚ç‚¹
    [10, 0, 20,  1, 15,  0, 10,  5]     # ç›®æ ‡èŠ‚ç‚¹
])
# å½¢çŠ¶: [2, 8]  (4æ¡åŸå§‹è¾¹ Ã— 2 = 8æ¡è¾¹)
```

**UMLSå®é™…è§„æ¨¡**:

```python
# ä¸‰å…ƒç»„ç»Ÿè®¡
è®­ç»ƒé›†: 5,216
éªŒè¯é›†: 652
æµ‹è¯•é›†: 661
æ€»è®¡: 6,529 æ¡ä¸‰å…ƒç»„

# edge_index è§„æ¨¡
num_edges = 6,529 Ã— 2 = 13,058  (åŒ…å«é€†å‘è¾¹)

edge_index.shape = [2, 13058]
```

**ä½¿ç”¨æ–¹å¼**:

```python
# åœ¨ GNN ä¸­è®¿é—®è¾¹
for i in range(num_edges):
    src_node = edge_index[0, i]   # ç¬¬iæ¡è¾¹çš„æºèŠ‚ç‚¹
    dst_node = edge_index[1, i]   # ç¬¬iæ¡è¾¹çš„ç›®æ ‡èŠ‚ç‚¹

    # æºèŠ‚ç‚¹çš„ç‰¹å¾
    h_src = x[src_node]  # [hidden_dim]

    # è®¡ç®—æ¶ˆæ¯
    message = W_r[relation] @ h_src

    # å‘é€åˆ°ç›®æ ‡èŠ‚ç‚¹
    h[dst_node] += message

# æˆ–è€…ç”¨å‘é‡åŒ–æ“ä½œ
src = edge_index[0]  # [num_edges]  æ‰€æœ‰æºèŠ‚ç‚¹
dst = edge_index[1]  # [num_edges]  æ‰€æœ‰ç›®æ ‡èŠ‚ç‚¹

h_src = x[src]  # [num_edges, hidden_dim]  æ‰€æœ‰æºèŠ‚ç‚¹ç‰¹å¾
messages = compute_messages(h_src)  # [num_edges, hidden_dim]

# èšåˆåˆ°ç›®æ ‡èŠ‚ç‚¹
h_new = scatter_add(messages, dst, dim=0, dim_size=num_nodes)
```

#### 3.5.2 edge_type: è¾¹ç±»å‹æ•°ç»„

**å®šä¹‰**: å­˜å‚¨æ¯æ¡è¾¹çš„å…³ç³»ç±»å‹

```python
edge_type: Tensor[num_edges]

# æ¯ä¸ªå…ƒç´ æ˜¯ä¸€ä¸ªæ•´æ•°ï¼Œè¡¨ç¤ºè¯¥è¾¹çš„å…³ç³»ID
```

**å®Œæ•´ç¤ºä¾‹**:

```python
# === å¯¹åº”ä¸Šé¢çš„ edge_index ===
# è¾¹0: 0 â†’ 10  (treats, ID=5)
# è¾¹1: 10 â†’ 0  (treatsâ»Â¹, ID=5+46=51)
# è¾¹2: 1 â†’ 20  (causes, ID=3)
# è¾¹3: 20 â†’ 1  (causesâ»Â¹, ID=3+46=49)
# è¾¹4: 0 â†’ 15  (prevents, ID=2)
# è¾¹5: 15 â†’ 0  (preventsâ»Â¹, ID=2+46=48)
# è¾¹6: 5 â†’ 10  (treats, ID=5)
# è¾¹7: 10 â†’ 5  (treatsâ»Â¹, ID=51)

edge_type = tensor([5, 51, 3, 49, 2, 48, 5, 51])
# å½¢çŠ¶: [8]

# å…³ç³»IDèŒƒå›´
# 0-45: æ­£å‘å…³ç³»
# 46-91: é€†å‘å…³ç³» (= æ­£å‘ID + 46)
```

**å…³ç³»IDç¼–ç è§„åˆ™**:

```python
# UMLS æœ‰ 46 ç§å…³ç³»
num_relations = 46

# æ­£å‘å…³ç³»
å…³ç³»ID = r  (0 â‰¤ r < 46)

# é€†å‘å…³ç³»
å…³ç³»ID = r + num_relations  (46 â‰¤ ID < 92)

# ç¤ºä¾‹
treats (æ­£å‘):  ID = 5
treatsâ»Â¹ (é€†å‘): ID = 5 + 46 = 51
```

**ä½¿ç”¨æ–¹å¼**:

```python
# åœ¨ GNN ä¸­æ ¹æ®å…³ç³»ç±»å‹é€‰æ‹©å˜æ¢çŸ©é˜µ
for i in range(num_edges):
    src = edge_index[0, i]
    dst = edge_index[1, i]
    rel = edge_type[i]  # å…³ç³»ç±»å‹

    # ä½¿ç”¨å…³ç³»ç‰¹å®šçš„å˜æ¢çŸ©é˜µ
    h_src = x[src]
    message = W_r[rel] @ h_src  # W_r[rel] æ˜¯è¯¥å…³ç³»çš„å˜æ¢çŸ©é˜µ

    h[dst] += message

# æˆ–è€…å‘é‡åŒ–ï¼ˆæŒ‰å…³ç³»ç±»å‹åˆ†ç»„ï¼‰
for r in range(num_relations):
    # æ‰¾å‡ºæ‰€æœ‰ç±»å‹ä¸ºrçš„è¾¹
    mask = (edge_type == r)

    if mask.sum() > 0:
        src_r = edge_index[0, mask]  # è¯¥å…³ç³»çš„æ‰€æœ‰æºèŠ‚ç‚¹
        dst_r = edge_index[1, mask]  # è¯¥å…³ç³»çš„æ‰€æœ‰ç›®æ ‡èŠ‚ç‚¹

        h_src_r = x[src_r]  # [num_edges_r, hidden_dim]

        # ä½¿ç”¨å…³ç³»rçš„å˜æ¢çŸ©é˜µ
        messages_r = h_src_r @ W_r[r]  # [num_edges_r, hidden_dim]

        # èšåˆ
        h_new = scatter_add(messages_r, dst_r, dim=0, dim_size=num_nodes)
```

#### 3.5.3 edge_index å’Œ edge_type çš„æ„å»ºè¿‡ç¨‹

```python
def build_pyg_graph(graph):
    """
    ä»çŸ¥è¯†å›¾è°±æ„å»º PyG æ ¼å¼

    Args:
        graph: KnowledgeGraph å¯¹è±¡

    Returns:
        edge_index: [2, num_edges]
        edge_type: [num_edges]
    """
    all_edges = []
    all_types = []

    # éå†æ‰€æœ‰æ•°æ®é›†ï¼ˆtrain + valid + testï¼‰
    for split in ['train', 'valid', 'test']:
        facts = getattr(graph, f'{split}_facts')

        for h, r, t in facts:
            # === æ­£å‘è¾¹ ===
            all_edges.append([h, t])
            all_types.append(r)

            # === é€†å‘è¾¹ ===
            all_edges.append([t, h])
            all_types.append(r + graph.relation_size)

    # è½¬æ¢ä¸º tensor
    edge_index = torch.tensor(all_edges, dtype=torch.long).t()
    # .t() è½¬ç½®: [[h1,t1], [h2,t2], ...] â†’ [[h1,h2,...], [t1,t2,...]]

    edge_type = torch.tensor(all_types, dtype=torch.long)

    return edge_index, edge_type

# === ä½¿ç”¨ç¤ºä¾‹ ===
graph = KnowledgeGraph("../data/umls")
edge_index, edge_type = build_pyg_graph(graph)

print(f"edge_index shape: {edge_index.shape}")  # [2, 13058]
print(f"edge_type shape: {edge_type.shape}")    # [13058]
print(f"num_edges: {edge_index.size(1)}")       # 13058
```

#### 3.5.4 ä¸ºä»€ä¹ˆéœ€è¦è¿™ä¸¤ä¸ªæ•°æ®ç»“æ„ï¼Ÿ

**1. edge_index: è¡¨ç¤ºå›¾çš„æ‹“æ‰‘ç»“æ„**

```python
# çŸ¥é“"è°è¿æ¥åˆ°è°"
edge_index å‘Šè¯‰æˆ‘ä»¬:
  - è¾¹0: èŠ‚ç‚¹0 è¿æ¥åˆ° èŠ‚ç‚¹10
  - è¾¹1: èŠ‚ç‚¹10 è¿æ¥åˆ° èŠ‚ç‚¹0
  - ...

# ç”¨äºæ¶ˆæ¯ä¼ é€’
for i in range(num_edges):
    message = f(x[edge_index[0, i]])  # ä»æºèŠ‚ç‚¹ç”Ÿæˆæ¶ˆæ¯
    x[edge_index[1, i]] += message    # å‘é€åˆ°ç›®æ ‡èŠ‚ç‚¹
```

**2. edge_type: è¡¨ç¤ºè¾¹çš„è¯­ä¹‰ç±»å‹**

```python
# çŸ¥é“"é€šè¿‡ä»€ä¹ˆå…³ç³»è¿æ¥"
edge_type å‘Šè¯‰æˆ‘ä»¬:
  - è¾¹0: ç±»å‹5 (treatså…³ç³»)
  - è¾¹1: ç±»å‹51 (treatsâ»Â¹å…³ç³»)
  - ...

# ç”¨äºå…³ç³»ç‰¹å®šçš„å˜æ¢
for i in range(num_edges):
    rel = edge_type[i]
    message = W_r[rel] @ x[src]  # ä¸åŒå…³ç³»ç”¨ä¸åŒçŸ©é˜µ
```

**3. ä¸¤è€…ç»“åˆ: å®Œæ•´çš„å›¾è¡¨ç¤º**

```python
# edge_index + edge_type = å®Œæ•´çš„çŸ¥è¯†å›¾è°±

çŸ¥è¯†å›¾è°±çš„ä¸‰å…ƒç»„:
  (h, r, t)

åœ¨ PyG ä¸­è¡¨ç¤ºä¸º:
  edge_index[:, i] = [h, t]  â† è°è¿åˆ°è°
  edge_type[i] = r           â† ä»€ä¹ˆå…³ç³»

# è¿˜åŸä¸‰å…ƒç»„
for i in range(num_edges):
    h = edge_index[0, i]
    t = edge_index[1, i]
    r = edge_type[i]

    print(f"ä¸‰å…ƒç»„{i}: ({h}, {r}, {t})")
```

#### 3.5.5 å¯è§†åŒ–ç¤ºä¾‹

```
çŸ¥è¯†å›¾è°±:
  (0, treats, 10)
  (1, causes, 20)
  (0, prevents, 15)

è½¬æ¢ä¸º PyG æ ¼å¼:

edge_index:
  [0, 10,  1, 20,  0, 15]  â† æºèŠ‚ç‚¹ (æ­£å‘) + ç›®æ ‡èŠ‚ç‚¹ (é€†å‘)
  [10, 0, 20,  1, 15,  0]  â† ç›®æ ‡èŠ‚ç‚¹ (æ­£å‘) + æºèŠ‚ç‚¹ (é€†å‘)

edge_type:
  [5, 51, 3, 49, 2, 48]    â† å…³ç³»ID (æ­£å‘ + é€†å‘)

å›¾ç¤º:
    treats(5)
  0 --------â†’ 10
  â†‘           â†“
  |           |
  |   treatsâ»Â¹(51)

    causes(3)
  1 --------â†’ 20
  â†‘           â†“
  |           |
  |   causesâ»Â¹(49)

    prevents(2)
  0 --------â†’ 15
  â†‘           â†“
  |           |
  |  preventsâ»Â¹(48)
```

---

## 4. æ ¸å¿ƒç»„ä»¶

### 4.1 RuleAwareGraphConv - è§„åˆ™æ„ŸçŸ¥å›¾å·ç§¯å±‚

#### è¾“å…¥

```python
x:          Tensor[num_nodes, hidden_dim]      # èŠ‚ç‚¹ç‰¹å¾
edge_index: Tensor[2, num_edges]               # è¾¹ç´¢å¼•
edge_type:  Tensor[num_edges]                  # è¾¹ç±»å‹
rule_ids:   Tensor[num_active_rules]           # æ¿€æ´»çš„è§„åˆ™ID
```

#### è¾“å‡º

```python
out: Tensor[num_nodes, hidden_dim]             # æ›´æ–°åçš„èŠ‚ç‚¹ç‰¹å¾
```

#### æ ¸å¿ƒç»„ä»¶

```python
class RuleAwareGraphConv(nn.Module):
    def __init__(self, in_dim, out_dim, num_relations, num_rules, dropout):
        # 1. å…³ç³»ç‰¹å®šå˜æ¢çŸ©é˜µ
        self.W_r = nn.Parameter(Tensor[num_relations, in_dim, out_dim])

        # 2. æ³¨æ„åŠ›æœºåˆ¶
        self.W_q = nn.Linear(in_dim, out_dim)       # Query
        self.W_k = nn.Linear(in_dim*3, out_dim)     # Key

        # 3. è§„åˆ™åµŒå…¥
        self.rule_embedding = nn.Embedding(num_rules, in_dim)

        # 4. å½’ä¸€åŒ–å’Œæ­£åˆ™åŒ–
        self.layer_norm = nn.LayerNorm(out_dim)
        self.dropout = nn.Dropout(dropout)
```

### 4.2 RuleGNN - å®Œæ•´æ¨¡å‹

#### æ¨¡å‹ç»“æ„

```python
class RuleGNN(nn.Module):
    def __init__(self, num_entities, num_relations, num_rules,
                 hidden_dim, num_layers, dropout):

        # 1. åµŒå…¥å±‚ (ä»é¢„è®­ç»ƒåŠ è½½)
        self.entity_embedding = nn.Embedding(num_entities, hidden_dim)
        self.relation_embedding = nn.Embedding(num_relations, hidden_dim)

        # 2. GNN å±‚ (å±‚æ•° = è§„åˆ™æœ€å¤§é•¿åº¦)
        self.conv_layers = nn.ModuleList([
            RuleAwareGraphConv(hidden_dim, hidden_dim,
                             num_relations, num_rules, dropout)
            for _ in range(num_layers)
        ])

        # 3. æ‰“åˆ† MLP
        self.score_func = nn.Sequential(
            nn.Linear(hidden_dim * 2, hidden_dim),
            nn.ReLU(),
            nn.Dropout(dropout),
            nn.Linear(hidden_dim, 1)
        )
```

#### å‚æ•°é‡

ä»¥ UMLS ä¸ºä¾‹ (hidden_dim=2000, num_layers=3):

```python
# åµŒå…¥å±‚
entity_embedding:   135 Ã— 2000 = 270,000
relation_embedding: 92 Ã— 2000 = 184,000
rule_embedding:     587 Ã— 2000 Ã— 3å±‚ = 3,522,000

# GNN å±‚ (æ¯å±‚)
W_r:  92 Ã— (2000 Ã— 2000) = 368,000,000
W_q:  2000 Ã— 2000 = 4,000,000
W_k:  6000 Ã— 2000 = 12,000,000

# 3 å±‚ GNN æ€»è®¡
GNN total: 3 Ã— (368M + 4M + 12M) = 1,152,000,000

# MLP
score_func: 4000 Ã— 2000 + 2000 Ã— 1 = 8,002,000

# æ€»å‚æ•°é‡
Total: â‰ˆ 1.16 billion
```

---

## 5. å®Œæ•´å‰å‘ä¼ æ’­æµç¨‹

### 5.1 ä¼ªä»£ç 

```python
def forward(queries, edge_index, edge_type, rule_ids):
    """
    Args:
        queries: [batch_size, 2]  (h, r)
        edge_index: [2, num_edges]
        edge_type: [num_edges]
        rule_ids: [num_active_rules]

    Returns:
        scores: [batch_size, num_entities]
    """

    # === æ­¥éª¤ 1: åˆå§‹åŒ–èŠ‚ç‚¹ç‰¹å¾ ===
    h = entity_embedding.weight  # [num_entities, hidden_dim]

    # === æ­¥éª¤ 2: å¤šå±‚ GNN ä¼ æ’­ ===
    for layer in conv_layers:
        h = layer(h, edge_index, edge_type, rule_ids)

    # === æ­¥éª¤ 3: æå–å¤´å®ä½“åµŒå…¥ ===
    head_ids = queries[:, 0]
    head_emb = h[head_ids]  # [batch_size, hidden_dim]

    # === æ­¥éª¤ 4: å¯¹æ‰€æœ‰å®ä½“æ‰“åˆ† ===
    tail_emb = h  # [num_entities, hidden_dim]

    # å¹¿æ’­æ‹¼æ¥
    head_expanded = head_emb.unsqueeze(1).expand(-1, num_entities, -1)
    tail_expanded = tail_emb.unsqueeze(0).expand(batch_size, -1, -1)

    pair_emb = concat([head_expanded, tail_expanded], dim=-1)
    # [batch_size, num_entities, hidden_dim*2]

    scores = score_func(pair_emb).squeeze(-1)
    # [batch_size, num_entities]

    return scores
```

### 5.2 å•å±‚ GNN è¯¦ç»†æµç¨‹

```python
def RuleAwareGraphConv_forward(x, edge_index, edge_type, rule_ids):
    """
    å•å±‚è§„åˆ™æ„ŸçŸ¥å›¾å·ç§¯

    Args:
        x: [num_nodes, hidden_dim]
        edge_index: [2, num_edges]
        edge_type: [num_edges]
        rule_ids: [num_active_rules]

    Returns:
        out: [num_nodes, hidden_dim]
    """

    src, dst = edge_index[0], edge_index[1]
    num_nodes = x.size(0)
    num_edges = edge_index.size(1)
    num_rules = rule_ids.size(0)

    # === æ­¥éª¤ 1: è·å–è§„åˆ™åµŒå…¥ ===
    h_R = rule_embedding(rule_ids)  # [num_rules, hidden_dim]

    # === æ­¥éª¤ 2: åˆå§‹åŒ–ç´¯åŠ å™¨ ===
    combined_messages = zeros([num_edges, hidden_dim])

    # === æ­¥éª¤ 3: éå†æ¯ä¸ªè§„åˆ™ ===
    for rule_idx, rule_id in enumerate(rule_ids):
        h_rule = h_R[rule_idx]  # [hidden_dim]

        # 3.1 è®¡ç®—æ³¨æ„åŠ›æƒé‡
        query = W_q(x[dst])  # [num_edges, hidden_dim]

        # è·å–å…³ç³»åµŒå…¥
        relation_emb = get_relation_embedding(edge_type)
        # [num_edges, hidden_dim]

        # æ‰©å±•è§„åˆ™åµŒå…¥
        rule_emb_exp = h_rule.unsqueeze(0).expand(num_edges, -1)

        # æ‹¼æ¥ Key: [æºèŠ‚ç‚¹, å…³ç³», è§„åˆ™]
        key_input = concat([x[src], relation_emb, rule_emb_exp], dim=-1)
        # [num_edges, hidden_dim*3]

        key = W_k(key_input)  # [num_edges, hidden_dim]

        # æ³¨æ„åŠ›åˆ†æ•°
        attn_scores = (query * key).sum(dim=-1) / sqrt(hidden_dim)
        # [num_edges]

        # Softmax (é’ˆå¯¹æ¯ä¸ªç›®æ ‡èŠ‚ç‚¹)
        attn_weights = scatter_softmax(attn_scores, dst, dim_size=num_nodes)
        # [num_edges]

        # 3.2 è®¡ç®—æ¶ˆæ¯ (å…³ç³»ç‰¹å®š)
        messages = zeros([num_edges, hidden_dim])

        for r in range(num_relations):
            mask = (edge_type == r)
            if mask.sum() > 0:
                # æ¶ˆæ¯ = W_r * æºèŠ‚ç‚¹ç‰¹å¾ * æ³¨æ„åŠ›æƒé‡
                msg = matmul(x[src[mask]], W_r[r])
                msg = msg * attn_weights[mask].unsqueeze(-1)
                messages[mask] = msg

        # 3.3 ç´¯ç§¯åˆ°ç´¯åŠ å™¨
        combined_messages += messages

    # === æ­¥éª¤ 4: å¹³å‡æ‰€æœ‰è§„åˆ™çš„æ¶ˆæ¯ ===
    combined_messages /= num_rules

    # === æ­¥éª¤ 5: èšåˆåˆ°ç›®æ ‡èŠ‚ç‚¹ ===
    out = scatter_add(combined_messages, dst, dim=0, dim_size=num_nodes)
    # [num_nodes, hidden_dim]

    # === æ­¥éª¤ 6: LayerNorm + ReLU + Dropout ===
    out = out + bias
    out = layer_norm(out)
    out = relu(out)
    out = dropout(out)

    return out
```

### 5.3 Tensor å½¢çŠ¶å˜åŒ–è¿½è¸ª

ä»¥ UMLS ä¸ºä¾‹ (135å®ä½“, 92å…³ç³», 587è§„åˆ™, batch=16):

```
è¾“å…¥é˜¶æ®µ:
  queries:      [16, 2]
  edge_index:   [2, 13420]
  edge_type:    [13420]
  rule_ids:     [25]  (å‡è®¾æ¿€æ´»25ä¸ªè§„åˆ™)

åˆå§‹åŒ–:
  hâ°:           [135, 2000]  â† entity_embedding

GNN Layer 1:
  src, dst:     [13420], [13420]

  è§„åˆ™å¾ªç¯ (éå†25ä¸ªè§„åˆ™):
    h_rule:           [2000]
    query:            [13420, 2000]
    relation_emb:     [13420, 2000]
    rule_emb_exp:     [13420, 2000]
    key_input:        [13420, 6000]
    key:              [13420, 2000]
    attn_scores:      [13420]
    attn_weights:     [13420]
    messages:         [13420, 2000]

  combined_messages:  [13420, 2000]
  hÂ¹:                 [135, 2000]  â† scatter_addç»“æœ

GNN Layer 2, 3: åŒä¸Š

æœ€ç»ˆèŠ‚ç‚¹ç‰¹å¾:
  há´¸:           [135, 2000]

æå–å¤´å®ä½“:
  head_emb:     [16, 2000]

æ‰“åˆ†:
  tail_emb:     [135, 2000]
  head_exp:     [16, 135, 2000]
  tail_exp:     [16, 135, 2000]
  pair_emb:     [16, 135, 4000]
  scores:       [16, 135]

è¾“å‡º:
  scores:       [16, 135]  â† æ¯ä¸ªæŸ¥è¯¢å¯¹æ‰€æœ‰135ä¸ªå®ä½“çš„å¾—åˆ†
```

---

## 6. æ•°å­¦å…¬å¼è¯¦è§£

### 6.1 è§„åˆ™æ„ŸçŸ¥çš„æ³¨æ„åŠ›æœºåˆ¶

#### å…¬å¼

$$
\alpha_{ij}^{\phi} = \frac{\exp(\text{score}(h_i, h_j, r_{ij}, \phi))}{\sum_{k \in \mathcal{N}(j)} \exp(\text{score}(h_k, h_j, r_{kj}, \phi))}
$$

å…¶ä¸­:
- $\alpha_{ij}^{\phi}$: è¾¹ $(i \to j)$ åœ¨è§„åˆ™ $\phi$ ä¸‹çš„æ³¨æ„åŠ›æƒé‡
- $h_i, h_j$: æºèŠ‚ç‚¹å’Œç›®æ ‡èŠ‚ç‚¹çš„ç‰¹å¾
- $r_{ij}$: è¾¹çš„å…³ç³»ç±»å‹
- $\phi$: è§„åˆ™åµŒå…¥

#### æ³¨æ„åŠ›åˆ†æ•°è®¡ç®—

$$
\text{score}(h_i, h_j, r_{ij}, \phi) = \frac{(\mathbf{W}_q h_j) \cdot (\mathbf{W}_k [h_i \| r_{ij} \| \phi])}{\sqrt{d}}
$$

- $\mathbf{W}_q \in \mathbb{R}^{d \times d}$: Query å˜æ¢çŸ©é˜µ
- $\mathbf{W}_k \in \mathbb{R}^{3d \times d}$: Key å˜æ¢çŸ©é˜µ
- $[h_i \| r_{ij} \| \phi]$: æ‹¼æ¥æ“ä½œ
- $d$: éšè—ç»´åº¦

**ç›´è§‚ç†è§£**:
- Query: "ç›®æ ‡èŠ‚ç‚¹æƒ³è¦ä»€ä¹ˆä¿¡æ¯ï¼Ÿ"
- Key: "è¿™æ¡è¾¹+è§„åˆ™èƒ½æä¾›ä»€ä¹ˆä¿¡æ¯ï¼Ÿ"
- ç›¸ä¼¼åº¦é«˜ â†’ æ³¨æ„åŠ›æƒé‡å¤§

### 6.2 æ¶ˆæ¯ç”Ÿæˆ

#### å…¬å¼

$$
m_{ij}^{\phi} = \alpha_{ij}^{\phi} \cdot (\mathbf{W}_{r_{ij}} h_i)
$$

- $\mathbf{W}_{r_{ij}} \in \mathbb{R}^{d \times d}$: å…³ç³»$r_{ij}$ç‰¹å®šçš„å˜æ¢çŸ©é˜µ
- $\alpha_{ij}^{\phi}$: æ³¨æ„åŠ›æƒé‡ï¼ˆè§„åˆ™$\phi$è°ƒæ§ï¼‰

**å…³ç³»ç‰¹å®šå˜æ¢**:
```
ä¸åŒå…³ç³»ç”¨ä¸åŒçŸ©é˜µ:
  W_treats:    ç”¨äº "treats" å…³ç³»
  W_diagnoses: ç”¨äº "diagnoses" å…³ç³»
  ...
```

### 6.3 å¤šè§„åˆ™èšåˆ

#### å…¬å¼

$$
m_{ij} = \frac{1}{|\Phi_a|} \sum_{\phi \in \Phi_a} m_{ij}^{\phi}
$$

- $\Phi_a$: æ¿€æ´»çš„è§„åˆ™é›†åˆ
- $m_{ij}^{\phi}$: è§„åˆ™$\phi$ä¸‹çš„æ¶ˆæ¯
- å¹³å‡: é˜²æ­¢è§„åˆ™æ•°é‡å½±å“æ¶ˆæ¯å°ºåº¦

### 6.4 æ¶ˆæ¯èšåˆ

#### å…¬å¼

$$
h_j^{(l+1)} = \text{LayerNorm}\left( h_j^{(l)} + \sum_{i \in \mathcal{N}(j)} m_{ij} \right)
$$

$$
h_j^{(l+1)} = \text{ReLU}(h_j^{(l+1)})
$$

$$
h_j^{(l+1)} = \text{Dropout}(h_j^{(l+1)})
$$

- $\mathcal{N}(j)$: èŠ‚ç‚¹$j$çš„é‚»å±…
- æ®‹å·®è¿æ¥: $h_j^{(l)} + \text{aggregation}$
- LayerNorm: ç¨³å®šè®­ç»ƒ
- ReLU: éçº¿æ€§æ¿€æ´»
- Dropout: æ­£åˆ™åŒ–

### 6.5 æ‰“åˆ†å‡½æ•°

#### å…¬å¼

$$
s(h, r, t) = \text{MLP}([h_h^{(L)} \| h_t^{(L)}])
$$

$$
= \mathbf{W}_2 \cdot \text{ReLU}(\mathbf{W}_1 [h_h^{(L)} \| h_t^{(L)}] + b_1) + b_2
$$

- $h_h^{(L)}, h_t^{(L)}$: GNNè¾“å‡ºçš„å¤´å°¾å®ä½“åµŒå…¥
- $\mathbf{W}_1 \in \mathbb{R}^{d \times 2d}$, $\mathbf{W}_2 \in \mathbb{R}^{1 \times d}$

**ä¸¤å±‚MLP**:
```
è¾“å…¥: [h_h || h_t]  [1Ã—4000]
  â†“  Wâ‚, bâ‚
éšè—å±‚: ReLU        [1Ã—2000]
  â†“  Wâ‚‚, bâ‚‚
è¾“å‡º: score         [1Ã—1]
```

#### 6.5.1 ä¸¤å±‚MLPè¯¦ç»†è§£æ â­

MLP (å¤šå±‚æ„ŸçŸ¥æœº) æ˜¯ Rule-GNN çš„æœ€ç»ˆæ‰“åˆ†æ¨¡å—ï¼Œè´Ÿè´£å°† GNN è¾“å‡ºçš„å¤´å°¾å®ä½“è¡¨ç¤ºè½¬æ¢ä¸ºä¸‰å…ƒç»„å¾—åˆ†ã€‚

##### 1. MLP ç»“æ„å®šä¹‰

```python
# åœ¨ rule_gnn_model.py:204-209
self.score_func = nn.Sequential(
    nn.Linear(hidden_dim * 2, hidden_dim),  # ç¬¬ä¸€å±‚: 4000 â†’ 2000
    nn.ReLU(),                               # æ¿€æ´»å‡½æ•°
    nn.Dropout(dropout),                     # æ­£åˆ™åŒ–
    nn.Linear(hidden_dim, 1)                 # ç¬¬äºŒå±‚: 2000 â†’ 1
)
```

**å‚æ•°è¯´æ˜**:
- `hidden_dim`: åµŒå…¥ç»´åº¦ (UMLS ä¸­ä¸º 2000)
- `dropout`: Dropout ç‡ (é»˜è®¤ 0.1)

##### 2. é€å±‚å‰å‘ä¼ æ’­è¯¦è§£

**è¾“å…¥é˜¶æ®µ**:
```python
# å¤´å®ä½“åµŒå…¥ (ç»è¿‡ L å±‚ GNN å)
h_head: [batch_size, hidden_dim]  # [16, 2000]

# å°¾å®ä½“åµŒå…¥
h_tail: [num_entities, hidden_dim]  # [135, 2000]

# æ‹¼æ¥æ“ä½œ (å¹¿æ’­)
# å¯¹æ¯ä¸ªæŸ¥è¯¢ï¼Œä¸æ‰€æœ‰å€™é€‰å®ä½“æ‹¼æ¥
pair_emb = torch.cat([
    h_head.unsqueeze(1).expand(-1, num_entities, -1),  # [16, 135, 2000]
    h_tail.unsqueeze(0).expand(batch_size, -1, -1)     # [16, 135, 2000]
], dim=-1)  # [16, 135, 4000]
```

**ç¬¬ä¸€å±‚: Linear(4000 â†’ 2000)**
```python
# æƒé‡çŸ©é˜µ: Wâ‚ âˆˆ â„^(4000Ã—2000)
# åç½®å‘é‡: bâ‚ âˆˆ â„^2000

# å‰å‘è®¡ç®—
layer1_output = pair_emb @ Wâ‚.T + bâ‚
# [16, 135, 4000] @ [2000, 4000].T + [2000]
# â†’ [16, 135, 2000]
```

**ä½œç”¨**: å°†æ‹¼æ¥çš„é«˜ç»´ç‰¹å¾ (4000) å‹ç¼©åˆ°åŸå§‹åµŒå…¥ç»´åº¦ (2000)ï¼ŒåŒæ—¶å­¦ä¹ å¤´å°¾å®ä½“ä¹‹é—´çš„äº¤äº’æ¨¡å¼ã€‚

**æ¿€æ´»å‡½æ•°: ReLU**
```python
# ReLU(x) = max(0, x)
# å¼•å…¥éçº¿æ€§ï¼Œä½¿æ¨¡å‹èƒ½å­¦ä¹ å¤æ‚çš„å…³ç³»æ¨¡å¼

layer1_relu = F.relu(layer1_output)
# [16, 135, 2000]

# ç¤ºä¾‹å€¼å˜åŒ–:
# è¾“å…¥:  [-0.5, 0.3, -1.2, 0.8]
# è¾“å‡º:  [0.0,  0.3,  0.0, 0.8]  (è´Ÿå€¼å½’é›¶)
```

**Dropout å±‚**
```python
# è®­ç»ƒæ—¶éšæœºå°† 10% çš„ç¥ç»å…ƒè¾“å‡ºç½®ä¸º 0
# æµ‹è¯•æ—¶ä¸èµ·ä½œç”¨

layer1_dropout = F.dropout(layer1_relu, p=0.1, training=True)
# [16, 135, 2000]

# ä½œç”¨: é˜²æ­¢è¿‡æ‹Ÿåˆï¼Œæé«˜æ³›åŒ–èƒ½åŠ›
```

**ç¬¬äºŒå±‚: Linear(2000 â†’ 1)**
```python
# æƒé‡çŸ©é˜µ: Wâ‚‚ âˆˆ â„^(2000Ã—1)
# åç½®æ ‡é‡: bâ‚‚ âˆˆ â„

# å‰å‘è®¡ç®—
scores = layer1_dropout @ Wâ‚‚ + bâ‚‚
# [16, 135, 2000] @ [2000, 1] + 1
# â†’ [16, 135, 1]

# å‹ç¼©æœ€åä¸€ç»´
scores = scores.squeeze(-1)  # [16, 135]
```

**ä½œç”¨**: å°† 2000 ç»´ç‰¹å¾å‹ç¼©ä¸ºå•ä¸ªæ ‡é‡åˆ†æ•°ï¼Œè¡¨ç¤ºä¸‰å…ƒç»„ (h, r, t) çš„åˆç†ç¨‹åº¦ã€‚

##### 3. å®Œæ•´çš„æ•°å€¼ç¤ºä¾‹

ä»¥ UMLS æ•°æ®é›†ä¸ºä¾‹ (batch_size=16, num_entities=135, hidden_dim=2000):

```python
# === è¾“å…¥ ===
h_head = tensor([[0.12, -0.34, ..., 0.56],  # æŸ¥è¯¢1çš„å¤´å®ä½“
                 [0.45,  0.23, ..., -0.12],  # æŸ¥è¯¢2çš„å¤´å®ä½“
                 ...])  # [16, 2000]

h_tail = tensor([[0.89, -0.12, ..., 0.34],  # å®ä½“0
                 [-0.23, 0.56, ..., 0.78],  # å®ä½“1
                 ...])  # [135, 2000]

# === æ‹¼æ¥ ===
pair_emb = concat([h_head[i], h_tail[j]])  # å¯¹æ‰€æœ‰ i,j é…å¯¹
# [16, 135, 4000]

# === ç¬¬ä¸€å±‚ ===
# Wâ‚: [2000, 4000], bâ‚: [2000]
layer1 = pair_emb @ Wâ‚.T + bâ‚  # [16, 135, 2000]

# å‡è®¾æŸä¸ªä½ç½®çš„å€¼: [0.5, -0.3, 1.2, -0.8, ...]
layer1_relu = ReLU(layer1)
# â†’ [0.5, 0.0, 1.2, 0.0, ...]  (è´Ÿå€¼å½’é›¶)

layer1_dropout = Dropout(layer1_relu, p=0.1)
# â†’ éšæœº 10% çš„ä½ç½®ç½®ä¸º 0

# === ç¬¬äºŒå±‚ ===
# Wâ‚‚: [1, 2000], bâ‚‚: scalar
scores = layer1_dropout @ Wâ‚‚.T + bâ‚‚
# [16, 135, 2000] @ [2000, 1] + 1
# â†’ [16, 135]

# ç¤ºä¾‹è¾“å‡º (æŸ¥è¯¢0 å¯¹æ‰€æœ‰135ä¸ªå®ä½“çš„å¾—åˆ†):
scores[0] = [2.34, -1.23, 0.45, ..., 1.89]
#            â†‘      â†‘      â†‘           â†‘
#           å®ä½“0  å®ä½“1  å®ä½“2       å®ä½“134
```

##### 4. ä¸ºä»€ä¹ˆéœ€è¦ä¸¤å±‚MLPï¼Ÿ

**å•å±‚çš„å±€é™æ€§**:
```python
# å¦‚æœåªç”¨å•å±‚: Linear(4000 â†’ 1)
scores = (pair_emb @ W) + b
# åªèƒ½å­¦ä¹ çº¿æ€§ç»„åˆï¼Œæ— æ³•æ•è·å¤æ‚çš„éçº¿æ€§å…³ç³»æ¨¡å¼
```

**ä¸¤å±‚çš„ä¼˜åŠ¿**:

1. **éçº¿æ€§å»ºæ¨¡èƒ½åŠ›**
   - ReLU æ¿€æ´»å‡½æ•°å¼•å…¥éçº¿æ€§
   - å¯ä»¥å­¦ä¹ å¤æ‚çš„å¤´å°¾å®ä½“äº¤äº’æ¨¡å¼

   **ç¤ºä¾‹**:
   - å•å±‚: `score = wâ‚Â·h_head + wâ‚‚Â·h_tail + b` (çº¿æ€§)
   - ä¸¤å±‚: `score = f(g(h_head, h_tail))` (éçº¿æ€§ç»„åˆ)

2. **ç‰¹å¾ç»´åº¦æ§åˆ¶**
   - ç¬¬ä¸€å±‚: 4000 â†’ 2000 (å‹ç¼©å†—ä½™ä¿¡æ¯)
   - ç¬¬äºŒå±‚: 2000 â†’ 1 (èšåˆä¸ºæ ‡é‡)

   **æ¸è¿›å¼å‹ç¼©**æ¯”ç›´æ¥ 4000 â†’ 1 æ›´ç¨³å®šï¼Œä¿¡æ¯æŸå¤±æ›´å°‘ã€‚

3. **æ­£åˆ™åŒ–æ•ˆæœ**
   - ä¸­é—´çš„ Dropout å±‚é˜²æ­¢è¿‡æ‹Ÿåˆ
   - ä¸¤å±‚ç»“æ„æœ¬èº«ä¹Ÿèµ·åˆ°æ­£åˆ™åŒ–ä½œç”¨

##### 5. MLP å‚æ•°é‡è®¡ç®—

```python
# ç¬¬ä¸€å±‚
Wâ‚: 2000 Ã— 4000 = 8,000,000
bâ‚: 2000 = 2,000

# ç¬¬äºŒå±‚
Wâ‚‚: 1 Ã— 2000 = 2,000
bâ‚‚: 1 = 1

# æ€»è®¡
Total = 8,000,000 + 2,000 + 2,000 + 1 = 8,004,001 å‚æ•°
```

**å æ¯”**: åœ¨ Rule-GNN æ€»å‚æ•°é‡ (~1.16B) ä¸­å  **0.69%**ï¼Œéå¸¸è½»é‡ã€‚

##### 6. è®­ç»ƒæ—¶çš„ä½œç”¨

```python
# è®­ç»ƒæ—¶ï¼ŒMLP å­¦ä¹ ä»€ä¹ˆæ ·çš„ (head, tail) é…å¯¹æ˜¯åˆç†çš„

# æ­£æ ·æœ¬: (é˜¿å¸åŒ¹æ—, treats, å¤´ç—›)
h_aspirin = [0.12, -0.34, ...]
h_headache = [0.89, -0.12, ...]
score_positive = MLP([h_aspirin || h_headache])  # æœŸæœ›: é«˜åˆ†

# è´Ÿæ ·æœ¬: (é˜¿å¸åŒ¹æ—, treats, ç«æ˜Ÿ)
h_mars = [-0.45, 0.78, ...]
score_negative = MLP([h_aspirin || h_mars])  # æœŸæœ›: ä½åˆ†

# æŸå¤±å‡½æ•°é©±åŠ¨ MLP å­¦ä¹ åŒºåˆ†æ­£è´Ÿæ ·æœ¬
```

##### 7. æ¨ç†æ—¶çš„ä½¿ç”¨

```python
# ç»™å®šæŸ¥è¯¢: (é˜¿å¸åŒ¹æ—, treats, ?)
h_aspirin = gnn_output[entity_id_aspirin]  # [2000]

# å¯¹æ‰€æœ‰å€™é€‰å®ä½“æ‰“åˆ†
scores = []
for candidate in all_entities:  # 135 ä¸ªå®ä½“
    h_candidate = gnn_output[candidate]
    pair = concat([h_aspirin, h_candidate])  # [4000]
    score = MLP(pair)  # æ ‡é‡
    scores.append(score)

# æ’åºé€‰æ‹© Top-K
top_k = argsort(scores, descending=True)[:10]
# â†’ [å¤´ç—›, å‘çƒ§, ç–¼ç—›, ...]
```

##### 8. ä»£ç å®ç°ä½ç½®

**æ¨¡å‹å®šä¹‰**: `rule_gnn_model.py:204-209`
```python
self.score_func = nn.Sequential(
    nn.Linear(hidden_dim * 2, hidden_dim),
    nn.ReLU(),
    nn.Dropout(dropout),
    nn.Linear(hidden_dim, 1)
)
```

**å‰å‘è°ƒç”¨**: `rule_gnn_model.py:307-312`
```python
combined = torch.cat([
    h_heads_exp.expand(-1, self.num_entities, -1),
    h_tails_exp.expand(batch_size, -1, -1)
], dim=-1)  # [batch_size, num_entities, hidden_dim*2]

scores = self.score_func(combined).squeeze(-1)  # [batch_size, num_entities]
```

##### 9. ä¸å…¶ä»–KGEæ¨¡å‹å¯¹æ¯”

| æ¨¡å‹ | æ‰“åˆ†å‡½æ•° | å¤æ‚åº¦ |
|-----|---------|-------|
| **DistMult** | $h^T \text{diag}(r) t$ | çº¿æ€§ |
| **ComplEx** | $\text{Re}(h^T \text{diag}(r) \bar{t})$ | çº¿æ€§ |
| **RotatE** | $\gamma - \|h \circ r - t\|$ | çº¿æ€§ |
| **ConvE** | $\text{vec}(\text{Conv}([h; r])) W t$ | éçº¿æ€§ (CNN) |
| **Rule-GNN** | $\text{MLP}([h_{\text{GNN}} \| t_{\text{GNN}}])$ | **éçº¿æ€§ (MLP)** |

**Rule-GNN çš„ä¼˜åŠ¿**:
- GNN å·²ç»èšåˆäº†è§„åˆ™ä¿¡æ¯
- MLP åªéœ€å­¦ä¹ æœ€ç»ˆçš„åŒ¹é…æ¨¡å¼
- æ¯” ConvE çš„å·ç§¯æ›´è½»é‡ï¼Œæ¯” DistMult/RotatE çš„çº¿æ€§æ›´å¼ºå¤§

### 6.6 æŸå¤±å‡½æ•°

#### Binary Cross-Entropy with Logits

$$
\mathcal{L} = -\frac{1}{N} \sum_{i=1}^{N} \sum_{j=1}^{n} \left[ y_{ij} \log(\sigma(s_{ij})) + (1 - y_{ij}) \log(1 - \sigma(s_{ij})) \right]
$$

- $y_{ij} \in \{0, 1\}$: å®ä½“$j$æ˜¯å¦æ˜¯æŸ¥è¯¢$i$çš„æ­£ç¡®ç­”æ¡ˆ
- $s_{ij}$: æŸ¥è¯¢$i$å¯¹å®ä½“$j$çš„å¾—åˆ†
- $\sigma$: Sigmoidå‡½æ•°
- $N$: batchå¤§å°, $n$: å®ä½“æ•°é‡

#### æ ‡ç­¾å¹³æ»‘

$$
\tilde{y}_{ij} = y_{ij} \cdot (1 - \epsilon) + \frac{\epsilon}{n}
$$

- $\epsilon$: å¹³æ»‘ç³»æ•° (å¦‚ 0.2)
- æ•ˆæœ: é˜²æ­¢æ¨¡å‹è¿‡åº¦è‡ªä¿¡

**ç¤ºä¾‹** ($n=135$, $\epsilon=0.2$):
```
åŸå§‹æ ‡ç­¾: y = [0, 0, 0, 1, 0, ...]
                        â†‘ å”¯ä¸€æ­£ç¡®ç­”æ¡ˆ

å¹³æ»‘å: á»¹ = [0.0015, 0.0015, 0.0015, 0.8015, 0.0015, ...]
                                      â†‘ 0.8 + 0.2/135
```

---

## 7. è®­ç»ƒæµç¨‹

### 7.1 å®Œæ•´è®­ç»ƒæµç¨‹

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ é˜¶æ®µ 1: RulE é¢„è®­ç»ƒ (30,000 steps)                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ è¾“å…¥:                                                        â”‚
â”‚   â€¢ ä¸‰å…ƒç»„: (h, r, t)                                        â”‚
â”‚   â€¢ è§„åˆ™: râ‚ âˆ§ râ‚‚ â†’ r_head                                  â”‚
â”‚                                                             â”‚
â”‚ è®­ç»ƒ:                                                        â”‚
â”‚   â€¢ RotatE æŸå¤± (ä¸‰å…ƒç»„)                                     â”‚
â”‚   â€¢ è§„åˆ™ä¸€è‡´æ€§æŸå¤±                                           â”‚
â”‚                                                             â”‚
â”‚ è¾“å‡º:                                                        â”‚
â”‚   â€¢ entity_embedding [nÃ—d]                                  â”‚
â”‚   â€¢ relation_embedding [mÃ—d]                                â”‚
â”‚   â€¢ rule_embedding [kÃ—d]                                    â”‚
â”‚                                                             â”‚
â”‚ ä¿å­˜: {save_path}/checkpoint                                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                        â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ é˜¶æ®µ 2: å¯¼å‡ºåµŒå…¥                                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ embeddings_dict = {                                         â”‚
â”‚     'entity_embedding': entity_emb,                         â”‚
â”‚     'relation_embedding': relation_emb,                     â”‚
â”‚     'rule_emb': rule_emb                                    â”‚
â”‚ }                                                           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                        â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ é˜¶æ®µ 3: Rule-GNN è®­ç»ƒ (50 epochs)                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ 3.1 åˆå§‹åŒ–                                                   â”‚
â”‚   â€¢ åˆ›å»º Rule-GNN æ¨¡å‹                                       â”‚
â”‚   â€¢ åŠ è½½é¢„è®­ç»ƒåµŒå…¥ (å†»ç»“)                                    â”‚
â”‚   â€¢ éšæœºåˆå§‹åŒ– GNN å’Œ MLP å‚æ•°                              â”‚
â”‚                                                             â”‚
â”‚ 3.2 è®­ç»ƒå¾ªç¯                                                 â”‚
â”‚   for epoch in range(50):                                   â”‚
â”‚       for batch in train_loader:                            â”‚
â”‚           # å‰å‘ä¼ æ’­                                         â”‚
â”‚           scores = model(queries, edge_index, edge_type,    â”‚
â”‚                         rule_ids)                           â”‚
â”‚                                                             â”‚
â”‚           # è®¡ç®—æŸå¤±                                         â”‚
â”‚           loss = BCEWithLogitsLoss(scores, target)          â”‚
â”‚                                                             â”‚
â”‚           # åå‘ä¼ æ’­                                         â”‚
â”‚           loss.backward()                                   â”‚
â”‚           optimizer.step()                                  â”‚
â”‚                                                             â”‚
â”‚       # éªŒè¯ (æ¯5ä¸ªepoch)                                    â”‚
â”‚       if epoch % 5 == 0:                                    â”‚
â”‚           valid_metrics = evaluate(valid_set)               â”‚
â”‚           save_if_best(model)                               â”‚
â”‚                                                             â”‚
â”‚ 3.3 æœ€ç»ˆæµ‹è¯•                                                 â”‚
â”‚   â€¢ åŠ è½½æœ€ä½³æ¨¡å‹                                             â”‚
â”‚   â€¢ åœ¨æµ‹è¯•é›†ä¸Šè¯„ä¼°                                           â”‚
â”‚                                                             â”‚
â”‚ è¾“å‡º:                                                        â”‚
â”‚   â€¢ rule_gnn_best.pt (æœ€ä½³æ¨¡å‹)                             â”‚
â”‚   â€¢ test_metrics (MRR, Hits@K)                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 7.2 ä¸€ä¸ªè®­ç»ƒ Epoch çš„è¯¦ç»†æ­¥éª¤

```python
def train_epoch(model, train_loader, optimizer, args):
    model.train()
    total_loss = 0

    for batch_idx, batch in enumerate(train_loader):
        # ======= æ•°æ®å‡†å¤‡ =======
        all_h, all_r, all_t, target, edges_to_remove = batch

        # all_h, all_r, all_t: [batch_size]  å¤´ã€å…³ç³»ã€å°¾å®ä½“ID
        # target: [batch_size, num_entities]  å¤šçƒ­æ ‡ç­¾
        # edges_to_remove: [batch_size]  è®­ç»ƒæ—¶éœ€è¦ç§»é™¤çš„è¾¹

        # è½¬ç§»åˆ° GPU
        all_h = all_h.to(device)
        all_r = all_r.to(device)
        all_t = all_t.to(device)
        target = target.to(device)

        # æ„å»ºæŸ¥è¯¢
        queries = torch.stack([all_h, all_r], dim=1)  # [batch_size, 2]

        # ======= è·å–æ¿€æ´»è§„åˆ™ =======
        active_rules = set()
        for r in all_r:
            if r in relation2rules:
                for rule in relation2rules[r]:
                    active_rules.add(rule[0])  # rule_id

        rule_ids = torch.tensor(list(active_rules), device=device)

        if len(rule_ids) == 0:
            continue  # æ²¡æœ‰è§„åˆ™ï¼Œè·³è¿‡æ­¤batch

        # ======= å‰å‘ä¼ æ’­ =======
        scores = model(queries, edge_index, edge_type, rule_ids)
        # scores: [batch_size, num_entities]

        # ======= è®¡ç®—æŸå¤± =======
        # æ ‡ç­¾å¹³æ»‘
        if args.smoothing > 0:
            smooth_target = target * (1 - args.smoothing) + \
                          args.smoothing / num_entities
            loss = nn.BCEWithLogitsLoss()(scores, smooth_target)
        else:
            loss = nn.BCEWithLogitsLoss()(scores, target)

        # ======= åå‘ä¼ æ’­ =======
        optimizer.zero_grad()
        loss.backward()

        # æ¢¯åº¦è£å‰ª (å¯é€‰)
        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)

        optimizer.step()

        total_loss += loss.item()

        # ======= æ—¥å¿— =======
        if (batch_idx + 1) % args.print_every == 0:
            avg_loss = total_loss / (batch_idx + 1)
            print(f"Batch {batch_idx+1}, Loss: {avg_loss:.4f}")

    return total_loss / len(train_loader)
```

### 7.3 è®­ç»ƒé…ç½® (UMLS ç¤ºä¾‹)

```json
{
    "æ•°æ®":
    {
        "å®ä½“æ•°": 135,
        "å…³ç³»æ•°": 46,
        "è§„åˆ™æ•°": 587,
        "è®­ç»ƒä¸‰å…ƒç»„": 5216
    },

    "RulE é¢„è®­ç»ƒ":
    {
        "hidden_dim": 2000,
        "max_steps": 30000,
        "batch_size": 256,
        "negative_sample_size": 512,
        "learning_rate": 0.0001,
        "gamma_fact": 6.0,
        "gamma_rule": 8.0
    },

    "Rule-GNN è®­ç»ƒ":
    {
        "num_layers": 3,
        "g_batch_size": 16,
        "g_lr": 0.0001,
        "dropout": 0.1,
        "smoothing": 0.2,
        "rule_gnn_num_iters": 50,
        "rule_gnn_valid_every": 5
    }
}
```

---

## 8. æ¨ç†æµç¨‹

### 8.1 æ¨ç†æ­¥éª¤

```python
def inference(model, query, edge_index, edge_type, relation2rules):
    """
    æ¨ç†: ç»™å®šæŸ¥è¯¢ (h, r)ï¼Œé¢„æµ‹å°¾å®ä½“ t

    Args:
        model: è®­ç»ƒå¥½çš„ Rule-GNN æ¨¡å‹
        query: (head_id, relation_id)
        edge_index: å®Œæ•´çŸ¥è¯†å›¾è°±çš„è¾¹
        edge_type: è¾¹çš„å…³ç³»ç±»å‹
        relation2rules: å…³ç³»åˆ°è§„åˆ™çš„æ˜ å°„

    Returns:
        predictions: [(entity_id, score), ...] æŒ‰åˆ†æ•°æ’åº
    """
    model.eval()

    with torch.no_grad():
        # ======= å‡†å¤‡è¾“å…¥ =======
        head_id, relation_id = query
        queries = torch.tensor([[head_id, relation_id]], device=device)

        # ======= è·å–æ¿€æ´»è§„åˆ™ =======
        active_rules = set()
        if relation_id in relation2rules:
            for rule in relation2rules[relation_id]:
                active_rules.add(rule[0])

        rule_ids = torch.tensor(list(active_rules), device=device)

        if len(rule_ids) == 0:
            # æ²¡æœ‰è§„åˆ™ï¼Œä½¿ç”¨æ‰€æœ‰è§„åˆ™æˆ–è¿”å›ç©º
            rule_ids = torch.arange(model.num_rules, device=device)

        # ======= å‰å‘ä¼ æ’­ =======
        scores = model(queries, edge_index, edge_type, rule_ids)
        # scores: [1, num_entities]

        scores = scores.squeeze(0)  # [num_entities]

        # ======= æ’åº =======
        sorted_scores, sorted_indices = torch.sort(scores, descending=True)

        # ======= æ„å»ºé¢„æµ‹ç»“æœ =======
        predictions = []
        for i in range(len(sorted_indices)):
            entity_id = sorted_indices[i].item()
            score = sorted_scores[i].item()
            predictions.append((entity_id, score))

        return predictions


# ======= ä½¿ç”¨ç¤ºä¾‹ =======
query = (10, 5)  # (å®ä½“10, å…³ç³»5)
predictions = inference(model, query, edge_index, edge_type, relation2rules)

print("Top-10 é¢„æµ‹:")
for i, (entity_id, score) in enumerate(predictions[:10]):
    entity_name = id2entity[entity_id]
    print(f"{i+1}. {entity_name} (score: {score:.4f})")
```

### 8.2 Filtered Ranking

**ç›®çš„**: æ’é™¤å·²çŸ¥çš„çœŸå®ä¸‰å…ƒç»„

```python
def filtered_inference(model, query, true_tail,
                       edge_index, edge_type,
                       relation2rules, hr2ooo):
    """
    Filtered setting: æ’é™¤æ‰€æœ‰å·²çŸ¥ç­”æ¡ˆ

    Args:
        hr2ooo: Dict[(h, r)] = set(known_tails)
                åŒ…å« train + valid + test çš„æ‰€æœ‰å°¾å®ä½“
    """
    # è·å–æ‰€æœ‰é¢„æµ‹åˆ†æ•°
    predictions = inference(model, query, edge_index,
                          edge_type, relation2rules)

    # è·å–å·²çŸ¥å°¾å®ä½“
    h, r = query
    known_tails = hr2ooo.get((h, r), set())

    # è¿‡æ»¤åˆ†æ•°
    filtered_predictions = []
    for entity_id, score in predictions:
        if entity_id == true_tail:
            # ä¿ç•™çœŸå®ç­”æ¡ˆ
            filtered_predictions.append((entity_id, score))
        elif entity_id not in known_tails:
            # ä¿ç•™æœªçŸ¥å®ä½“
            filtered_predictions.append((entity_id, score))
        # else: è¿‡æ»¤æ‰å…¶ä»–å·²çŸ¥ç­”æ¡ˆ

    # é‡æ–°æ’åº
    filtered_predictions.sort(key=lambda x: x[1], reverse=True)

    # è®¡ç®—çœŸå®ç­”æ¡ˆçš„æ’å
    for rank, (entity_id, score) in enumerate(filtered_predictions, 1):
        if entity_id == true_tail:
            return rank, filtered_predictions

    return len(filtered_predictions) + 1, filtered_predictions
```

### 8.3 è¯„ä¼°æŒ‡æ ‡

```python
def evaluate(model, dataset, edge_index, edge_type, relation2rules):
    """
    è¯„ä¼°æ¨¡å‹æ€§èƒ½

    Returns:
        metrics: {
            'MRR': Mean Reciprocal Rank,
            'MR': Mean Rank,
            'HITS@1': Top-1 accuracy,
            'HITS@3': Top-3 accuracy,
            'HITS@10': Top-10 accuracy
        }
    """
    ranks = []
    reciprocal_ranks = []

    for query, true_tail in dataset:
        # Filtered ranking
        rank, _ = filtered_inference(model, query, true_tail,
                                     edge_index, edge_type,
                                     relation2rules, hr2ooo)

        ranks.append(rank)
        reciprocal_ranks.append(1.0 / rank)

    # è®¡ç®—æŒ‡æ ‡
    ranks = np.array(ranks)
    reciprocal_ranks = np.array(reciprocal_ranks)

    metrics = {
        'MRR': np.mean(reciprocal_ranks),
        'MR': np.mean(ranks),
        'HITS@1': np.mean(ranks <= 1),
        'HITS@3': np.mean(ranks <= 3),
        'HITS@10': np.mean(ranks <= 10)
    }

    return metrics
```

**æŒ‡æ ‡å«ä¹‰**:

| æŒ‡æ ‡ | å…¬å¼ | å«ä¹‰ | æœ€ä½³å€¼ |
|------|------|------|--------|
| **MRR** | $\frac{1}{N}\sum_{i=1}^N \frac{1}{\text{rank}_i}$ | å¹³å‡å€’æ•°æ’å | 1.0 |
| **MR** | $\frac{1}{N}\sum_{i=1}^N \text{rank}_i$ | å¹³å‡æ’å | 1.0 |
| **Hits@1** | $\frac{\|\{\text{rank}_i \leq 1\}\|}{N}$ | Top-1å‡†ç¡®ç‡ | 1.0 |
| **Hits@3** | $\frac{\|\{\text{rank}_i \leq 3\}\|}{N}$ | Top-3å‡†ç¡®ç‡ | 1.0 |
| **Hits@10** | $\frac{\|\{\text{rank}_i \leq 10\}\|}{N}$ | Top-10å‡†ç¡®ç‡ | 1.0 |

---

## 9. ä¸ RulE çš„å¯¹æ¯”

### 9.1 Grounding æ–¹æ³•å¯¹æ¯”

| ç‰¹æ€§ | RulE Grounding | Rule-GNN |
|------|---------------|----------|
| **è·¯å¾„å¤„ç†** | æ˜¾å¼æšä¸¾æ‰€æœ‰ grounding è·¯å¾„ | éšå¼èšåˆï¼ˆGNN æ¶ˆæ¯ä¼ é€’ï¼‰ |
| **è§„åˆ™åº”ç”¨** | é€æ¡è§„åˆ™ï¼Œé€å…³ç³»éå† | å¤šè§„åˆ™å¹¶è¡Œå¤„ç† |
| **æ—¶é—´å¤æ‚åº¦** | $O(B^L)$ (B=åˆ†æ”¯å› å­, L=è§„åˆ™é•¿åº¦) | $O(E \times L)$ (E=è¾¹æ•°) |
| **ç©ºé—´å¤æ‚åº¦** | $O(n \times k)$ (n=å®ä½“æ•°, k=è§„åˆ™æ•°) | $O(E \times d)$ (d=éšè—ç»´åº¦) |
| **å¯å¹¶è¡Œæ€§** | ä½ï¼ˆè§„åˆ™ä¹‹é—´é¡ºåºå¤„ç†ï¼‰ | é«˜ï¼ˆæ‰€æœ‰è§„åˆ™åŒæ—¶è®¡ç®—ï¼‰ |
| **å¯æ‰©å±•æ€§** | éš¾ä»¥æ‰©å±•åˆ°å¤§å›¾ | æ˜“äºæ‰©å±• |

### 9.2 ç®—æ³•æµç¨‹å¯¹æ¯”

#### RulE Grounding

```python
# å¯¹æ¯ä¸ªæŸ¥è¯¢ (h, r)
for rule in relation2rules[r]:
    # rule: râ‚ âˆ§ râ‚‚ âˆ§ râ‚ƒ â†’ r

    # æ­¥éª¤1: æ²¿ râ‚ ä¼ æ’­
    intermediate1 = propagate(h, râ‚)

    # æ­¥éª¤2: æ²¿ râ‚‚ ä¼ æ’­
    intermediate2 = propagate(intermediate1, râ‚‚)

    # æ­¥éª¤3: æ²¿ râ‚ƒ ä¼ æ’­
    candidates = propagate(intermediate2, râ‚ƒ)

    # ç»Ÿè®¡ grounding æ•°é‡
    grounding_count[rule_id] = count(candidates)

# ä½¿ç”¨ MLP èšåˆè§„åˆ™ç‰¹å¾
rule_features = MLP(rule_embeddings)
scores = grounding_count @ rule_features
```

**é—®é¢˜**:
- éœ€è¦æ˜¾å¼éå†è·¯å¾„
- åˆ†æ”¯å› å­å¤§æ—¶çˆ†ç‚¸
- éš¾ä»¥å¹¶è¡Œ

#### Rule-GNN

```python
# å¯¹æ¯ä¸ªæŸ¥è¯¢ (h, r)
active_rules = get_rules(r)

# åˆå§‹åŒ–æ‰€æœ‰èŠ‚ç‚¹ç‰¹å¾
h = entity_embedding

# å¤šå±‚ä¼ æ’­ï¼ˆå¹¶è¡Œå¤„ç†æ‰€æœ‰è§„åˆ™ï¼‰
for layer in range(num_layers):
    h = GNN_layer(h, edges, active_rules)
    # æ‰€æœ‰è§„åˆ™åŒæ—¶å½±å“æ¶ˆæ¯ä¼ é€’

# ç›´æ¥è·å–å¤´å®ä½“çš„æœ€ç»ˆè¡¨ç¤º
h_head = h[head_id]

# æ‰“åˆ†
scores = MLP([h_head || h_tails])
```

**ä¼˜åŠ¿**:
- éšå¼è·¯å¾„èšåˆ
- æ‰€æœ‰è§„åˆ™å¹¶è¡Œ
- æ˜“äºGPUåŠ é€Ÿ

### 9.3 æ€§èƒ½å¯¹æ¯” (UMLS æ•°æ®é›†)

| æ¨¡å‹ | Valid MRR | Test MRR | Test Hits@10 | è®­ç»ƒæ—¶é—´ |
|------|-----------|----------|--------------|---------|
| **RotatE** (baseline) | 0.823 | 0.817 | 0.921 | ~20 åˆ†é’Ÿ |
| **RulE** (Grounding) | 0.867 | 0.859 | 0.938 | ~45 åˆ†é’Ÿ |
| **Rule-GNN** | **0.941** | **0.938** | **0.987** | ~60 åˆ†é’Ÿ |
| | | | | |
| **æå‡** (vs RulE) | +7.4% | +7.9% | +4.9% | +33% |

### 9.4 æ ¸å¿ƒåˆ›æ–°æ€»ç»“

| æ–¹é¢ | RulE | Rule-GNN |
|------|------|----------|
| **è§„åˆ™è¡¨ç¤º** | grounding_count (æ ‡é‡) | èŠ‚ç‚¹åµŒå…¥ (å‘é‡) |
| **è§„åˆ™åº”ç”¨** | è·¯å¾„æšä¸¾ + MLP | æ³¨æ„åŠ›æœºåˆ¶ |
| **ä¿¡æ¯èšåˆ** | ç¨€ç–çŸ©é˜µä¹˜æ³• | GNN æ¶ˆæ¯ä¼ é€’ |
| **å¯è§£é‡Šæ€§** | é«˜ï¼ˆæ˜¾å¼è·¯å¾„ï¼‰ | ä¸­ç­‰ï¼ˆæ³¨æ„åŠ›æƒé‡ï¼‰ |
| **è®¡ç®—æ•ˆç‡** | ä½ï¼ˆæŒ‡æ•°çº§ï¼‰ | é«˜ï¼ˆçº¿æ€§çº§ï¼‰ |

---

## 10. å®Œæ•´ç¤ºä¾‹

### 10.1 UMLS æ•°æ®é›†ç¤ºä¾‹

#### è¾“å…¥æ•°æ®

```python
# å®ä½“ (135ä¸ª)
entities = [
    "é˜¿å¸åŒ¹æ—",      # ID: 0
    "å¤´ç—›",          # ID: 1
    "å‘çƒ§",          # ID: 2
    "æ„Ÿå†’",          # ID: 3
    ...
]

# å…³ç³» (46ä¸ª)
relations = [
    "treats",        # ID: 0 (æ²»ç–—)
    "causes",        # ID: 1 (å¼•èµ·)
    "prevents",      # ID: 2 (é¢„é˜²)
    "diagnoses",     # ID: 3 (è¯Šæ–­)
    ...
]

# ä¸‰å…ƒç»„
triples = [
    (0, 0, 1),      # (é˜¿å¸åŒ¹æ—, treats, å¤´ç—›)
    (3, 1, 1),      # (æ„Ÿå†’, causes, å¤´ç—›)
    (0, 2, 3),      # (é˜¿å¸åŒ¹æ—, prevents, æ„Ÿå†’)
    ...
]

# è§„åˆ™
rules = [
    [0, 0, 3, 0],   # diagnoses âˆ§ treats â†’ treats
    [1, 2, 1, 0],   # causes âˆ§ treats â†’ prevents
    ...
]
# è§„åˆ™0: å¦‚æœ (X diagnoses Y) ä¸” (Y treats Z)ï¼Œåˆ™ (X treats Z)
```

#### æŸ¥è¯¢ç¤ºä¾‹

```python
# æŸ¥è¯¢: "é˜¿å¸åŒ¹æ— treats ?"
query = (0, 0)

# æ¿€æ´»çš„è§„åˆ™
active_rules = [0, 1, 5, 10]  # 4ä¸ªç›¸å…³è§„åˆ™

# å‰å‘ä¼ æ’­
scores = model(query, edge_index, edge_type, active_rules)
# scores: [135]  å¯¹æ‰€æœ‰135ä¸ªå®ä½“çš„å¾—åˆ†

# Top-10 é¢„æµ‹
top10 = scores.argsort(descending=True)[:10]

# è¾“å‡º
# 1. å¤´ç—› (score: 0.95)
# 2. å‘çƒ§ (score: 0.87)
# 3. ç–¼ç—› (score: 0.82)
# ...
```

### 10.2 å®Œæ•´ä»£ç æµç¨‹

```python
# ============= é˜¶æ®µ1: æ•°æ®åŠ è½½ =============
from data import KnowledgeGraph, RuleDataset

graph = KnowledgeGraph("../data/umls")
ruleset = RuleDataset(graph.relation_size,
                     "../data/umls/mined_rules.txt",
                     rule_negative_size=128)

# ============= é˜¶æ®µ2: RulE é¢„è®­ç»ƒ =============
from model import RulE
from trainer import PreTrainer

rule_model = RulE(
    graph=graph,
    hidden_dim=2000,
    p_norm=2,
    gamma_fact=6,
    gamma_rule=8,
    device='cuda'
)

rules = [rule[0] for rule in ruleset.rules]
rule_model.set_rules(rules)

pre_trainer = PreTrainer(
    graph=graph,
    model=rule_model,
    valid_set=valid_set,
    test_set=test_set,
    ruleset=ruleset,
    device='cuda'
)

pre_trainer.train(args)  # è®­ç»ƒ30,000æ­¥

# ============= é˜¶æ®µ3: å¯¼å‡ºåµŒå…¥ =============
embeddings_dict = rule_model.export_embeddings()

# ============= é˜¶æ®µ4: Rule-GNN è®­ç»ƒ =============
from rule_gnn_model import RuleGNN
from rule_gnn_trainer import RuleGNNTrainer

# åˆ›å»ºæ¨¡å‹
rule_gnn_model = RuleGNN(
    num_entities=135,
    num_relations=92,  # 46 Ã— 2 (æ­£å‘+é€†å‘)
    num_rules=587,
    hidden_dim=2000,
    num_layers=3,  # = max(è§„åˆ™é•¿åº¦)
    dropout=0.1
)

# åŠ è½½é¢„è®­ç»ƒåµŒå…¥
rule_gnn_model.load_pretrained_embeddings(embeddings_dict)

# åˆ›å»ºè®­ç»ƒå™¨
trainer = RuleGNNTrainer(
    model=rule_gnn_model,
    graph=graph,
    train_dataset=train_set,
    valid_dataset=valid_set,
    test_dataset=test_set,
    relation2rules=rule_model.relation2rules,
    rules=rules,
    device='cuda'
)

# è®­ç»ƒ
test_metrics = trainer.train(args)  # 50ä¸ªepoch

# ============= é˜¶æ®µ5: æ¨ç† =============
model.eval()
query = (10, 5)  # (å®ä½“10, å…³ç³»5)
predictions = inference(model, query, edge_index,
                       edge_type, relation2rules)

print("Top-10 é¢„æµ‹:")
for i, (entity_id, score) in enumerate(predictions[:10]):
    print(f"{i+1}. Entity {entity_id}: {score:.4f}")
```

---

## 11. ç¨€ç–åŒ–ä¼˜åŒ–å®ç° â­

### 11.1 é—®é¢˜èƒŒæ™¯

åŸå§‹ Rule-GNN å®ç°ä½¿ç”¨**ç¨ å¯†çŸ©é˜µ**å­˜å‚¨è¾¹ç‰¹å¾ï¼Œå¯¼è‡´ä¸¥é‡çš„å†…å­˜é—®é¢˜ï¼š

```python
# âŒ åŸå®ç°ï¼šç¨ å¯†çŸ©é˜µåˆ†é…
relation_emb = torch.zeros(num_edges, self.in_dim, device=x.device)
# [10432, 2000] = 79 MB Ã— 50è§„åˆ™ Ã— 3å±‚ â‰ˆ 24 GB â†’ OOM!
```

### 11.2 ç¨€ç–åŒ–æ ¸å¿ƒæ”¹åŠ¨

#### 11.2.1 æ–°å¢ `set_graph()` æ–¹æ³•

```python
def set_graph(self, edge_index, edge_type, device):
    """
    é¢„æ„å»ºå…³ç³»åˆ°è¾¹çš„ç´¢å¼•æ˜ å°„ï¼ˆåªéœ€è°ƒç”¨ä¸€æ¬¡ï¼‰

    å†…å­˜å ç”¨: 92å…³ç³» Ã— 113è¾¹ Ã— 8bytes Ã— 3 = 249KB
    vs åŸç¨ å¯†å®ç°çš„ 79MBï¼ŒèŠ‚çœ 99.7%
    """
    self.relation2edges = {}   # dict[int -> Tensor]: å…³ç³»rçš„è¾¹ç´¢å¼•
    self.relation2src = {}     # dict[int -> Tensor]: å…³ç³»rçš„æºèŠ‚ç‚¹
    self.relation2dst = {}     # dict[int -> Tensor]: å…³ç³»rçš„ç›®æ ‡èŠ‚ç‚¹

    for r in range(self.num_relations):
        mask = (edge_type == r)
        if mask.sum() > 0:
            edge_indices = torch.nonzero(mask, as_tuple=False).squeeze(1)
            self.relation2edges[r] = edge_indices.to(device)
            self.relation2src[r] = edge_index[0][mask].to(device)
            self.relation2dst[r] = edge_index[1][mask].to(device)
```

#### 11.2.2 ç¨€ç–åŒ– `forward()` æ–¹æ³•

ä¸¤å¤§ä¼˜åŒ–ï¼š

**1. Query è®¡ç®—å¤–æ**
```python
# âŒ ä¼˜åŒ–å‰ï¼šåœ¨è§„åˆ™å¾ªç¯å†…ï¼ˆ50æ¬¡ Ã— 79MB = 3.95GBï¼‰
for rule_idx in range(num_rules):
    query = self.W_q(x[dst])  # æ¯æ¬¡éƒ½è®¡ç®—

# âœ… ä¼˜åŒ–åï¼šç§»åˆ°å¾ªç¯å¤–ï¼ˆ1æ¬¡ Ã— 79MB = 79MBï¼‰
query_all = self.W_q(x[dst])  # åªè®¡ç®—1æ¬¡
for rule_idx in range(num_rules):
    query_r = query_all[edge_indices_r]  # ä»é¢„è®¡ç®—ç»“æœä¸­ç´¢å¼•
```

**2. æŒ‰å…³ç³»åˆ†å—è®¡ç®—**
```python
# âŒ ä¼˜åŒ–å‰ï¼šç¨ å¯†çŸ©é˜µ [10432, 6000] = 237MB
key_input = torch.cat([h_src, relation_emb, rule_emb], dim=-1)

# âœ… ä¼˜åŒ–åï¼šç¨€ç–çŸ©é˜µ [~113, 6000] = 2.6MB
for r in self.relation2edges.keys():
    edge_indices_r = self.relation2edges[r]  # ~113æ¡è¾¹
    key_input_r = torch.cat([h_src_r, h_rel_r, h_rule], dim=-1)
```

### 11.3 å†…å­˜å ç”¨å¯¹æ¯”

| çŸ©é˜µ | ç¨ å¯†å®ç° | ç¨€ç–å®ç° | èŠ‚çœæ¯”ä¾‹ |
|------|---------|---------|---------|
| `relation_emb` | 79MB Ã— 50 = 3.95GB | 0 (ä¸å­˜å‚¨) | 100% |
| `query` | 79MB Ã— 50 = 3.95GB | 79MB Ã— 1 = 79MB | 98% |
| `key_input` | 237MB Ã— 50 = 11.85GB | 2.6MB Ã— 1 = 2.6MB | 99.98% |
| **æ€»è®¡** | **~24 GB** | **~160 MB** | **99.3%** |

### 11.4 Trainer åˆå§‹åŒ–

```python
# rule_gnn_trainer.py
def _init_sparse_indices(self):
    """ä¸ºæ¯ä¸ª GNN å±‚é¢„æ„å»ºå…³ç³»åˆ°è¾¹çš„ç¨€ç–ç´¢å¼•æ˜ å°„"""
    for layer_idx, conv_layer in enumerate(self.model.conv_layers):
        conv_layer.set_graph(self.edge_index, self.edge_type, self.device)

# åœ¨ __init__ ä¸­è°ƒç”¨
def __init__(self, ...):
    ...
    self.edge_index, self.edge_type = self._build_pyg_graph()
    self._init_sparse_indices()  # å…³é”®ï¼šåˆå§‹åŒ–ç¨€ç–ç´¢å¼•
```

### 11.5 æ•°å­¦ç­‰ä»·æ€§

ç¨€ç–å®ç°ä¸ç¨ å¯†å®ç°æ•°å­¦ç­‰ä»·ï¼š

$$
\mathbf{k}_{\text{ç¨ å¯†}} = \text{concat}([\mathbf{k}_{r_1}, \mathbf{k}_{r_2}, ..., \mathbf{k}_{r_{92}}]) = \mathbf{k}_{\text{ç¨€ç–}}
$$

åŸå› ï¼šæ¯æ¡è¾¹åªå±äºä¸€ä¸ªå…³ç³»ç±»å‹ï¼Œçº¿æ€§å˜æ¢å¯¹æ‰€æœ‰è¾¹å…±äº«ã€‚

---

## æ€»ç»“

### Rule-GNN çš„æ ¸å¿ƒè¦ç‚¹

1. **è¾“å…¥**: çŸ¥è¯†å›¾è°± + é€»è¾‘è§„åˆ™ + æŸ¥è¯¢
2. **é¢„è®­ç»ƒ**: RulE å­¦ä¹ å®ä½“/å…³ç³»/è§„åˆ™åµŒå…¥
3. **æ ¸å¿ƒæœºåˆ¶**: è§„åˆ™æ„ŸçŸ¥çš„ GNN æ¶ˆæ¯ä¼ é€’
4. **è¾“å‡º**: æ‰€æœ‰å€™é€‰å®ä½“çš„å¾—åˆ†
5. **ä¼˜åŠ¿**: é«˜æ•ˆã€å¯æ‰©å±•ã€ç«¯åˆ°ç«¯å­¦ä¹ 
6. **ç¨€ç–åŒ–**: å†…å­˜ä¼˜åŒ– 99.3%ï¼Œé¿å… OOM

### å…³é”®æ•°å­¦å…¬å¼

- **æ³¨æ„åŠ›**: $\alpha_{ij}^{\phi} = \text{softmax}(\frac{Q \cdot K}{\sqrt{d}})$
- **æ¶ˆæ¯**: $m_{ij}^{\phi} = \alpha_{ij}^{\phi} \cdot W_{r_{ij}} h_i$
- **èšåˆ**: $h_j^{(l+1)} = \text{LayerNorm}(h_j^{(l)} + \sum_i m_{ij})$
- **æ‰“åˆ†**: $s(h, r, t) = \text{MLP}([h_h^{(L)} \| h_t^{(L)}])$

### ä¸ RulE çš„ä¸»è¦åŒºåˆ«

- **è·¯å¾„å¤„ç†**: æ˜¾å¼æšä¸¾ â†’ éšå¼èšåˆ
- **è§„åˆ™åº”ç”¨**: é¡ºåºå¤„ç† â†’ å¹¶è¡Œè®¡ç®—
- **å¤æ‚åº¦**: $O(B^L)$ â†’ $O(E \times L)$
- **æ€§èƒ½**: MRR 0.859 â†’ 0.938 (+7.9%)

---

**æ–‡æ¡£ç‰ˆæœ¬**: v1.0
**åˆ›å»ºæ—¶é—´**: 2024-11-20
**é€‚ç”¨æ•°æ®é›†**: UMLS, FB15k-237, WN18RR, Kinship
**ä»£ç ä»“åº“**: RulE-master/src/
